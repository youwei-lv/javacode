0: A Dynamical Approach to Temporal Pattern Processing
    id = 77
    authors = Hogg_T Huberman_B Stornetta_W 
    4 (0.21626): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.14852): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.10711): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

1: Minkowski-r Back-Propagation: Learning in Connectionist Models with Non-Euclidian Error Signals
    id = 36
    authors = Burr_D Hanson_S 
    8 (0.24261): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.17110): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.14099): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.12593): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

2: Data Analysis Using G/Splines
    id = 562
    authors = Rogers_D 
    10 (0.28777): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.22755): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.05819): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

3: COMPUTATIONAL STRUCTURE OF COORDINATE TRANSFORMATIONS: A GENERALIZATION STUDY
    id = 983
    authors = Ghahramani_Z Jordan_M Wolpert_D 
    10 (0.33670): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.20121): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

4: Feudal Reinforcement Learning
    id = 606
    authors = Dayan_P Hinton_G 
    4 (0.27648): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.21626): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    10 (0.14099): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.07324): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.05066): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

5: Odor Processing in the Bee: A Preliminary Study of the Role of Central Input to the Antennal Lobe
    id = 766
    authors = Kerszberg_M Linster_C Marson_D Masson_C 
    3 (0.33294): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.15981): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.09959): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.08077): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    17 (0.01679): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

6: Globally Trained Handwritten Word Recognizer Using Spatial Representation, Convolutional Neural Networks, and Hidden Markov Models
    id = 817
    authors = Bengio_Y Henderson_D LeCun_Y 
    1 (0.34799): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.20121): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.09206): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.06195): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.03937): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

7: Comparison Training for a Rescheduling Problem in Neural Networks
    id = 800
    authors = Keymeulen_D de-Gerlache_M 
    5 (0.23508): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.21626): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.13722): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.06195): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    38 (0.04313): 20 information  (0.10772) 6 function  (0.10772) 13 output  (0.10772) 3 neural  (0.07853) 10 networks  (0.04934) 1 learning  (0.04934) 7 figure  (0.04934) 24 performance  (0.04934) 21 problem  (0.04934) 23 hidden  (0.04934)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

8: The Statistical Mechanics of k-Satisfaction
    id = 755
    authors = Gyorgyi_G Kirkpatrick_S Tishby_N Troyansky_L 
    1 (0.26519): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.16733): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.12970): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

9: Synergy of Clustering Multiple Back Propagation Networks
    id = 264
    authors = Lincoln_W Skrzypek_J 
    0 (0.26143): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.21250): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.19744): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

10: Phase-coupling in Two-Dimensional Networks of Interacting Oscillators . . .
    id = 302
    authors = Kammen_D Koch_C Niebur_E Ruderman_D Schuster_H 
    4 (0.27648): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.13722): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

11: Analog Computation at a Critical Point .
    id = 304
    authors = Bialek_W Kruglyak_L 
    5 (0.25766): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.20873): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.17863): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.07324): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06195): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

12: Analysis of Linsker's Simulations of Hebbian Rules
    id = 269
    authors = MacKay_D Miller_K 
    8 (0.29154): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.03937): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    32 (0.00926): 14 number  (0.22966) 4 input  (0.08488) 12 algorithm  (0.08488) 13 output  (0.04869) 16 error  (0.04869) 2 model  (0.04869) 5 data  (0.04869) 24 performance  (0.04869) 20 information  (0.04869) 3 neural  (0.03059)

13: Dynamics of Generalization in Linear Perceptrons .
    id = 407
    authors = Hertz_J Krogh_A 
    7 (0.32165): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.18615): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.08830): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.03560): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

14: Kohonen Networks and Clustering .
    id = 419
    authors = Bilbro_G Nissman_D Snyder_W VandenBout_D 
    3 (0.25766): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.14475): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.10711): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.03937): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

15: Neural Network Gaussian Mixture Hybrid for Speech Recognition or Density Estimation
    id = 450
    authors = Bengio_Y De-Mori_R Flammia_G Kompe_R 
    4 (0.46843): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.05819): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.01679): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

16: A Neural Network that Learns to Interpret Myocardial Planar Thallium Scintigrams
    id = 665
    authors = Atlan_H Erel_J Rosenberg_C 
    3 (0.25014): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.23884): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.08830): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.03937): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

17: Locally Adaptive Nearest Neighbor Algorithms
    id = 723
    authors = Dietterich_T Wettschereck_D 
    7 (0.26519): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.23508): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.08830): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.02055): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

18: Dynamic, Non-Local Role Bindings and Inferencing in a Localist Network for Natural Language Understanding
    id = 152
    authors = Dyer_M Lange_T 
    3 (0.23132): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.18615): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.16733): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.08453): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

19: Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems
    id = 71
    authors = Macy_S Shepanski_J 
    7 (0.35552): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.19368): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.11088): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.09959): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

20: Statistics of Natural Images: Scaling in the Woods
    id = 769
    authors = Bialek_W Ruderman_D 
    3 (0.34423): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.17863): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.10335): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.03560): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.03184): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

21: A Topograhic Product for the Optimization of Self-Organizing Feature Maps . .
    id = 569
    authors = Bauer_H Geisel_T Pawelzik_K 
    3 (0.29906): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.25390): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.16357): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.05066): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

22: A CHARGE-BASED CMOS PARALLEL ANALOG VECTOR QUANTIZER
    id = 940
    authors = Cauwenberghs_G Pedroni_V 
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.20497): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.08453): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.02055): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)

23: Extensions of a Theory of Networks for Approximation and Learning .
    id = 387
    authors = Caprile_B Girosi_F Poggio_T 
    0 (0.27272): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.25390): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

24: Implementing Intelligence on Silicon Using Neuron-Like Functional MOS  Transistors
    id = 815
    authors = Ishii_H Kosaka_H Kotani_K Ohmi_T Shibata_T Yamashita_T 
    3 (0.51736): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.12593): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.11841): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

25: Recognition-Based Segmentation of On-Line Cursive Handwriting
    id = 797
    authors = Flann_N 
    0 (0.24637): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.18615): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.16357): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.11841): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    29 (0.00926): 15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

26: Locomotion in a Lower Vertebrate: Studies of the Cellular Basis of Rhythmogenesis and Oscillator Coupling
    id = 441
    authors = Buchanan_J 
    9 (0.44585): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.22379): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

27: OCULAR DOMINANCE AND PATTERNED LATERAL CONNFL-TIONS IN A SELF-ORGANIZING MODEL OFTHE PRIMARY VISUAL CORTEX
    id = 857
    authors = Miikkulainen_R Sirosh_J 
    12 (0.21626): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.15228): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.12217): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.08077): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

28: NEW ALGORITHMS FOR 2D AND 3D POINT MATCHING: POSE ESTIMATION AND CORRESPONDENCE
    id = 962
    authors = Gold_S Lu_C Mjolsness_E Pappu_S Rangarajan_A 
    6 (0.46090): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.15228): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.04313): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

29: A Neural Network for Feature Extraction
    id = 272
    authors = Intrator_N 
    4 (0.24637): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.14099): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

30: A Short-Term Memory Architecture for the Learning of Morphophonemic Rules .
    id = 368
    authors = Gasser_M Lee_C 
    12 (0.51736): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.15981): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

31: The Capacity of the Kanerva Associative Memory is Exponential
    id = 18
    authors = Chou_P 
    6 (0.23132): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.21626): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.11841): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.11088): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.03184): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

32: Constrained Differential Optimization
    id = 63
    authors = Barr_A Platt_J 
    5 (0.26895): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.08830): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

33: LEARNING LOCAL ERROR BARS FOR NONLINEAR REGRESSION
    id = 904
    authors = Nix_D Weigend_A 
    6 (0.28401): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.28401): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.11464): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

34: Connectionist Music Composition Based on Melodic and Stylistic Constraints . .
    id = 392
    authors = Mozer_M Soukup_T 
    11 (0.34423): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.18615): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.12593): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

35: Memory-based Reinforcement Learning: Efficient Computation with Prioritized Sweeping
    id = 605
    authors = Atkeson_C Moore_A 
    5 (0.26895): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.13722): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

36: Associative Memory in a Simple Model of Oscillating Cortex ........
    id = 193
    authors = Baird_B 
    6 (0.45338): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.09582): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

37: HMM Speech Recognition with Neural Net Discrimination
    id = 208
    authors = Huang_W Lippmann_R 
    4 (0.29906): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.16733): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.05442): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

38: Forecasting Demand for Electric Power
    id = 663
    authors = Fine_T Yuan_J 
    8 (0.31036): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.20121): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.06571): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.03937): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)

39: Global Regularization of Inverse Kinematics for Redundant Manipulators
    id = 604
    authors = DeMers_D Kreutz-Delgado_K 
    2 (0.28401): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.13722): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.13346): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

40: A Formal Model of the Insect Olfactory Macroglomerulus: Simulations and Analytic Results
    id = 698
    authors = Dreyfus_G Kerszberg_M Linster_C Marsan_D Masson_C Personnaz_L 
    11 (0.26895): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.20873): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.12217): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.06195): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

41: Fast Pruning Using Principal Components
    id = 704
    authors = Leen_T Levin_A Moody_J 
    4 (0.28777): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.22755): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.06571): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.06195): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

42: Constructive Learning Using Internal Representation Conflicts
    id = 735
    authors = Jabri_M Leerink_L 
    8 (0.38563): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.11464): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.10335): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.05442): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

43: The VC-Dimension versus the Statistical Capacity of Multilayer Networks
    id = 542
    authors = Ji_C Psaltis_D 
    2 (0.23132): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.17110): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.08077): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.07324): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.06571): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

44: Node Splitting: A Contructive Algorithm for Feed-Forward Neural Networks
    id = 560
    authors = Wynne-Jones_M 
    8 (0.33670): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.26143): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.07324): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    18 (0.02431): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

45: Reorganization of Somatosensory Cortex after Tactile Training
    id = 995
    authors = Peterson_R Taylor_J 
    13 (0.20497): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.15228): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.09206): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.08453): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)

46: FROM DATA DISTRIBUTIONS TO REGULARIZATION IN INVARIANT LEARNING
    id = 871
    authors = Leen_T 
    11 (0.28025): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.26143): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.14475): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

47: Two-Dimensional Object Localization by Coarse-to-Fine Correlation Matching
    id = 823
    authors = Lu_C Mjolsness_E 
    21 (0.46467): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    0 (0.23884): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.03184): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

48: Asynchronous Dynamics of Continuous Time Neural Networks
    id = 762
    authors = Blum_E Li_Q Wang_X 
    3 (0.25390): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.14852): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.08830): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.03560): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

49: Optimal Filtering in the Salamander Retina .
    id = 336
    authors = Bialek_W Owen_W Rieke_F 
    13 (0.22755): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.16357): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.13722): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.09959): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.03937): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

50: An Application of the Principle of Maximum Information Preservation to Linear Systems
    id = 111
    authors = Linsker_R 
    3 (0.37434): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.17486): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.11088): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

51: Does the Neuron 'Learn' Like the Synapse?
    id = 109
    authors = Tawel_R 
    6 (0.23132): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

52: Range Image Restoration Using Mean Field Annealing
    id = 158
    authors = Bilbro_G Snyder_W 
    2 (0.32541): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.09206): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.08453): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

53: Relaxation Networks for Large Supervised Learning Problems .
    id = 423
    authors = Allen_R Alspector_J Jayakumar_A Meir_R Zeppenfeld_T 
    8 (0.29906): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.29530): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

54: USING A NEURAL NETTO INSTANTlATE A DEFORMABLE MODEL
    id = 963
    authors = Hinton_G Revow_M Williams_C 
    1 (0.33294): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.32541): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

55: ADAPTIVE ELASTIC INPUT FIELD FOR RECOGNITION IMPROVEMENT
    id = 980
    authors = Asogawa_M 
    6 (0.24261): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.21626): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.10335): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

56: Classifying Hand Gestures with a View-Based Distributed Representation
    id = 818
    authors = Darrell_T Pentland_A 
    13 (0.24261): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.18615): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.14475): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.11841): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

57: A Novel Approach to Prediction of the 3-Dimensional Structures .
    id = 356
    authors = Bohr_H Bohr_J Brunak_S Cotterill_R Fredholm_H Lautmp_B Petersen_S 
    14 (0.35176): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.04690): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

58: On The Circuit Complexity of Neural Networks .
    id = 415
    authors = Kailath_T Orlitsky_A Roychowdhury_V Siu_K 
    3 (0.38939): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.10335): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.04313): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

59: A Cost Function for Internal Representations
    id = 274
    authors = Hertz_J Krogh_A Thorbergsson_C 
    12 (0.42703): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.18992): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

60: Recognizing Overlapping Hand-Printed Characters by Centered-Object Integrated Segmentation and Recognition
    id = 490
    authors = Martin_G Rashid_M 
    4 (0.40445): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.10335): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

61: Training a 3-Node Neural Network is NP-Complete
    id = 146
    authors = Blum_A Rivest_R 
    3 (0.35176): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    19 (0.11088): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.07701): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

62: BOLTZMANN CHAINS AND HIDDEN MARKOV MODELS
    id = 897
    authors = Jordan_M Saul_L 
    3 (0.52489): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.14099): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.08830): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

63: Distributed Recursive Structure Processing ..
    id = 366
    authors = Legendre_G Miyata_Y Smolensky_P 
    4 (0.28025): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.17863): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.13722): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.07701): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

64: A comparison between a neural netwok model for the formation of brain maps and experimental data
    id = 439
    authors = Blasdel_G Obermayer_K Schulten_K 
    6 (0.32165): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.13346): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.12970): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.08077): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.02055): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

65: A Recurrent Neural Network for Word Identification from Continuous Phoneme Strings .
    id = 313
    authors = Allen_R Kamm_C 
    11 (0.40445): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

66: A SOLVABLE CONNECTIONIST MODEL OF IMMEDIATE RECALL OF ORDERED LISTS
    id = 850
    authors = Burgess_N 
    3 (0.18239): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.18239): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.15981): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.13722): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.06948): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

67: THE NI1000: HIGH SPEED PARALLEL VLSI FOR IMPLEMENTING MULTILAYER PERCEPTRONS
    id = 936
    authors = Cooper_L Perrone_M 
    0 (0.23884): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.15604): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.10711): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.07701): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.04313): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

68: Kernel Regression and Backpropagation Training with Noise
    id = 555
    authors = Holmstrom_L Koistinen_P 
    16 (0.24261): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.11464): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.03937): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

69: Neural Analog Diffusion-Enhancement Layer and Spatio-Temporal Grouping in Early Vision
    id = 123
    authors = Cunningham_R Seibert_M Waxman_A Wu_J 
    11 (0.22755): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.22003): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

70: Temporal Adaptation in a Silicon Auditory Nerve
    id = 528
    authors = Lazzaro_J 
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.12217): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.11088): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.09582): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.07324): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.07324): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.05066): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)

71: Estimating Average-Case Learning Curves Using Bayesian, Statistical Physics and VC Dimension Methods
    id = 533
    authors = Haussler_D Kearns_M Opper_M Schapire_R 
    2 (0.23884): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.20497): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.13346): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.12217): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.06195): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

72: Learning to Make Coherent Predictions in Domains with Discontinuities
    id = 474
    authors = Becker_S Hinton_G 
    10 (0.22379): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.17863): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

73: A MIXTURE MODEL SYSTEM FOR MEDICAL AND MACHINE DIAGNOSIS
    id = 977
    authors = Sejnowski_T Stensmo_M 
    11 (0.20497): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.17486): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.10335): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

74: Hierarchies of adaptive experts
    id = 549
    authors = Jacobs_R Jordan_M 
    5 (0.26143): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.21626): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.18992): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.08077): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

75: GENESIS: A System for Simulating Neural Networks
    id = 145
    authors = Bhalla_U Bower_J Uhley_J Wilson_M 
    11 (0.53241): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.20497): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

76: Learning Global Direct Inverse Kinematics
    id = 500
    authors = DeMers_D Kreutz-Delgado_K 
    1 (0.30659): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.18615): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.09959): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    18 (0.00926): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

77: Operational Fault Tolerance of CMAC Networks
    id = 226
    authors = Carter_M Nucci_A Rudolph_F 
    11 (0.31788): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.22755): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.14852): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.05066): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

78: Neural Computing with Small Weights
    id = 544
    authors = Bruck_J Siu_K 
    10 (0.31036): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.22379): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.13346): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.06195): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

79: PREDICTIVE CODING WITH NEURAL NETS: APPLICATION TO TEXT COMPRESSION
    id = 973
    authors = Heil_S Schmidhuber_J 
    9 (0.43079): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.12217): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

80: Developing Population Codes by Minimizing Description Length
    id = 701
    authors = Hinton_G Zemel_R 
    2 (0.41198): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

81: The Effective Number of Parameters: An Analysis of Generalization and Regularization in Nonlinear Learning Systems
    id = 532
    authors = Moody_J 
    15 (0.43832): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.14852): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

82: Adaptive Synchronization of Neural and Physical Oscillators
    id = 442
    authors = Doya_K Yoshizawa_S 
    2 (0.38563): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.22379): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.13722): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

83: FACTORIAL LEARNING BY CLUSTERING FEATURES
    id = 913
    authors = Tenenbaum_J Todorov_E 
    0 (0.38563): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.15228): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.09582): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    18 (0.03560): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

84: Learning Mackey-Glass from 25 Examples, Plus or Minus 2
    id = 841
    authors = Cottrell_G Plutowski_M White_H 
    2 (0.37810): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.31788): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

85: Reconfigurable Neural Net Chip with 32K Connections ..
    id = 426
    authors = Graf_H Henderson_D Janow_R Lee_R 
    3 (0.40445): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.18615): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.03937): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

86: How Receptive Field Parameters Affect Neural Learning ..
    id = 388
    authors = Mel_B Omohundro_S 
    7 (0.31788): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.21250): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.12217): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.07324): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

87: Dynamics of Attention as Near Saddle-node Bifurcation Behavior
    id = 989
    authors = Doya_K Nakahara_H 
    4 (0.34046): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.22003): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

88: Learning Sequential Structure in Simple Recurrent Networks
    id = 164
    authors = Cleeremans_A McClelland_J Servan-Schreiber_D 
    12 (0.20121): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.08830): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.04313): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

89: USING A SALIENCY MAP FOR ACTIVE SPATIAL SUBJECTIVE ATTENTION: IMPLEMENTATION &INITIAL RESULTS
    id = 899
    authors = Baluja_S Pomerleau_D 
    8 (0.25766): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.20873): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.11841): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.04690): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)

90: Statistical and Dynamical Interpretation of ISIH Data from Periodically Stimulated Sensory Neurons
    id = 694
    authors = Douglass_J Longtin_A Moss_F 
    6 (0.27272): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.19744): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.18239): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

91: Information Measure Based Skeletonisation
    id = 561
    authors = Pratt_L Ramachandran_S 
    0 (0.29906): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.13722): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.11464): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

92: Convergence of Stochastic Iterative Dynamic Programming Algorithms
    id = 788
    authors = Jaakkola_T Jordan_M Singh_S 
    0 (0.29530): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.05442): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

93: A Computational Basis for Phonology
    id = 230
    authors = Touretzky_D Wheeler_D 
    5 (0.38939): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.09206): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.07324): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

94: Remote Sensing Image Analysis via a Texture Classification Neural Network
    id = 625
    authors = Goodman_R Greenspan_H 
    0 (0.23508): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.20873): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.17110): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

95: Decoding of Neuronal Signals in Visual Pattern Recognition
    id = 472
    authors = Eskandar_E Hertz_J Kjaer_T Optican_L Richmond_B 
    0 (0.46090): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.06571): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

96: Performance of Connectionist Learning Algorithms on 2-D SIMD Processor Arrays
    id = 283
    authors = Fortes_J Nunez_F 
    4 (0.22755): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.22003): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.15981): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.14099): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

97: Neural Networks for Template Matching: Application to Real-Time Classification of the Action Potentials of Real Neurons
    id = 10
    authors = Banik_J Bower_J Wong_Y 
    5 (0.44961): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

98: VISI15 A Neural Model of Covert Visual Attention
    id = 480
    authors = Ahmad_S 
    0 (0.41950): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.16733): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.12217): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

99: Time-Sequential Self-Organization of Hierarchical Neural Networks
    id = 73
    authors = Noetzel_A Silverman_R 
    5 (0.24261): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.22379): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.19744): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.08830): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

100: Neural Dynamics of Motion Segmentation and Grouping .
    id = 331
    authors = Mingolla_E 
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.19368): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.13346): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.06195): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.02808): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

101: Bit-Serial Neural Networks
    id = 59
    authors = Butler_Z Murray_A Smith_A 
    9 (0.29530): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.14099): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

102: Object-Based Analog VLSI Vision Circuits
    id = 674
    authors = Harris_J Koch_C Liu_S Luo_J Mathur_B Sivilotti_M 
    0 (0.36681): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.14475): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.13346): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.06948): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    4 (0.05819): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

103: MURPHY: A Robot that Learns by Doing
    id = 56
    authors = Mel_B 
    3 (0.38187): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.11464): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.03937): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    22 (0.00926): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)

104: Diffusion Approximations for the Constant Step Size Backpropogation Algorithm and Resistance to Local Minima
    id = 629
    authors = Finnoff_W 
    10 (0.26143): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.23132): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.14099): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

105: An Analog VLSI Splining Network .
    id = 422
    authors = Samalam_V Schwartz_D 
    4 (0.37057): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.23132): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.12217): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

106: Speech Recognition Using Demi-Syllable Neural Prediction Model .
    id = 316
    authors = Iso_K Watanabe_T 
    6 (0.28777): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.21250): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.12593): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

107: Learning Classification with Unlabeled Data
    id = 714
    authors = de-Sa_V 
    5 (0.28025): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.20497): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.17486): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

108: Time Warping Invariant Neural Networks
    id = 595
    authors = Chen_H Lee_Y Sun_G 
    4 (0.31036): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.23508): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.15604): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

109: Robust Reinforcement Learning in Motion Planning
    id = 782
    authors = Barto_A Connolly_C Ginpen_R Singh_S 
    1 (0.25390): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.23132): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    29 (0.10711): 15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029)
    2 (0.09582): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.07701): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

110: A Multiscale Adaptive Network Model of Motion Computation in Primates . . .
    id = 332
    authors = Koch_C Mathur_B Wang_H 
    2 (0.18992): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.15604): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    9 (0.13722): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.09959): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.05442): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

111: ANN Based Classification for Heart Defibrillators
    id = 506
    authors = Chi_Z Flower_B Jabri_M Leong_P Pickard_S Xie_Y 
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.14852): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.14099): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.08077): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.03184): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

112: Amplifying and Linearizing Apical Synaptic Inputs to Cortical Pyramidal Cells
    id = 765
    authors = Bernander_O Douglas_R Koch_C 
    3 (0.34046): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.19368): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.12217): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

113: Efficient Simulation of Biological Neural Networks on Massively Parallel Supercomputers with Hypercube Architecture
    id = 813
    authors = Brettle_D Niebur_E 
    7 (0.32165): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.23132): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.14852): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.03184): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

114: Basis-Function Trees as a Generalization of Local Variable Selection Methods . .
    id = 380
    authors = Sanger_T 
    3 (0.27648): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.14099): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.12970): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.08077): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

115: Constrained Optimization Applied to the Parameter Setting Problem  for Analog Circuits
    id = 525
    authors = Barr_A Fleischer_K Kirk_D Watts_L 
    3 (0.54370): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.06571): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.02808): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

116: PATIERN PLAYBACK IN THE '90S
    id = 946
    authors = Slaney_M 
    5 (0.27272): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.20121): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.05066): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

117: Stationarity of Synaptic Coupling Strength Between Neurons with Nonstationary Discharge Properties
    id = 430
    authors = Sydorenko_M Young_E 
    5 (0.22755): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.08830): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.06948): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.06195): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.03937): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

118: Analysis and Comparison of Different Learning Algorithms for Pattern Association Problems
    id = 7
    authors = Bernasconi_J 
    0 (0.36681): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.20873): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.06195): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

119: PAIRWISE NEURAL NETWORK CLASSIFIERS WITH PROBABILISTIC OUTPUTS
    id = 981
    authors = Dreyfus_G Knerr_S Personnaz_L Price_D 
    10 (0.29530): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.17863): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.03560): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

120: Identifying Fault-Prone Software Modules Using Feed-Forward Networks: A Case Study
    id = 799
    authors = Kamnanithi_N 
    2 (0.22003): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.22003): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.19744): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

121: Clustering with a Domain-Specific Distance Measure
    id = 712
    authors = Gold_S Mjolsness_E Rangarajan_A 
    2 (0.53241): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

122: Learning Sequential Tasks by Incrementally Adding Higher Orders
    id = 587
    authors = Ring_M 
    25 (0.19368): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    7 (0.15604): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.14475): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.08077): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.07701): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.05066): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)

123: Spontaneous and Information-Triggered Segments of Series of Human Brain Electric Field Maps
    id = 48
    authors = Brandeis_D Horst_A Lehmann_D Ozaki_H Pal_I 
    2 (0.17486): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.07324): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

124: CAPAClTY AND INFORMATION EFFICIENCY OF A BRAIN-LIKE ASSOCIATIVE NET
    id = 907
    authors = Graham_B Willshaw_D 
    9 (0.29906): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.17110): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.12593): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.12217): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.05819): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

125: Counting Function Theorem for Multi-Layer Networks
    id = 747
    authors = Kowalczyk_A 
    10 (0.33670): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.26895): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.04313): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

126: Discrete Affine Wavelet Transforms .
    id = 386
    authors = Krishnaprasad_P Pati_Y 
    1 (0.19368): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.16733): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.16357): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.09582): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.05819): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.04313): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    38 (0.02055): 20 information  (0.10772) 6 function  (0.10772) 13 output  (0.10772) 3 neural  (0.07853) 10 networks  (0.04934) 1 learning  (0.04934) 7 figure  (0.04934) 24 performance  (0.04934) 21 problem  (0.04934) 23 hidden  (0.04934)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

127: Optical Implementation of a Self-Organizing Feature Extractor
    id = 529
    authors = Anderson_D Benkert_C Hebler_V Jang_J Montgomery_D Saffman_M 
    6 (0.31036): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.24261): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.14852): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.06571): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

128: Back Propagation Implementation .
    id = 425
    authors = McCartor_H 
    10 (0.24261): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.09959): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

129: Modeling Time Varying Systems Using Hidden Control Neural Architecture
    id = 305
    authors = Levin_E 
    8 (0.32917): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.20497): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.06195): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

130: Credit Assignment through Time: Alternatives to Backpropagation
    id = 709
    authors = Bengio_Y Frasconi_P 
    5 (0.36305): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.18615): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.11464): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.05819): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.04313): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

131: Planar Hidden Markov Modeling: from Speech to Optical Character Recognition
    id = 662
    authors = Levin_E Pieraccini_R 
    6 (0.31036): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.20497): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.09206): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    18 (0.01302): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

132: Explanation-based Neural Network Learning for Robot Control
    id = 608
    authors = Mitchell_T Thrun_S 
    10 (0.28025): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.19744): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.03184): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

133: A LAGRANGIAN FORMULATION FOR OPTICAL BACKPROPAGATION TRAINING IN KERR-TYPE OPTICAL NETWORKS
    id = 939
    authors = Behrman_E Cmz-Cabrara_A Skinner_S Steck_J 
    3 (0.39316): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.05442): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

134: Interposing an Ontogenic Model Between Genetic Algorithms and Neural Networks
    id = 585
    authors = Belew_R 
    5 (0.26519): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.21250): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.10335): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

135: Learning Aspect Graph Representations from View Sequences
    id = 216
    authors = Seibert_M Waxman_A 
    0 (0.18239): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.17110): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.06948): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    23 (0.02431): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

136: Predicting Weather Using a Genetic Memory: A Combination of Kanerva's Sparse Distributed Memory with Holland's Genetic Algorithms
    id = 240
    authors = Rogers_D 
    3 (0.21626): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.20497): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.15981): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.08077): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.01302): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    30 (0.00926): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    21 (0.00926): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)

137: A Bifurcation Theory Approach to the Programming of Periodic Attractors in Network Models of Olfactory Cortex
    id = 142
    authors = Baird_B 
    7 (0.31036): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.18615): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.07701): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)

138: A Parallel Analog CCD/CMOS Signal Processor
    id = 520
    authors = Neugebauer_C Yariv_A 
    3 (0.24637): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.15981): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

139: EXTRACTING RULES FROM ARTIFICIAL NEURAL NETWORKS WITH DISTRIBUTED REPRESENTATIONS
    id = 906
    authors = Thrun_S 
    19 (0.27272): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    5 (0.22003): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.17110): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

140: Synchronization, Oscillations, and l/f Noise in Networks of Spiking Neurons
    id = 779
    authors = Koch_C Olami_Z Stemmler_M Usher_M 
    6 (0.28401): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.16357): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.15604): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.04313): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.03184): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    0 (0.02808): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)

141: A Weighted Probabilistic Neural Network
    id = 565
    authors = Montana_D 
    1 (0.24261): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.23884): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.20121): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

142: Higher Order Recurrent Networks and Grammatical Inference
    id = 231
    authors = Chen_D Chen_H Giles_C Lee_Y Sun_G 
    8 (0.21626): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.14852): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.14099): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.13722): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.05819): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

143: Emergence of Global Structure from Local Associations
    id = 837
    authors = Ghiselli-Crippa_T Munro_P 
    4 (0.39316): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.22379): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.08453): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

144: A Second-Order Translation, Rotation and Scale Invariant Neural Network
    id = 327
    authors = Goggin_S Gustafson_K Johnson_K 
    8 (0.39692): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.21250): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.03184): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

145: Postal Address Block Location Using a Convolutional Locator Network
    id = 793
    authors = Platt_J Wolf_R 
    4 (0.19744): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.14852): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.08830): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    30 (0.00926): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

146: Networks with Learned Unit Response Functions
    id = 557
    authors = Moody_J Yarvin_N 
    9 (0.23508): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.20121): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.18615): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

147: Incremental Parsing by Modular Recurrent Connectionist Networks
    id = 229
    authors = Jain_A Waibel_A 
    8 (0.38563): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.26143): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

148: ON THE COMPUTATIONAL COMPLEXITY OF NETWORKS OF SPIKING NEURONS
    id = 866
    authors = Maass_W 
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.15981): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.13722): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.12593): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.11464): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

149: Applications of Neural Networks in Video Signal Processing
    id = 324
    authors = Pearson_J Spence_C Sverdlove_R 
    2 (0.36681): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.12593): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

150: Models Wanted: Must Fit Dimensions of Sleep and Dreaming
    id = 429
    authors = Hobson_J Mamelak_A Sutton_J 
    10 (0.22379): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.15981): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.14852): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.08453): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.07324): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

151: Discovering Viewpoint-Invariant Relationships That Characterize Objects
    id = 325
    authors = Hinton_G Zemel_R 
    0 (0.35552): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.18239): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.15981): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

152: Network Model of State-Dependent Sequencing
    id = 463
    authors = Hobson_J Mamelak_A Sutton_J 
    7 (0.23508): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.15604): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.14099): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.12593): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.07701): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.05066): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

153: Comparing Biases for Minimal Network Construction with Back-Propagation
    id = 110
    authors = Hanson_S Pratt_L 
    4 (0.23508): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.15228): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.14852): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    25 (0.01302): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)

154: Oscillation Onset in Neural Delayed Feedback .
    id = 303
    authors = Longtin_A 
    5 (0.33670): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.20873): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.09959): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.08453): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

155: Speaker Recognition Using Neural Tree Networks
    id = 829
    authors = Farrell_K Mammone_R 
    6 (0.25014): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.08453): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)

156: Exploiting Chaos to Control the Future
    id = 781
    authors = Chen_H Flake_G Lee_Y Sun_G 
    2 (0.46090): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.11464): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

157: A Comparison of Projection Pursuit and Neural Network Regression Modeling
    id = 571
    authors = Hwang_J Li_H Maechler_M Martin_R Schimert_J 
    9 (0.39316): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.06195): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

158: Training Connectionist Networks with Queries and Selective Sampling
    id = 253
    authors = Atlas_L Cohn_D Ladnet_R 
    4 (0.40445): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.08453): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.04690): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.03560): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

159: Using Genetic Algorithms to Improve Pattern Classification Performance .
    id = 393
    authors = Chang_E Lippmann_R 
    9 (0.20121): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.19744): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.15604): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

160: Statistical Mechanics of Learning in a Large Committee Machine
    id = 637
    authors = Hertz_J Schwarze_H 
    1 (0.25766): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.18239): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.12593): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.05442): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

161: An Optimization Method of Layered Neural Networks Based on the Modified Information Criterion
    id = 737
    authors = Watanabe_S 
    6 (0.31788): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.24637): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.04313): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

162: A MODEL OF THE HIPPOCAMPUS COMBINING SELF-ORGANIZATION AND ASSOCIATIVE MEMORY FUNCTION
    id = 853
    authors = Hasselmo_M Schnell_E 
    1 (0.34423): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.27272): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.11841): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    30 (0.00926): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

163: NEURAL NETWORK ENSEMBLES, CROSS VALIDATION, AND ACTIVE LEARNING
    id = 872
    authors = Krogh_A Vedelsby_J 
    6 (0.45338): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.15228): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

164: An Analog VLSI Saccadic Eye Movement System
    id = 773
    authors = Bisofberger_B Horiuchi_T Koch_C 
    1 (0.23132): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.20497): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

165: Combined Neural Networks for Time Series Analysis
    id = 728
    authors = Ginzburg_I Horn_D 
    1 (0.22379): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.20873): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.19744): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.11841): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

166: ALVINN: An Autonomous Land Vehicle in a Neural Network
    id = 125
    authors = Pomerleau_D 
    10 (0.34046): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.11088): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.09959): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.05066): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

167: A Passive Shared Element Analog Electrical Cochlea
    id = 166
    authors = Eisenberg_J Feld_D Lewis_E 
    2 (0.38187): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.14852): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.06948): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

168: OPTIMAL MOVEMENT PRIMITIVES
    id = 970
    authors = Sanger_T 
    1 (0.32165): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.15604): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

169: Input Reconstruction Reliability Estimation
    id = 607
    authors = Pomerleau_D 
    3 (0.24637): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.22379): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.20497): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.08830): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

170: A Practice Strategy for Robot Learning Control
    id = 614
    authors = Sanger_T 
    13 (0.31788): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.18615): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

171: Combining Neural and Symbolic Learning to Revise Probabilistic Rule Bases
    id = 586
    authors = Mahoney_J Mooney_R 
    0 (0.47219): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.10711): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

172: Linear Operator for Object Recognition
    id = 484
    authors = Basri_R Ullman_S 
    4 (0.22003): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.16357): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.15228): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

173: A Computer Modeling Approach to Understanding the Inferior Olive and Its Relationships to the Cerebellar Cortex in Rats
    id = 199
    authors = Bower_J Lee_M 
    2 (0.22379): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.18239): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.16733): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.02055): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

174: PREDICTING THE RISK OF COMPLICATIONS IN CORONARY ARTERY BYPASS OPERATIONS USING NEURAL NETWORKS
    id = 974
    authors = Kukolich_L Lippmann_R Shahian_D 
    3 (0.55876): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.20121): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

175: CAM Storage of Analog Patterns and Continuous Sequences with 3N 2 Weights .
    id = 298
    authors = Baird_B Eeckman_F 
    9 (0.28401): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.19744): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.08077): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.03560): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

176: Simple Spin Models for the Development of Ocular Dominance Columns and Iso-Orientation Patches
    id = 289
    authors = Cowen_J Friedman_A 
    4 (0.26519): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.24261): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.15228): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

177: Parameterising Feature Sensitive Cell Formation in Linsker Networks in the Auditory System
    id = 696
    authors = Bisset_D Walton_L 
    8 (0.30659): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.28401): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

178: Assessing the Quality of Learned Local Models
    id = 720
    authors = Atkeson_C Schaal_S 
    11 (0.29154): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.19368): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.04690): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

179: REINFORCEMENT LEARNING ALGORITHM FOR PARTIALLY OBSERVABLE MARKOV DECISION PROBLEMS
    id = 886
    authors = Jaakkola_T Jordan_M Singh_S 
    4 (0.39316): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.17110): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.08453): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.04690): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.03937): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

180: Development of Orientation and Ocular Dominance Columns in Infant Macaques
    id = 768
    authors = Blasdel_G Kiorpes_L Obermayer_K 
    8 (0.23508): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.22003): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.17110): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.12593): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

181: Bayesian Backpropagation over I-O Functions Rather Than Weights
    id = 725
    authors = Wolpert_D 
    3 (0.22003): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.18992): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.10711): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    6 (0.09582): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.06195): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

182: A Neural Network Classifier Based on Coding Theory
    id = 17
    authors = Chiueh_T Goodman_R 
    0 (0.48725): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.11841): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.07324): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

183: Use of Multi-Layered Networks for Coding Speech with Phonetic Features
    id = 115
    authors = Bengio_Y Cardin_R Cosi_P De-Mori_R 
    0 (0.22003): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.14099): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

184: Modeling Consistency in a Speaker Independent Continuous Speech Recognition System
    id = 656
    authors = Abrash_V Cohen_M Franco_H Konig_Y Morgan_N Wooters_C 
    11 (0.25014): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.14852): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.14099): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.04313): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

185: A Note on Learning Vector Quantization
    id = 600
    authors = Ballard_D de-Sa_V 
    7 (0.34423): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.22755): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.08830): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.05066): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

186: Phasor Neural Networks
    id = 60
    authors = Noest_A 
    6 (0.37057): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.26143): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

187: ASSOCIATIVE DECORRELATION DYNAMICS: A THEORY OF SELF-ORGANIZATION AND OPTIMIZATION IN FEEDBACK NETWORKS
    id = 958
    authors = Dong_D 
    7 (0.34046): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.14852): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.13722): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

188: Generalization Performance in PARSEC--A Structured Connectionist Parsing Architecture
    id = 454
    authors = Jain_A 
    0 (0.28777): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.12217): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.07701): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

189: Computational Efficiency: A Common Organizing Principle for Parallel Computer Maps and Brain Maps?
    id = 192
    authors = Bower_J Nelson_M 
    6 (0.34423): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.08077): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.06195): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

190: Tonal Music as a Componential Code: Learning Temporal Relationships between and within Pitch and Timing Components
    id = 835
    authors = Stevens_C Wiles_J 
    3 (0.37057): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.20873): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    24 (0.15228): 9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

191: On Line Estimation of Optimal Control Sequences: HJB Estimators
    id = 612
    authors = Peterson_J 
    10 (0.31412): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.13722): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.11464): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.05442): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

192: A Self-Organizing Multiple-View Representation of 3D Objects
    id = 218
    authors = Btilthoff_H Edelman_S Weinshall_D 
    12 (0.20497): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.15228): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.11464): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.09206): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.07701): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)

193: Closed-Form Inversion of Backpropagation Networks
    id = 403
    authors = Rossen_M 
    7 (0.45338): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.07701): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.06195): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

194: Context-Dependent Multiple Distribution Phonetic Modeling with MLPs
    id = 652
    authors = Abrash_V Cohen_M Franco_H Morgan_N Rumelhart_D 
    1 (0.35552): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.08830): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.03560): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

195: Holographic Recurrent Networks
    id = 577
    authors = Plate_T 
    1 (0.34423): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.30283): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.07324): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.05442): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

196: Reinforcement Learning in Markovian and Non-Markovian Environments . . .
    id = 353
    authors = Schmidhuber_J 
    4 (0.25390): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.20497): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.09959): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.08453): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

197: Speech Recognition: Statistical and Neural Information Processing Approaches
    id = 183
    authors = Bridle_J 
    6 (0.38939): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.18992): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.06571): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

198: Active Exploration in Dynamic Environments
    id = 493
    authors = Moller_K Thrun_S 
    3 (0.21250): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.20873): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.09959): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.05819): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    18 (0.00926): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

199: A Dynamical Model of Priming and Repetition Blindness
    id = 680
    authors = Bavelier_D Jordan_M 
    2 (0.27648): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.25390): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.05442): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    9 (0.04313): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.02055): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

200: Connection Topology and Dynamics in Lateral Inhibition Networks
    id = 299
    authors = Marcus_C Waugh_F Westervelt_R 
    3 (0.23132): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.22755): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.20121): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.05819): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.03937): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

201: Single Neuron Model: Response to Weak Modulation in the Presence of Noise
    id = 437
    authors = Bulsara_A Jacobs_E Moss_Moss 
    2 (0.21626): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.17486): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.16733): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.07324): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

202: Optimization by Mean Field Annealing
    id = 100
    authors = Bilbro_G Mann_R Miller_T Snyder_W VandenBout_D White_M 
    8 (0.26143): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.19744): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.18615): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

203: Incrementally Learning Time-varying Half-planes
    id = 541
    authors = Kuh_A Petsche_T Rivest_R 
    5 (0.21626): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.20497): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.16357): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

204: Learning Curves: Asymptotic Values and Rate of Convergence
    id = 741
    authors = Cortes_C Denker_J Jackel_L Solla_S Vapnik_V 
    4 (0.24637): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    25 (0.21626): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

205: Schema for Motor Control Utilizing a Network Model of the Cerebellum
    id = 38
    authors = Houk_J 
    1 (0.23132): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.15228): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.13722): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.02055): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

206: Retinogeniculate Development: The Role of Competition and Correlated Retinal Activity
    id = 440
    authors = Keesing_R Shatz_C Stork_D 
    3 (0.38563): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.06948): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.05819): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    5 (0.03560): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

207: AN ALTERNATIVE MODEL FOR MIXTURES OF EXPERTS
    id = 922
    authors = Hinton_G Jordan_M Xu_L 
    11 (0.23132): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.17486): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

208: Neural Network Implementation of Admission Control ..
    id = 352
    authors = Guyon_I Milito_R Solla_S 
    8 (0.28025): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.15604): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.14099): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    20 (0.05442): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

209: Using Neural Networks to Improve Cochlear Implant Speech Perception
    id = 81
    authors = Tenorio_M 
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.20873): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.19744): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.09959): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.03937): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

210: A Method for the Associative Storage of Analog Vectors
    id = 256
    authors = Abu-Mostafa_Y Atiya_A 
    7 (0.31036): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.19368): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.09206): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.03184): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

211: Operators and curried functions: Training and analysis of simple recurrent networks
    id = 468
    authors = Bloesch_A Wiles_J 
    0 (0.38187): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.27272): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

212: BAYESIAN QUERY CONSTRUCTION FOR NEURAL NETWORK MODELS
    id = 898
    authors = Kindermann_J Paass_G 
    4 (0.24637): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.21626): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.17110): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

213: Fixed Point Analysis for Recurrent Networks
    id = 107
    authors = Ballard_D Oftaway_M Simard_P 
    0 (0.35928): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.16357): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.13346): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.10711): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

214: Speech Production Using A Neural Network with a Cooperative Learning Mechanism
    id = 116
    authors = Komura_M Tanaka_A 
    9 (0.25766): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.21626): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.17486): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.11088): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

215: FINANCIAL APPLICATIONS OF LEARNING FROM HINTS
    id = 894
    authors = Abu-Mostafa_Y 
    3 (0.28401): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.21250): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.02431): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

216: A NOVEL REINFORCEMENT MODEL OF BIRDSONG VOCALIZATION LEARNING
    id = 856
    authors = Doya_K Sejnowski_T 
    0 (0.28401): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.23132): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.03184): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

217: A Systematic Study of the Input/Output Properties of a 2 Compartment Model Neuron With Active Membranes
    id = 203
    authors = Rhodes_P 
    6 (0.33294): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.25390): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.05819): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    25 (0.01679): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

218: Image Segmentation with Networks of Variable Scales
    id = 487
    authors = Ben_J Graf_H Nohl_C 
    13 (0.23508): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.22003): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.12970): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.03184): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

219: A 'Neural' Network that Learns to Play Backgammon
    id = 82
    authors = Sejnowski_T Tesauro_G 
    0 (0.33670): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.07324): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

220: WATTLE: A Trainable Gain Analogue VLSI Neural Network
    id = 809
    authors = Coggins_R Jabri_M 
    0 (0.30659): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.18992): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.12970): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.12217): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

221: Mixtures of Controllers for Jump Linear and Non-Linear Plants
    id = 790
    authors = Cacciatore_T Nowlan_S 
    10 (0.31036): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.06195): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

222: Merging Constrained Optimisation with Deterministic Annealing to "Solve" Combinatorially Hard Problems
    id = 554
    authors = Stolorz_P 
    5 (0.27272): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.21250): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

223: A Neural Network Approach for Three-Dimensional Object Recognition
    id = 326
    authors = Tresp_V 
    12 (0.26519): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.14475): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    31 (0.14099): 17 state  (0.15178) 1 learning  (0.11685) 14 number  (0.09938) 6 function  (0.08192) 7 figure  (0.08192) 24 performance  (0.08192) 2 model  (0.02952) 9 set  (0.02952) 13 output  (0.02952) 5 data  (0.02952)
    3 (0.11464): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)

224: Event-Driven Simulation of Networks of Spiking Neurons
    id = 816
    authors = Watts_L 
    0 (0.28777): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.23884): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    29 (0.10711): 15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029)
    2 (0.08830): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.03937): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

225: Filter Selection Model for Generating Visual Motion Signals
    id = 618
    authors = Nowlan_S Sejnowski_T 
    4 (0.35176): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.11464): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

226: Structural and Behavioral Evolution of Recurrent Networks
    id = 711
    authors = Angeline_P Pollack_J Saunders_G 
    4 (0.30283): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.20121): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.13346): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

227: Generalization Abilities of Cascade Network Architecture
    id = 596
    authors = Littmann_E Ritter_H 
    8 (0.22379): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.15981): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.12593): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.09959): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.05442): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

228: Structured Machine Learning for "Soft" Classification with Smoothing Spline ANOVA and Stacked Tuning, Testing, and Evaluation
    id = 752
    authors = Gu_C Klein_B Klein_R Wahba_G Wang_Y 
    6 (0.35928): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.18239): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.16733): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

229: Information Theoretic Analysis of Connection Structure from Spike Trains
    id = 636
    authors = Matsumoto_K Nakashima_M Shiono_S Yamada_S 
    2 (0.31036): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.28025): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.14099): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.01302): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

230: Statistical Reliability of a Blowfly Movement-Sensitive Neuron
    id = 432
    authors = Bialek_W de-Ruyter-van-Steveninck_R 
    1 (0.38563): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.14852): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

231: Optimal Unsupervised Motor Learning Predicts the Internal Representation of Barn Owl Head Movements
    id = 777
    authors = Sanger_T 
    7 (0.32917): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.11841): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.10335): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.02808): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

232: Some Estimates of Necessary Number of Connections and Hidden Units for Feed-Forward Networks
    id = 651
    authors = Kowalczyk_A 
    3 (0.29906): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.19744): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.12217): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

233: Weight Space Probability Densities in Stochastic Learning: II. Transients and Basin Hopping Times
    id = 635
    authors = Leen_T Orr_G 
    1 (0.26143): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.22755): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

234: Dynamics of Learning in Recurrent Feature-Discovery Networks .
    id = 295
    authors = Leen_T 
    0 (0.32917): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.23132): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

235: USING VOICE TRANSFORMATIONS TO CREATE ADDITIONAL TRAINING TALKERS FOR WORD SPOTTING
    id = 952
    authors = Chang_E Lippmann_R 
    9 (0.29530): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.24261): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    18 (0.06571): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

236: Simulation and Measurement of the Electric Fields Generated by Weakly Electric Fish
    id = 139
    authors = Assad_C Bower_J Nelson_M Rasnow_B 
    10 (0.37434): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.20873): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

237: Non-Linear Dimensionality Reduction
    id = 644
    authors = Cottrell_G DeMers_D 
    6 (0.31036): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.27648): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.06195): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

238: Learning Time-varying Concepts .
    id = 310
    authors = Kuh_A Petsche_T Rivest_R 
    19 (0.21250): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    23 (0.00926): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

239: High Order Neural Networks for Efficient Associative Memory Design
    id = 24
    authors = Dreyfus_G Guyon_I Nadal_J Personnaz_L 
    3 (0.22755): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.22755): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.11841): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.03937): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

240: ART2/BP Architecture for Adaptive Estimation of Dynamic Processes
    id = 308
    authors = Sorheim_E 
    8 (0.26519): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.24261): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.20497): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.04313): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

241: Fault Diagnosis of Antenna Pointing Systems Using Hybrid Neural Network and Signal Processing Models
    id = 510
    authors = Mellstrom_J Smyth_P 
    2 (0.41574): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.20121): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.07324): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

242: An Analog VLSI Chip for Radial Basis Functions
    id = 666
    authors = Anderson_J Kirk_D Platt_J 
    1 (0.23508): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.14852): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.12217): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

243: Resolving Motion Ambiguities
    id = 822
    authors = Diamantaras_K Geiger_D 
    3 (0.18992): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.17110): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.16357): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

244: Temporal Representations in a Connectionist Speech System
    id = 117
    authors = Smythe_E 
    11 (0.41574): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.14099): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

245: Single-iteration Threshold Hamming Networks
    id = 642
    authors = Meilijson_I Ruppin_E Sipper_M 
    11 (0.27272): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.15604): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.14475): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.04690): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

246: On Properties of Networks of Neuron-Like Elements
    id = 4
    authors = Baldi_P Venkatesh_S 
    1 (0.43456): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

247: Adaptive Development of Connectionist Decoders for Complex Error-Correcting Codes
    id = 513
    authors = Blaum_M Gish_S 
    8 (0.27272): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.14099): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.13722): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.07701): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.06948): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.03184): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

248: Supervised Learning with Growing Cell Structures
    id = 732
    authors = Fritzke_B 
    7 (0.47596): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.05442): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

249: Analog Cochlear Model for Multiresolution Speech Analysis
    id = 654
    authors = Andreou_A Goldstein_M Liu_W 
    0 (0.41574): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.16357): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    30 (0.03184): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

250: Non-Linear Statistical Analysis and Self-Organizing Hebbian Networks
    id = 751
    authors = Prtigel-Bennett_A Shapiro_J 
    1 (0.38187): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.15604): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

251: A Boundary Hunting Radial Basis Function Classifier which Allocates Centers Constructively
    id = 590
    authors = Chang_E Lippmann_R 
    9 (0.28025): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.14475): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.08077): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.03560): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

252: EMPATH: Face, Emotion, and Gender Recognition Using Holons ..
    id = 362
    authors = Cottrell_G Metcalfe_J 
    8 (0.23508): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.16357): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.12970): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.06948): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.05819): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

253: Connectionist Models for Auditory Scene Analysis
    id = 833
    authors = Duda_R 
    10 (0.38187): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.14099): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

254: VLSI Phase Locking Architectures for Feature Linking in Multiple Target Tracking Systems
    id = 808
    authors = Andreou_A Edwards_T 
    2 (0.30659): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.18615): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.17486): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.03937): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)

255: Neural Network Definitions of Highly Predictable Protein Secondary Structure Classes
    id = 801
    authors = Farber_R Lapedes_A Steeg_E 
    6 (0.26519): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.26143): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.09582): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

256: Order Reduction for Dynamical Systems Describing the Behavior of Complex Neurons .
    id = 293
    authors = Abbott_L Kepler_T Marder_E 
    0 (0.46090): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.09206): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

257: Learning Fuzzy Rule-Based Neural Networks for Control
    id = 616
    authors = Goodman_R Higgins_C 
    8 (0.41574): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.18615): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.08830): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    18 (0.00926): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

258: An Attractor Neural Network Model of Recall and Recognition .
    id = 373
    authors = Ruppin_E Yeshurun_Y 
    4 (0.22379): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.18239): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.09582): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.03184): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

259: The Role of MT Neuron Receptive Field Surrounds in Computing Object Shape from Velocity Fields
    id = 821
    authors = Albright_T Buracas_G 
    7 (0.32165): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.17110): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.08830): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.03937): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

260: On the K-Winners-Take-All Network
    id = 163
    authors = Abu-Mostafa_Y Erlanson_R Majani_E 
    2 (0.26895): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.20873): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.14475): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

261: Combined Neural Network and Rule-Based Framework for Probabilistic Pattern Recognition and Discovery
    id = 483
    authors = Chellappa_R Goodman_R Greenspan_H 
    10 (0.33294): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.23884): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.14099): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

262: Computing with Arrays of Bell-Shaped and Sigrnoid Functions .
    id = 385
    authors = Baldi_P 
    22 (0.34799): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.08830): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    18 (0.04690): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

263: Further Explorations in Visually-Guided Reaching: Making MURPHY Smarter
    id = 130
    authors = Mel_B 
    9 (0.17863): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.16357): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.12970): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.12593): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

264: Iterative Construction of Sparse Polynomial Approximations
    id = 559
    authors = Matheus_C Sanger_T Sutton_R 
    1 (0.23132): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.15981): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)

265: Mathematical Analysis of Learning Behavior of Neuronal Models
    id = 16
    authors = Cheung_J Omidvar_M 
    8 (0.20497): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.19368): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.15981): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.11841): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.08830): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

266: Grouping Contours by Iterated Pairing Network .
    id = 330
    authors = Shashua_A Ullman_S 
    1 (0.43079): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.20497): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.04313): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

267: Information through a Spiking Neuron
    id = 994
    authors = Stevens_C Zador_A 
    5 (0.30283): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.25390): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.09582): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.09582): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

268: A Network for Image Segmentation Using Color
    id = 124
    authors = Hurlbert_A Poggio_T 
    3 (0.23508): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.05066): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

269: Recurrent Networks and NARMA Modeling
    id = 465
    authors = Atlas_L Connor_J Martin_D 
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.16357): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.14475): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.12970): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)

270: Polynomial Uniform Convergence of Relative Frequencies to Probabilities
    id = 539
    authors = Bertoni_A Campadelli_P Morpurgo_A Panizza_S 
    4 (0.33670): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.09959): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.03560): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    22 (0.00926): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

271: Neural Approach for TV Image Compression Using a Hopfield Type Network
    id = 120
    authors = Naillon_M Theeten_J 
    10 (0.20873): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.17486): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.03184): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

272: A Self-Learning Neural Network
    id = 178
    authors = Hartstein_A Koch_R 
    0 (0.31036): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.03560): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    30 (0.02055): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    44 (0.00926): 14 number  (0.09258) 8 time  (0.03781) 7 figure  (0.03781) 6 function  (0.03781) 10 networks  (0.03781) 9 set  (0.03781) 11 training  (0.03781) 1 learning  (0.03781) 2 model  (0.03781) 0 network  (0.03781)
    11 (0.00549): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)

273: RECURRENT NETWORKS: SECOND ORDER PROPERTIES AND PRUNING
    id = 927
    authors = Hansen_L Pedersen_M 
    2 (0.22379): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.22003): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.14099): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.08077): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

274: Neural Network Implementation Approaches for the Connection Machine
    id = 12
    authors = Brown_N 
    7 (0.29154): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.26143): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

275: AN INTEGRATED ARCHITECTURE OF ADAPTIVE NEURAL NETWORK CONTROL FOR DYNAMIC SYSTEMS
    id = 971
    authors = Ke_L McVey_B Tokar_R 
    1 (0.28025): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.24261): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.03937): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

276: A Hybrid Linear/Nonlinear Approach to Channel Equilization Problems
    id = 655
    authors = Lee_W Pearson_J 
    9 (0.27648): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.19368): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.07324): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.05442): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

277: AN ACTOR/CRITIC ALGORITHM THAT IS EQUIVALENT TO Q-LEARNING
    id = 893
    authors = Barto_A Crites_R 
    1 (0.57381): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.06195): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

278: Learning Representations by Recirculation
    id = 37
    authors = Hinton_G McClelland_J 
    9 (0.41950): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.27272): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.03937): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

279: Forward Dynamics Modeling of Speech Motor Control Using Physiological Data
    id = 452
    authors = Hirayama_M Jordan_M Kawato_M Vatikiotis-Bateson_E 
    0 (0.29906): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.14852): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.12593): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.06195): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.05442): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

280: Performance of a Stochastic Learning Microchip
    id = 176
    authors = Allen_R Alspector_J Gupta_B 
    9 (0.25014): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.23508): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    36 (0.08830): 8 time  (0.11651) 11 training  (0.09167) 5 data  (0.09167) 13 output  (0.06683) 18 results  (0.06683) 9 set  (0.06683) 10 networks  (0.06683) 23 hidden  (0.06683) 15 system  (0.04199) 7 figure  (0.04199)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.03184): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

281: Rapidly Adapting Artificial Neural Networks for Autonomous Navigation .
    id = 343
    authors = Pomerleau_D 
    8 (0.34423): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.27272): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

282: Digital-Analog Hybrid Synapse Chips for Electronic Neural Networks
    id = 278
    authors = Duong_T Moopenn_A Thakoor_A 
    6 (0.26519): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.21250): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.20497): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

283: Spherical Units as Dynamic Consequential Regions .
    id = 375
    authors = Gluck_M Hanson_S 
    12 (0.23132): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.20121): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.12970): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.09582): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.08077): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.03937): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

284: Supervised Learning of Probability Distributions by Neural Networks
    id = 5
    authors = Baum_E Wilczek_F 
    4 (0.25766): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.15981): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

285: Training Multilayer Perceptrons with the Extended Kalman Algorithm
    id = 105
    authors = Singhal_S Wu_L 
    11 (0.39692): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.26519): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

286: Neural Network Analysis of Event Related Potentials and Electroencephalogram Predicts Vigilance
    id = 508
    authors = Lytton_W Sejnowski_T Venturini_R 
    1 (0.29906): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.24637): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.09582): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.03184): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

287: The Power of Amnesia
    id = 722
    authors = Ron_D Singer_Y Tishby_N 
    11 (0.28777): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.16357): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.11841): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

288: Collective Oscillations in the Visual Cortex
    id = 194
    authors = Holmes_P Kammen_D Koch_C 
    0 (0.25766): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.20497): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.13722): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.13346): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

289: Second Order Properties of Error Surfaces .
    id = 410
    authors = Kanter_I LeCun_Y Solla_S 
    0 (0.27272): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.18239): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.15981): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.13722): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

290: The Recurrent Cascade-Correlation Architecture .
    id = 311
    authors = Fahlman_S 
    3 (0.26519): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.21250): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.17486): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.05066): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

291: Unsupervised Parallel Feature Extraction from First Principles
    id = 717
    authors = Lenz_R Osterberg_M 
    6 (0.52112): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.18239): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.03184): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.01679): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

292: Extended Regularization Methods for Nonconvergent Model Selections
    id = 601
    authors = Finnoff_W Hergert_Hergert Zimmermann_H 
    2 (0.32917): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.23884): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.17110): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

293: Learning to Control an Unstable System with Forward Modeling
    id = 224
    authors = Jacobs_R Jordan_M 
    1 (0.28401): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.12970): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.09206): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

294: A NON-LINEAR INFORMATION MAXIMISATION ALGORITHM THAT PERFORMS BLIND SEPARATION
    id = 901
    authors = Bell_A Sejnowski_T 
    2 (0.32917): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.11088): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.05442): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

295: A Comparison of Dynamic Reposing and Tangent Distance for Drug Activity Prediction
    id = 727
    authors = Dietterich_T Jain_A Lathrop_R Lozano-Perez_T 
    11 (0.26895): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.13346): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.12593): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.06195): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    37 (0.00926): 4 input  (0.13303) 19 units  (0.13303) 8 time  (0.07631) 15 system  (0.04794) 13 output  (0.04794) 0 network  (0.04794) 9 set  (0.04794) 10 networks  (0.04794) 21 problem  (0.04794) 20 information  (0.04794)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

296: Analog Neural Networks as Decoders .
    id = 365
    authors = Abu-Mostafa_Y Erlanson_R 
    17 (0.20497): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    10 (0.17486): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.14475): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.09582): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.05442): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

297: Direct Memory Access Using Two Cues .
    id = 372
    authors = Bain_J Dennis_S Humphreys_M Wiles_J 
    2 (0.28025): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.17486): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.14099): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.11841): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.02808): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

298: DIFFUSION OF CREDIT IN MARKOVIAN MODELS
    id = 912
    authors = Bengio_Y Frasconi_P 
    21 (0.25766): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    3 (0.18615): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.15228): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.13346): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    17 (0.02808): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

299: Time Trials on Second-Order and Variable-Learning-Rate Algorithms .
    id = 418
    authors = Rohwer_R 
    7 (0.25014): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.17863): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.14475): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.08830): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.02055): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

300: Convergence of a Neural Network Classifier .
    id = 399
    authors = Baras_J LaVigna_A 
    5 (0.57005): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

301: Synchronization and Grammatical Inference in an Oscillating Elman Net
    id = 602
    authors = Baird_B Eeckman_F Troyer_T 
    10 (0.22379): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.14099): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    26 (0.14099): 3 neural  (0.21238) 8 time  (0.12636) 6 function  (0.08335) 12 algorithm  (0.04895) 4 input  (0.04895) 22 models  (0.04895) 14 number  (0.04034) 23 hidden  (0.04034) 17 state  (0.04034) 7 figure  (0.03174)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.03560): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

302: A SILICON AXON
    id = 935
    authors = Coggins_R Diorio_C Hasler_P Mead_C Minch_B 
    0 (0.27272): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.25014): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.13346): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.10335): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

303: VLSI Implementations of Learning and Memory Systems ..
    id = 420
    authors = Holler_M 
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.20121): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

304: A COMPARISON OF DISCRETE-TIME OPERATOR MODELS FOR NONLINEAR SYSTEM IDENTIFICATION
    id = 953
    authors = Back_A Tsoi_A 
    6 (0.35176): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.15604): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.12217): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    32 (0.05442): 14 number  (0.22966) 4 input  (0.08488) 12 algorithm  (0.08488) 13 output  (0.04869) 16 error  (0.04869) 2 model  (0.04869) 5 data  (0.04869) 24 performance  (0.04869) 20 information  (0.04869) 3 neural  (0.03059)
    14 (0.04690): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

305: Analog VLSI Implementation of Gradient Descent
    id = 669
    authors = Barr_A Fleischer_K Kerns_D Kirk_D 
    0 (0.37434): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.14099): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.12217): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.03560): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

306: VLSI Implementation of a High-Capacity Neural Network Associative Memory
    id = 281
    authors = Chiueh_T Goodman_R 
    14 (0.15981): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.14099): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.13346): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.04313): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

307: Multi-State Time Delay Neural Networks for Continuous Speech Recognition
    id = 445
    authors = Haffner_P Waibel_A 
    10 (0.31036): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.22379): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.10711): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.05442): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

308: Probabilistic Characterization of Neural Model Computations
    id = 33
    authors = Golden_R 
    2 (0.22755): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.21626): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.17863): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.13346): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

309: AN INPUT OUTPUT HMM ARCHITECTURE
    id = 896
    authors = Bengio_Y Frasconi_P 
    11 (0.29154): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.17863): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.17863): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.11841): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

310: An Analog VLSI Chip for Finding Edges from Zero-crossings .
    id = 339
    authors = Bair_W Koch_C 
    8 (0.22379): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    27 (0.22003): 19 units  (0.11722) 22 models  (0.09875) 18 results  (0.09875) 21 problem  (0.08951) 16 error  (0.08027) 20 information  (0.08027) 17 state  (0.06180) 23 hidden  (0.06180) 14 number  (0.05256) 5 data  (0.04333)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.14099): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

311: Q-Learning with Hidden-Unit Restarting
    id = 583
    authors = Anderson_C 
    9 (0.26895): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.16357): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    8 (0.12593): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.08453): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

312: On Tropistic Processing and Its Applications
    id = 27
    authors = Fernandez_M 
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.19744): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.11088): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.10335): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.08453): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.07701): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

313: Performance Comparisons Between Backpropagation Networks and Classification Trees on Three Real-World Applications
    id = 260
    authors = Atlas_L Barnard_E Cole_R Connor_J El-Sharkawi_M Marks_R Muthusamy_Y 
    5 (0.28025): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.26143): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.11088): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.07701): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

314: A Connectionist Symbol Manipulator that Discovers the Structure of Context-Free Languages
    id = 678
    authors = Das_S Mozer_M 
    3 (0.32917): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.22379): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.12593): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

315: A Local Algorithm to Learn Trajectories with Stochastic Neural Networks
    id = 710
    authors = Movellan_J 
    2 (0.25014): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.24261): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.14099): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.10711): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

316: Synaptic Weight Noise During MLP Learning Enhances Fault-Tolerance, Generalization and Learning Trajectory
    id = 633
    authors = Edwards_P Murray_A 
    10 (0.29154): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.22379): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.12970): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    21 (0.01302): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

317: Sequential Decision Problems and Neural Networks
    id = 268
    authors = Barto_A Sutton_R Watkins_C 
    13 (0.18992): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.15228): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

318: Analyzing the Energy Landscapes of Distributed Winner-Take-All Networks
    id = 162
    authors = Touretzky_D 
    1 (0.39316): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.18615): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

319: A Hodgkin-Huxley Type Neuron Model That Learns Slow Non-Spike Oscillation
    id = 771
    authors = Doya_K Rowat_P Selverston_A 
    5 (0.20497): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.19368): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.05819): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

320: Intersecting Regions: The Key to Combinatorial Structure in Hidden Unit Space
    id = 576
    authors = Ollila_M Wiles_J 
    1 (0.25390): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.17486): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.15981): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

321: Capacity for Patterns and Sequences in Kanerva's SDM as Compared to Other Associative Memory Models
    id = 43
    authors = Keeler_J 
    0 (0.23132): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.18239): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.13346): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.10711): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

322: Green's Function Method for Fast On-line Learning Algorithm of Recurrent Neural Networks
    id = 469
    authors = Chen_H Lee_Y Sun_G 
    0 (0.38939): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.36305): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.00549): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

323: A Knowledge-Based Model of Geometry Learning
    id = 681
    authors = Lehrer_R Towell_G 
    3 (0.33294): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.23508): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.15228): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

324: On Learning mu-Perceptron Networks with Binary Weights
    id = 645
    authors = Golea_M Hancock_T Marchand_M 
    11 (0.37434): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.26143): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

325: Nets with Unreliable Hidden Nodes Learn Error-Correcting Codes
    id = 584
    authors = Judd_S Munro_P 
    6 (0.38939): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.21626): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.09582): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.04690): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

326: BOOSTING THE PERFORMANCE OF RBF NETWORKS WITH DYNAMIC DECAY ADJUSTMENT
    id = 908
    authors = Berthold_M Diamond_J 
    2 (0.37434): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.28777): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.06571): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.04690): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.00549): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

327: DIRECT MULTI-STEP TIME SERIES PREDICTION USING TD(LAMBDA)
    id = 933
    authors = Kazlas_P Weigend_A 
    9 (0.42703): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.09959): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.02431): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

328: INSTANCE-BASED STATE IDENTIFICATION FOR REINFORCEMENT LEARNING
    id = 890
    authors = McCallum_R 
    6 (0.25390): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.23132): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.12593): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.08830): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

329: Implications of Recursive Distributed Representations
    id = 150
    authors = Pollack_J 
    4 (0.25390): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.23508): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.17863): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

330: Observability of Neural Network Behavior
    id = 757
    authors = Botelho_F Garzon_M 
    11 (0.38563): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.26519): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.06195): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    26 (0.00926): 3 neural  (0.21238) 8 time  (0.12636) 6 function  (0.08335) 12 algorithm  (0.04895) 4 input  (0.04895) 22 models  (0.04895) 14 number  (0.04034) 23 hidden  (0.04034) 17 state  (0.04034) 7 figure  (0.03174)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

331: Multi-Digit Recognition Using a Space Displacement Neural Network
    id = 488
    authors = Burges_C Denker_J LeCun_Y Matan_O 
    1 (0.18992): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.17486): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.15604): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.06571): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

332: Fast Non-Linear Dimension Reduction
    id = 719
    authors = Kambhatla_N Leen_T 
    23 (0.36305): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

333: e-Entropy and the Complexity of Feedforward Neural Networks .
    id = 414
    authors = Williamson_R 
    1 (0.40445): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.17110): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.13346): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.05442): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

334: ON-LINE LEARNING OF DICHOTOMIES
    id = 881
    authors = Barkai_N Seung_H 
    11 (0.28401): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.17110): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.12593): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.08453): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

335: Evaluation of Adaptive Mixtures of Competing Experts ..
    id = 390
    authors = Hinton_G Nowlan_S 
    2 (0.29906): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.13346): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)

336: A Segment-based Automatic Language Identification System
    id = 458
    authors = Cole_R Muthusamy_Y 
    4 (0.29906): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.23884): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.16733): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.04690): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.02431): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

337: A Framework for the Cooperation of Learning Algorithms .
    id = 391
    authors = Bottou_L Gallinari_P 
    5 (0.20121): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.18239): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.16357): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

338: Central and Pairwise Data Clustering by Competitive Neural Networks
    id = 713
    authors = Buhmann_J Hofmann_T 
    9 (0.31412): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.30283): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.13346): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

339: ANALYSIS OF UNSTANDARDIZED CONTRIBUTIONS IN CROSS CONNECTED NETWORKS
    id = 918
    authors = Oshima-Takane_Y Shultz_T Takane_Y 
    4 (0.32917): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.28025): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

340: A Computer Simulation of Cerebral Neocortex: Computational Capabilities of Nonlinear Neural Networks
    id = 74
    authors = Donoghue_J Singer_A 
    6 (0.26519): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.18239): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.17110): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.07701): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

341: Solvable Models of Artificial Neural Networks
    id = 753
    authors = Watanabe_S 
    0 (0.23508): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.21250): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.04690): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.03184): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    25 (0.01302): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

342: Signature Verification Using a "Siamese" Time Delay Neural Network
    id = 792
    authors = Bromley_J Guyon_I LeCun_Y Sackinger_E Shah_R 
    0 (0.24261): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.24261): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.18239): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

343: Shaping the State Space Landscape in Recurrent Networks .
    id = 300
    authors = Raysz_J Simard_P Victorri_B 
    3 (0.32541): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.15604): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.12970): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

344: Neuronal Group Selection Theory: A Grounding in Robotics
    id = 222
    authors = Donnett_J Smithers_T 
    4 (0.38563): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.27648): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.03937): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    20 (0.02431): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

345: A Recurrent Neural Network Model of Velocity Storage in the Vestibulo-Ocular Reflex
    id = 290
    authors = Anastasio_T 
    1 (0.35552): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.14475): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.11841): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.03937): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

346: Neural Networks that Learn to Discriminate Similar Kanji Characters
    id = 128
    authors = Mori_Y Yokosawa_K 
    12 (0.34423): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.09959): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

347: ALCOVE: A Connectionist Model of Human Category Learning .
    id = 374
    authors = Kruschke_J 
    9 (0.25390): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.07324): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.07324): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    33 (0.05066): 23 hidden  (0.10685) 16 error  (0.10685) 4 input  (0.08807) 19 units  (0.08807) 9 set  (0.06929) 12 algorithm  (0.06929) 11 training  (0.05052) 5 data  (0.05052) 6 function  (0.03174) 2 model  (0.03174)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)

348: Generation of Internal Representation by a-Transformation
    id = 734
    authors = Kamimura_R 
    5 (0.32917): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.11464): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.08830): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.04313): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.03937): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.03560): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)

349: A RIGOROUS ANALYSIS OF LINSKER-TYPE HEBBIAN LEARNING
    id = 883
    authors = Feng_J Pan_H Roychowdhury_V 
    3 (0.33294): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.24261): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.06948): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

350: A Self-organizing Associative Memory System for Control Applications
    id = 225
    authors = Hormel_M 
    3 (0.19368): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    20 (0.18239): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    4 (0.13722): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.08453): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.06948): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    19 (0.03937): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)

351: Planning with an Adaptive World Model .
    id = 346
    authors = Linden_A Moller_K Thrun_S 
    6 (0.20497): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.18615): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.12593): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.04690): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    23 (0.01302): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

352: Automatic Capacity Tuning of Very Large VC-Dimension Classifiers
    id = 591
    authors = Boser_B Guyon_I Vapnik_V 
    1 (0.27648): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.17863): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

353: A Neural Network for Real-Time Signal Processing
    id = 215
    authors = Malkoff_D 
    12 (0.19368): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.17486): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.08077): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.08077): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

354: Learning Control Under Extreme Uncertainty
    id = 613
    authors = Gullapalli_V 
    7 (0.28025): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.18992): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.17110): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

355: Analyzing Cross-Connected Networks
    id = 839
    authors = Elman_J Shultz_T 
    6 (0.18239): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.15604): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.15604): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.10711): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

356: Maximum Likelihood Competitive Learning
    id = 254
    authors = Nowlan_S 
    3 (0.25390): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.17486): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.15604): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

357: Neural Network Exploration Using Optimal Experiment Design
    id = 785
    authors = Cohn_D 
    3 (0.22379): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.22379): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.19368): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.06948): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

358: Oscillatory Model of Short Term Memory
    id = 444
    authors = Horn_D Usher_M 
    7 (0.29154): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.12217): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

359: HARMONET: A Neural Net for Harmonizing Chorales in the Style of J.S. Bach
    id = 461
    authors = Feulner_J Hild_H Menzel_W 
    6 (0.18615): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

360: Rule Induction through Integrated Symbolic and Subsymbolic Processing
    id = 547
    authors = McMillan_C Mozer_M Smolensky_P 
    5 (0.26895): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.13346): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.05819): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

361: Generalization and Scaling in Reinforcement Learning
    id = 251
    authors = Ackley_D Littman_M 
    1 (0.22003): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.20121): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.13722): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.12970): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

362: LEARNING WITH PREKNOWLEDGE: CLUSTERING WITH FOINT AND GRAPH MATCHING DISTANCE MEASURES
    id = 932
    authors = Gold_S Mjolsness_E Rangarajan_A 
    7 (0.23508): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.23508): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.18992): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.03937): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

363: Generalization Error and the Expected Network Complexity
    id = 746
    authors = Ji_C 
    7 (0.26895): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.18615): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.15981): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.07324): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.05819): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.03937): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

364: Simulation of Optimal Movements Using the Minimum-Muscle-Tension-Change Model
    id = 505
    authors = Dornay_M Kawato_M Suzuki_R Uno_Y 
    4 (0.38939): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.12217): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.11088): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

365: Note on Learning Rate Schedules for Stochastic Optimization .
    id = 398
    authors = Darken_C Moody_J 
    6 (0.31788): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.14852): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.07324): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    2 (0.05819): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

366: A Recurrent Neural Network for Generation of Occular Saccades
    id = 697
    authors = Massone_L 
    11 (0.40445): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.17110): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.13346): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

367: A COMPUTATIONAL MODEL OF PREFRONTAL CORTEX FUNCTION
    id = 861
    authors = Braver_T Cohen_J Servan-Schreiber_D 
    0 (0.20121): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.13346): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.08830): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.06571): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.05442): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.05442): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)

368: REINFORCEMENT LEARNING PREDICTS THE SITE OF PLASTICITY FOR AUDITORY REMAPPING IN THE BARN OWL
    id = 859
    authors = Deffayet_C Pouget_A Sejnowski_T 
    4 (0.23508): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.17863): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.14099): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.09206): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

369: The Cocktail Party Problem: Speech/Data Signal Separation Comparison between Backpropagation and SONN
    id = 250
    authors = Kassebaum_J Schaefers_C Tenorio_M 
    3 (0.21250): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.13722): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.08077): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

370: CORRELATION AND INTERPOLATION NETWORKS FOR REAL-TIME EXPRESSION ANALYSIS/SYNTHESIS
    id = 956
    authors = Darrell_T Essa_I Pentland_A 
    5 (0.39692): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.18992): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.09582): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.05442): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

371: Computer Simulation of Oscillatory Behavior in Cerebral Cortical Networks
    id = 195
    authors = Bower_J Wilson_M 
    11 (0.32917): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.27272): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.08830): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

372: Monte Carlo Matrix Inversion and Reinforcement Learning
    id = 786
    authors = Barto_A Duff_M 
    6 (0.33294): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.23884): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

373: Scaling and Generalization in Neural Networks: A Case Study
    id = 108
    authors = Ahmad_S Tesauro_G 
    5 (0.20497): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.17486): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.15981): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.07701): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.05442): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    39 (0.01302): 9 set  (0.09521) 12 algorithm  (0.09521) 17 state  (0.05982) 11 training  (0.05982) 16 error  (0.05982) 6 function  (0.05982) 10 networks  (0.05982) 20 information  (0.05982) 2 model  (0.05982) 7 figure  (0.02443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

374: Optimal Brain Damage
    id = 257
    authors = Denker_J LeCun_Y Solla_S 
    2 (0.50230): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.17486): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.03937): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

375: Studies of a Model for the Development and Regeneration of Eye-Brain Maps
    id = 286
    authors = Cowen_J Friedman_A 
    2 (0.42703): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.08453): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.03184): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.01679): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

376: Adaptive Range Coding .
    id = 351
    authors = Goodwin_J Rosen_B Vidal_J 
    0 (0.25390): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.17110): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.14475): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

377: Asymptotic Convergence of Backpropagation: Numerical Experiments
    id = 258
    authors = Ahmad_S He_Y Tesauro_G 
    5 (0.44208): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.14475): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.10711): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.03560): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

378: Bayesian Inference of Regular Grammar and Markov Source Models
    id = 232
    authors = Miller_M Smith_K 
    3 (0.19744): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.15981): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.04690): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.03560): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    33 (0.01302): 23 hidden  (0.10685) 16 error  (0.10685) 4 input  (0.08807) 19 units  (0.08807) 9 set  (0.06929) 12 algorithm  (0.06929) 11 training  (0.05052) 5 data  (0.05052) 6 function  (0.03174) 2 model  (0.03174)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)

379: Learning to Categorize Objects Using Temporal Coherence
    id = 617
    authors = Becker_S 
    9 (0.46843): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.11464): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

380: ESTIMATING CONDITIONAL PROBABILITY DENSroES FOR PERIODIC VARIABLES
    id = 923
    authors = Bishop_C Legleye_C 
    3 (0.22379): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.18239): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.14475): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.13346): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    10 (0.08453): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

381: Benchmarking Feed-Forward Neural Networks: Models and Measures
    id = 572
    authors = Hamey_L 
    4 (0.25390): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.18992): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    10 (0.14099): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

382: GLOVE-TALK II: MAPPING HAND GESTURES TO SPEECH USING NEURAL NETWORKS
    id = 948
    authors = Fels_S Hinton_G 
    0 (0.20497): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.16357): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.07324): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

383: Address Block Location with a Neural Net System
    id = 798
    authors = Cosatto_E Graf_H 
    2 (0.28025): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.18239): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.14099): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.10711): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

384: Coupled Dynamics of Fast Neurons and Slow Interactions
    id = 756
    authors = Coolen_A Penney_R Sherrington_D 
    9 (0.49854): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.11464): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.04690): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    43 (0.00926): 11 training  (0.09258) 7 figure  (0.03781) 8 time  (0.03781) 6 function  (0.03781) 10 networks  (0.03781) 9 set  (0.03781) 0 network  (0.03781) 1 learning  (0.03781) 2 model  (0.03781) 5 data  (0.03781)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

385: PLASTICITY-MEDIATED COMPEIITIVE LEARNING
    id = 902
    authors = Schraudolph_N Sejnowski_T 
    6 (0.29906): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.22379): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.18239): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    19 (0.03560): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

386: Optimal Brain Surgeon: Extensions and Performance Comparisons
    id = 733
    authors = Hassibi_B Stork_D Watanabe_T Wolff_G 
    2 (0.29906): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.23884): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.16733): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.01679): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

387: 'Ensemble' Boltzmann Units have Collective Computational Properties like those of Hopfield and Tank Neurons
    id = 23
    authors = Derthick_M Tebelskis_J 
    4 (0.25014): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.10335): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

388: When Will a Genetic Algorithm Outperform Hill Climbing?
    id = 706
    authors = Forrest_S Holland_J Mitchell_M 
    2 (0.17863): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.15228): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

389: Learning in Compositional Hierarchies: Inducing the Structure of Objects from Data
    id = 736
    authors = Utans_J 
    1 (0.38563): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.11464): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.06571): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

390: Integrated Segmentation and Recognition of Hand-Printed Numerals .
    id = 361
    authors = Keeler_J Leow_W Rumelhart_D 
    12 (0.27648): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.16733): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.14475): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.05442): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

391: The Role of Activity in Synaptic Competition at the Neuromuscular Junction
    id = 997
    authors = Joseph_S Willshaw_D 
    2 (0.25390): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.25390): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.15228): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

392: A Neural-Network Solution to the Concentrator Assignment Problem
    id = 80
    authors = Page_E Tagliarini_G 
    0 (0.34046): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.10335): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.08453): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

393: Application of Neural Network Methodology to the Modelling of the Yield Strength in a Steel Rolling Plate Mill
    id = 514
    authors = Tsoi_A 
    20 (0.25766): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    2 (0.18615): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.13722): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    23 (0.13722): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    8 (0.03184): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

394: GENERALIZATION IN REINFORCEMENT LEARNING: SAFELY APPROXIMATING THE VALUE FUNCTION
    id = 889
    authors = Boyan_J Moore_A 
    3 (0.31036): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.19744): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.11088): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

395: Connected Letter Recognition with a Multi-State Time Delay Neural Network
    id = 660
    authors = Hild_H Waibel_A 
    7 (0.27648): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.27272): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

396: Correlational Strength and Computational Algebra of Synaptic Connections Between Neurons
    id = 28
    authors = Fetz_E 
    4 (0.20873): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.15981): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.14475): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

397: Neural Networks Structured for Control Application to Aircraft Landing .
    id = 341
    authors = Chauvin_Y Golden_R Henkle_V Schley_C 
    10 (0.35176): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.28025): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.05066): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.05066): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

398: A Connectionist Learning Control Architecture for Navigation .
    id = 347
    authors = Bachrach_J 
    9 (0.27272): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.26519): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.06195): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

399: VLSI Implementation of TInMANN .
    id = 428
    authors = Melton_M Phan_T Reeves_D VandenBout_D 
    9 (0.43832): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.14475): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    24 (0.03560): 9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

400: A Learning Analog Neural Network Chip with Continuous-Time Recurrent Dynamics
    id = 807
    authors = Cauwenberghs_G 
    8 (0.23132): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.19368): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.17863): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.06195): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

401: A Fast Stochastic Error-Descent Algorithm for Supervised Learning and Optimization
    id = 603
    authors = Cauwenberghs_G 
    0 (0.25014): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.21626): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.16733): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.09582): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

402: Neural Network Star Pattern Recognition for Spacecraft Attitude Determination and Control
    id = 126
    authors = Alvelda_P SanMartin_A 
    7 (0.32541): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.19368): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.09582): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.05066): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

403: An Optimization Network for Matrix Inversion
    id = 41
    authors = Jang_J Lee_S Shin_S 
    7 (0.38939): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.15228): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.09959): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

404: On the Distribution of the Number of Local Minima of a Random Function on a Graph
    id = 273
    authors = Baldi_P Rinott_Y Stein_C 
    5 (0.35552): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.17486): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

405: Neural Network Diagnosis of Avascular Necrosis from Magnetic Resonance Images
    id = 507
    authors = Christy_P Ehman_R Manduca_A 
    14 (0.28777): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.17110): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.03184): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

406: A MODEL OF THE NEURAL BASIS OF THE RAT'S SENSE OF DIRECTION
    id = 865
    authors = Knierim_J Kudrimoti_H McNaughton_B Skaggs_W 
    6 (0.22379): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.18992): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.05442): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.05442): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    18 (0.04313): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

407: CONNECTIONIST SPEAKER NORMALIZATION WITH GENERALIZED RESOURCE ALLOCATING NETWORKS
    id = 951
    authors = Furlanello_C Giuliani_D Trentin_E 
    4 (0.24637): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.16733): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.14099): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

408: The Performance of Convex Set Projection Based Neural Networks
    id = 55
    authors = Atlas_L Marks_R Oh_S Ritcey_J 
    4 (0.17863): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.10711): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.10711): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.09206): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    19 (0.08830): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    2 (0.06195): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

409: Connecting to the Past
    id = 52
    authors = MacDonald_B 
    6 (0.25014): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.23884): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

410: A Novel Net that Learns Sequential Decision Process
    id = 78
    authors = Chen_H Lee_Y Sun_G 
    16 (0.23508): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    2 (0.23132): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.09959): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.04313): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)

411: Scaling Properties of Coarse-Coded Symbol Memories
    id = 67
    authors = Rosenfeld_R Touretzky_D 
    3 (0.24637): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.17486): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

412: Topography and Ocular Dominance with Positive Correlations
    id = 693
    authors = Goodhill_G 
    12 (0.38563): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.19368): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.17110): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

413: Analytic Solutions to the Formation of Feature-Analysing Cells of a Three-Layer Feedforward Visual Information Processing Neural Net
    id = 204
    authors = Tang_D 
    12 (0.35552): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.18239): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.06195): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

414: A Massively-Parallel SIMD Processor for Neural Network and Machine Vision Applications
    id = 805
    authors = Glover_M Miller_W 
    8 (0.23884): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.18615): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.16733): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    19 (0.09582): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

415: Learning with Temporal Derivatives in Pulse-Coded Neuronal Systems
    id = 112
    authors = Gluck_M Parker_D Reifsnider_E 
    0 (0.28777): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.12593): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    19 (0.03937): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

416: Navigating Through Temporal Difference .
    id = 348
    authors = Dayan_P 
    7 (0.33670): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.24637): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.18615): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

417: Storing Covariance by the Associative Long-Term Potentiation and Depression of Synaptic Strengths in the Hippocampus
    id = 135
    authors = Sejnowski_T Stanton_P 
    2 (0.52865): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.12593): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

418: Subgrouping Reduces Complexity and Speeds Up Learning in Recurrent Networks
    id = 262
    authors = Zipser_D 
    3 (0.23132): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.15981): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

419: On Stochastic Complexity and Admissible Models for Neural Network Classifiers
    id = 396
    authors = Smyth_P 
    7 (0.25014): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.18992): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.16733): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.08453): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

420: PHASE-SPACE LEARNING
    id = 903
    authors = Cottrell_G Tsung_F 
    10 (0.41950): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.13722): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.11841): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    42 (0.00926): 22 models  (0.09258) 7 figure  (0.03781) 8 time  (0.03781) 6 function  (0.03781) 5 data  (0.03781) 10 networks  (0.03781) 9 set  (0.03781) 11 training  (0.03781) 0 network  (0.03781) 1 learning  (0.03781)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)

421: Dynamically-Adaptive Winner-Take-All Networks
    id = 470
    authors = Lange_T 
    6 (0.38939): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.22755): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.06948): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.05442): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

422: Convergence of Indirect Adaptive Asynchronous Value Iteration Algorithms
    id = 787
    authors = Barto_A Gullapalli_V 
    15 (0.22003): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    0 (0.21250): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.13722): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.05819): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

423: Qualitative Structure From Motion .
    id = 333
    authors = Weinshall_D 
    3 (0.32917): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.22003): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.19368): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    30 (0.01679): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

424: LEARNING IN LARGE LINEAR PERCEPTRONS AND WHY THE THERMODYNAMIC LIMIT IS RELEVANT TO THE REAL WORLD
    id = 869
    authors = Sollich_P 
    1 (0.32541): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.27648): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    25 (0.08453): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

425: Mapping Between Neural and Physical Activities of the Lobster Gastric Mill
    id = 684
    authors = Boyle_M Doya_K Selverston_A 
    0 (0.32541): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.17110): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.07324): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.04313): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.02808): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

426: LEARNING DIRECTION IN GLOBAL MOTION: TWO CLASSES OF PSYCHOPHYSICAI J .Y-MOTIVATED MODELS
    id = 957
    authors = Sundareswaran_V Vaina_L 
    7 (0.26895): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.22379): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.10711): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.04313): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

427: Learning Unambiguous Reduced Sequence Descriptions
    id = 464
    authors = Schmidhuber_J 
    9 (0.18992): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.17486): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.11088): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.09582): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.06948): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    38 (0.01302): 20 information  (0.10772) 6 function  (0.10772) 13 output  (0.10772) 3 neural  (0.07853) 10 networks  (0.04934) 1 learning  (0.04934) 7 figure  (0.04934) 24 performance  (0.04934) 21 problem  (0.04934) 23 hidden  (0.04934)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

428: Centric Models of the Orientation Map in Primary Visual Cortex
    id = 6
    authors = Baxter_W Dow_B 
    0 (0.28025): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.20497): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.17110): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.04690): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.01679): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    33 (0.01302): 23 hidden  (0.10685) 16 error  (0.10685) 4 input  (0.08807) 19 units  (0.08807) 9 set  (0.06929) 12 algorithm  (0.06929) 11 training  (0.05052) 5 data  (0.05052) 6 function  (0.03174) 2 model  (0.03174)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

429: Training Stochastic Model Recognition Algorithms as Networks can Lead to Maximum Mutual Information Estimation of Parameters
    id = 210
    authors = Bridle_J 
    6 (0.56629): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.19368): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

430: A Model of Distributed Sensorimotor Control in The Cockroach Escape Turn . .
    id = 354
    authors = Beer_R Chiel_H Kacmarcik_G Ritzmann_R 
    5 (0.22003): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.20497): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.18992): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.08453): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

431: Neurally Inspired Plasticity in Oculomotor Processes
    id = 220
    authors = Viola_P 
    2 (0.39692): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.12217): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.08830): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    34 (0.05066): 5 data  (0.15117) 12 algorithm  (0.12857) 17 state  (0.10598) 18 results  (0.08338) 8 time  (0.06079) 1 learning  (0.06079) 19 units  (0.06079) 14 number  (0.03819) 2 model  (0.03819) 3 neural  (0.03819)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

432: EFFICIENT METHODS FOR DEALING WITH MISSING DATA IN SUPERVISED LEARNING
    id = 929
    authors = Ahmad_S Neuneier_R Tresp_V 
    5 (0.31412): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.15981): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.06195): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

433: High Density Associative Memories
    id = 21
    authors = Dembo_A Zeitouni_O 
    3 (0.43079): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.21250): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

434: Rational Parameterizations of Neural Networks
    id = 649
    authors = Helmke_U Williamson_R 
    2 (0.34046): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    18 (0.20873): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    3 (0.15228): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

435: Improving Convergence in Hierarchical Matching Networks for Object Recognition
    id = 622
    authors = Gindi_G Utans_J 
    7 (0.19368): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.18992): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.15228): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.07701): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

436: Adaptive Elastic Models for Hand-Printed Character Recognition
    id = 491
    authors = Hinton_G Revow_M Williams_C 
    1 (0.44961): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.13722): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.10335): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.03184): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

437: NONLINEAR IMAGE INTERPOLATION USING MANIFOLD LEARNING
    id = 964
    authors = Bregler_C Omohundro_S 
    5 (0.25390): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.21250): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.14099): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

438: Multimodular Architecture for Remote Sensing Options
    id = 511
    authors = Badran_F Crepon_M Mejia_C Thiria_S 
    7 (0.20121): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.12217): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.01679): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

439: Hierarchical Learning Control--An Approach with Neuron-Like Associative Memories
    id = 26
    authors = Ersu_E Tolle_H 
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.13346): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.12970): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.09959): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    11 (0.09959): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.07701): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.04690): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.03184): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

440: Shooting Craps in Search of an Optimal Strategy for Training Connectionist Pattern Classifiers
    id = 567
    authors = Hampshire_J Kumar_B 
    0 (0.32165): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.15228): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.04690): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

441: Learning the Structure of Similarity
    id = 984
    authors = Tenenbaum_J 
    0 (0.30659): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.14852): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.09206): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.08830): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.03560): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

442: A Competitive Modular Connectionist Architecture .
    id = 389
    authors = Jacobs_R Jordan_M 
    6 (0.29906): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.22003): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.08453): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

443: Combining Visual and Acoustic Speech Signals with a Neural Network Improves Intelligibility
    id = 213
    authors = Goldstein_M Jenkins_R Sejnowski_T Yuhas_B 
    0 (0.41574): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.14475): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.06195): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.02431): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

444: Distributed Neural Information Processing in the Vestibulo-Ocular System
    id = 47
    authors = Honrubia_V Lau_C 
    14 (0.37057): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.26519): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.09582): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.03560): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

445: Hierarchical Transformation of Space in the Visual System
    id = 479
    authors = Fisher_S Pouget_A Sejnowski_T 
    7 (0.40068): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.22379): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.13722): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

446: Digital Boltzmann VLSI for Constraint Satisfaction and Learning
    id = 812
    authors = Boonyanit_K Burr_J Kritayakirana_K Leung_M Murray_M Peterson_A Schwartz_E Stork_D Watanabe_T Wolff_G 
    5 (0.25766): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.18615): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.05066): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    21 (0.01679): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    0 (0.00549): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)

447: Classification of Electroencephalogram Using Artificial Neural Networks
    id = 843
    authors = Sergejew_A So_D Tsoi_A 
    12 (0.47596): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.15604): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

448: Reflexive Associative Memories
    id = 51
    authors = Loos_H 
    7 (0.40068): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.14852): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.14099): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.05819): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

449: Continuous Speech Recognition by Linked Predictive Neural Networks .
    id = 312
    authors = Petek_B Schmidbauer_O Tebelskis_J Waibel_A 
    3 (0.28777): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.26895): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

450: How Neural Nets Work
    id = 46
    authors = Farber_R Lapedes_A 
    8 (0.18992): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.12593): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    26 (0.11088): 3 neural  (0.21238) 8 time  (0.12636) 6 function  (0.08335) 12 algorithm  (0.04895) 4 input  (0.04895) 22 models  (0.04895) 14 number  (0.04034) 23 hidden  (0.04034) 17 state  (0.04034) 7 figure  (0.03174)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

451: Coupled Markov Random Fields and Mean Field Theory
    id = 265
    authors = Geiger_D Girosi_F 
    10 (0.25014): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.23508): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

452: Against Edges: Function Approximation with Multiple Support Maps
    id = 476
    authors = Darrell_T Pentland_A 
    0 (0.25390): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.25014): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.06948): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.03184): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

453: Dual Inhibitory Mechanisms for Definition of Receptive Field Characteristics in a Cat Striate Cortex
    id = 438
    authors = Bonds_A 
    2 (0.25390): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.18615): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.16733): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.12593): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

454: Designing Application-Specific Neural Networks Using the Genetic Algorithm
    id = 239
    authors = Guha_A Harp_S Samad_T 
    10 (0.31036): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.22003): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.07701): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.03937): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

455: Attractor Neural Networks with Local Inhibition: from Statistical Physics to a Digital Programmable Integrated Circuit
    id = 671
    authors = Pasero_E Zecchina_R 
    0 (0.22003): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.13722): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.06571): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

456: Dynamic Behavior of Constrained Back-Propagation Networks
    id = 263
    authors = Chauvin_Y 
    12 (0.21250): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.15604): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.14475): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.05442): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

457: Using Prior Knowledge in a NNDPA to Learn Context-Free Languages
    id = 581
    authors = Das_S Giles_C Sun_G 
    10 (0.34799): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.17486): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.08830): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06195): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.04313): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

458: A Large-Scale Neural Network Which Recognizes Handwritten Kanji Characters
    id = 235
    authors = Joe_K Mori_Y 
    2 (0.38187): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.13346): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.08830): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.03184): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

459: Spoken Letter Recognition .
    id = 315
    authors = Cole_R Fanty_M 
    4 (0.28025): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.23132): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.03560): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

460: Linear Learning: Landscapes and Algorithms
    id = 97
    authors = Baldi_P 
    6 (0.31412): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.09959): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.02055): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

461: GENERALISATION IN FEEDFORWARD NETWORKS
    id = 870
    authors = Ferra_H Kowalczyk_A 
    11 (0.21626): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.21250): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.08453): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.06948): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

462: Information, Prediction, and Query by Committee
    id = 632
    authors = Freund_Y Seung_H Shamir_E Tishby_N 
    1 (0.29906): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.15604): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.06948): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

463: A Contrast Sensitive Silicon Retina with Reciprocal Synapses
    id = 522
    authors = Andreou_A Boahen_K 
    1 (0.21626): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.18615): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.15228): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.09206): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.06195): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.06195): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

464: Deriving Receptive Fields Using an Optimal Encoding Criterion
    id = 689
    authors = Linsker_R 
    4 (0.39316): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.15981): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.12217): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

465: Connectionist Architectures for Multi-Speaker Phoneme Recognition
    id = 209
    authors = Hampshire_J Waibel_A 
    0 (0.34046): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.13722): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.10335): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.09582): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

466: Learning Cellular Automaton Dynamics with Neural Networks
    id = 650
    authors = Hertz_J Wulff_N 
    15 (0.51360): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.08077): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.05066): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

467: Neural Network Simulation of Somatosensory Representational Plasticity
    id = 191
    authors = Grajski_K Merzenich_M 
    6 (0.52489): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.14475): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

468: Fast Learning with Predictive Forward Models
    id = 497
    authors = Brody_C 
    0 (0.25390): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.24261): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.04313): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

469: Propagation Filters in PDS Networks for Sequencing and Ambiguity Resolution
    id = 457
    authors = Dyer_M Sumida_R 
    4 (0.31036): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.17110): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.11464): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.06195): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.05442): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.04690): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

470: Two Iterative Algorithms for Computing the Singular Value Decomposition from Input/Output Samples
    id = 718
    authors = Sanger_T 
    7 (0.29906): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.24261): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.06195): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.03937): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

471: Hoo Optimality Criteria for LMS and Backpropagation
    id = 744
    authors = Hassibi_B Kailath_T Sayed_A 
    3 (0.25014): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.22003): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.08830): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.08077): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.06195): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.05442): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

472: Using Aperiodic Reinforcement for Directed Self-Organization During Development
    id = 691
    authors = Dayan_P Montague_P Nowlan_S Pouget_A Sejnowski_T 
    5 (0.29906): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.28777): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

473: How to Describe Neuronal Activity: Spikes, Rates, or Assemblies?
    id = 758
    authors = Gerstner_W vanHemmen_J 
    9 (0.20873): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.18615): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

474: Applications of Error Back-Propagation to Phonetic Classification
    id = 113
    authors = Leung_H Zue_V 
    2 (0.34046): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.20121): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.08453): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

475: Dynamic Modulation of Neurons and Networks
    id = 764
    authors = Marder_E 
    11 (0.29154): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.09582): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.09206): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.04690): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    23 (0.01302): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

476: Stereopsis by a Neural Network Which Learns the Constraints .
    id = 329
    authors = Khotanzad_A Lee_Y 
    11 (0.34046): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.18992): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.10711): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

477: Sequential Adaptation of Radial Basis Function Neural Networks ..
    id = 383
    authors = Fallside_F Kadirkamanathan_V Niranjan_M 
    3 (0.32541): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    21 (0.27272): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    2 (0.14852): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

478: THE USE OF DYNAMIC WRITING INFORMATION IN A CONNECTIONIST ON-LINE CURSIVE HANDWRITING RECOGNITION SYSTEM
    id = 979
    authors = Finke_M Manke_S Waibel_A 
    0 (0.18239): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.17486): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.17110): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.04313): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

479: An Electronic Photoreceptor Sensitive to Small Changes in Intensity
    id = 173
    authors = Delbruck_T Mead_C 
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.13722): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.12593): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.11841): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.08453): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    29 (0.04690): 15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

480: A CRITICAL COMPARISON OF MODELS FOR ORIENTATION AND OCULAR DOMINANCE COLUMNS IN THE STRIATE CORTEX
    id = 855
    authors = Erwin_E Obermayer_K Schulten_K 
    7 (0.41950): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.08453): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.05066): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

481: AN AUD1TORY LOCALIZATION AND COORDINATE TRANSFORM CHIP
    id = 941
    authors = Horiuchi_T 
    5 (0.67920): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.03937): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

482: TRANSFORMATION INVARIANT AUTOASSOCIATION WITH APPLICATION TO HANDWRrITEN CHARACTER RECOGNITION
    id = 966
    authors = Milgram_M Schwenk_H 
    12 (0.31036): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.23884): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.06948): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

483: Physiologically Based Speech Synthesis
    id = 653
    authors = Hirayama_M Honda_K Kawato_M Kioke_Y Vatikiotis-Bateson_E 
    1 (0.27272): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.21626): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.11088): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.06195): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    40 (0.02431): 20 information  (0.07594) 13 output  (0.07594) 17 state  (0.07594) 5 data  (0.07594) 12 algorithm  (0.07594) 8 time  (0.03101) 7 figure  (0.03101) 6 function  (0.03101) 9 set  (0.03101) 0 network  (0.03101)
    16 (0.01302): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

484: Interpretation of Artificial Neural Networks: Mapping Knowledge-Based Neural Networks into Rules
    id = 548
    authors = Shavlik_J Towell_G 
    5 (0.31788): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.19744): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.07701): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.07324): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

485: Neural Networks for Model Matching and Perceptual Organization
    id = 161
    authors = Anandan_P Gindi_G Mjolsness_E 
    5 (0.47219): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.14475): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.03937): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

486: Unsupervised learning of distributions on binary vectors using 2- layer networks
    id = 540
    authors = Freund_Y Haussler_D 
    20 (0.44208): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    10 (0.13722): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.10711): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

487: Development and Regeneration of Eye-Brain Maps: A Computational Model .
    id = 196
    authors = Cowan_J Friedman_A 
    10 (0.32165): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.23508): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.14099): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.04313): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    0 (0.02808): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00926): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

488: Encoding Geometric Invariances in Higher-Order Neural Networks
    id = 32
    authors = Giles_C Griffin_R Maxwell_T 
    6 (0.29906): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.02808): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

489: Practical Issues in Temporal Difference Learning
    id = 460
    authors = Tesauro_G 
    3 (0.43079): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.11088): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.04690): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.03184): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    17 (0.02055): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

490: The Effects of Circuit Integration on a Feature Map Vector Quantizer
    id = 212
    authors = Mann_J 
    8 (0.25766): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.22379): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.19744): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

491: Invariant Object Recognition Using a Distributed Associative Memory
    id = 86
    authors = Wechsler_H Zimmerman_G 
    12 (0.24637): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.18615): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.15604): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.07324): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

492: Learning by Choice of Internal Representations
    id = 98
    authors = Domany_E Grossman_T Meir_R 
    0 (0.45338): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.15981): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.08453): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

493: A Self-Organizing Integrated Segmentation and Recognition Neural Net
    id = 489
    authors = Keeler_J Rumelhart_D 
    2 (0.26519): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.24261): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

494: Optimal Sampling of Natural Images .
    id = 334
    authors = Bialek_W Ruderman_D Zee_A 
    2 (0.28777): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.15228): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.09959): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

495: An Object-Oriented Framework for the Simulation of Neural Networks
    id = 670
    authors = Linden_A Sudbrak_T Tietz_C Weber_Weber 
    1 (0.15981): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.14099): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.04313): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

496: Using Hippocampal 'Place Cells' for Navigation, Exploiting Phase Coding
    id = 686
    authors = Burgess_N O'Keefe_J Recce_M 
    0 (0.35176): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.11464): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.09959): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    26 (0.01302): 3 neural  (0.21238) 8 time  (0.12636) 6 function  (0.08335) 12 algorithm  (0.04895) 4 input  (0.04895) 22 models  (0.04895) 14 number  (0.04034) 23 hidden  (0.04034) 17 state  (0.04034) 7 figure  (0.03174)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

497: Tangent Prop--A formalism for specifying selected invariances in an adaptive network
    id = 538
    authors = Denker_J LeCun_Y Simard_P Victorri_B 
    5 (0.19744): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.18615): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.06195): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

498: Simulations Suggest Information Processing Roles for the Diverse Currents in Hippocampal Neurons
    id = 8
    authors = Borg-Graham_L 
    10 (0.48725): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.11841): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.04690): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

499: A Dynamical Model of Context Dependencies for the Vestibulo-Ocular Reflex
    id = 996
    authors = Coenen_O Sejnowski_T 
    12 (0.51360): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.10711): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

500: Training Knowledge-Based Neural Networks to Recognize Genes ..
    id = 357
    authors = Noordewier_M Shavlik_J Towell_G 
    6 (0.31036): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.20497): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.11088): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    37 (0.00926): 4 input  (0.13303) 19 units  (0.13303) 8 time  (0.07631) 15 system  (0.04794) 13 output  (0.04794) 0 network  (0.04794) 9 set  (0.04794) 10 networks  (0.04794) 21 problem  (0.04794) 20 information  (0.04794)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

501: Performance Through Consistency: MS-TDNN's for Large Vocabulary Continuous Speech Recognition
    id = 658
    authors = Tebelskis_J Waibel_A 
    4 (0.29530): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.26519): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.09582): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

502: Hoeffding Races: Accelerating Model Selection Search for Classification and Function Approximation
    id = 707
    authors = Maron_O Moore_A 
    4 (0.31788): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.17110): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.14852): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.05442): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

503: CCD Neural Network Processors for Pattern Recognition
    id = 519
    authors = Chiang_A Chuang_M LaFranchise_J 
    24 (0.34046): 9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784)
    3 (0.20497): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.09582): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.09206): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

504: Extracting and Learning an Unknown Grammar with Recurrent Neural Networks
    id = 467
    authors = Chen_D Chen_H Giles_C Lee_Y Miller_C Sun_G 
    0 (0.43079): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.22003): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.09206): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

505: SIMPLIFYING NEURAL NETS BY DISCOVERING FLAT MINIMA
    id = 909
    authors = Hochreiter_S Schmidhuber_J 
    6 (0.32917): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    28 (0.13722): 3 neural  (0.16986) 21 problem  (0.11898) 14 number  (0.10880) 9 set  (0.09862) 2 model  (0.08844) 20 information  (0.07827) 24 performance  (0.06809) 18 results  (0.03756) 8 time  (0.03756) 12 algorithm  (0.03756)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

506: Neural Network Application to Diagnostics ..
    id = 358
    authors = Marko_K 
    7 (0.21626): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.20121): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.18992): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.12593): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.04690): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

507: Constructing Hidden Units Using Examples and Queries ..
    id = 408
    authors = Baum_E Lang_K 
    8 (0.28777): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.15604): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.13346): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.08077): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

508: Assessing and Improving Neural Network Predictions by the Bootstrap Algorithm
    id = 597
    authors = Paass_G 
    8 (0.27648): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.22755): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.08453): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

509: Directional Hearing by the Mauthner System
    id = 772
    authors = Eaton_R Guzik_A 
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.15228): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.13346): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.09582): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.08077): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

510: An Analog VLSI Model of Adaptation in the Vestibulo-Ocular Reflex
    id = 275
    authors = DeWeerth_S Mead_C 
    9 (0.23884): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.18992): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.09582): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.09206): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.05066): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.01302): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

511: Robust Parameter Estimation and Model Selection for Neural Network Regression
    id = 724
    authors = Liu_Y 
    7 (0.25766): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.22755): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.14099): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.04313): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

512: Neural Network Visualization
    id = 241
    authors = Tesauro_G Wejchert_J 
    1 (0.33294): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.26143): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.11088): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.06571): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

513: Silicon Auditory Processors as Computer Peripherals
    id = 673
    authors = Gillespie_D Lazzaro_J Mahowald_M Sivilotti_M Wawrzynek_J 
    0 (0.28025): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.13346): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.12217): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.12217): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

514: Second Order Derivatives for Network Pruning: Optimal Brain Surgeon
    id = 593
    authors = Hassibi_B Stork_D 
    2 (0.25014): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.11464): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.10711): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.05819): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    5 (0.05066): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

515: A Reinforcement Learning Variant for Control Scheduling ..
    id = 350
    authors = Guha_A 
    9 (0.40445): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.15981): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.07324): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

516: LEARNING MANY RELATED TASKS AT THE SAME TIME WITH BACKPROPAGATION
    id = 925
    authors = Camana_R 
    6 (0.58134): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

517: Principled Architecture Selection for Neural Networks: Application to Corporate Bond Rating Prediction
    id = 512
    authors = Moody_J Utans_J 
    9 (0.20497): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.15981): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.15604): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.15228): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.04313): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

518: A Method for the Design of Stable Lateral Inhibition Networks that is Robust in the Presence of Circuit Parasitics
    id = 89
    authors = Standley_D Wyatt_J 
    3 (0.20121): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.18239): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.16357): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.11841): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

519: Probability Estimation from a Database Using a Gibbs Energy Model
    id = 638
    authors = Goodman_R Miller_J 
    4 (0.41950): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.23884): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.06195): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    31 (0.00926): 17 state  (0.15178) 1 learning  (0.11685) 14 number  (0.09938) 6 function  (0.08192) 7 figure  (0.08192) 24 performance  (0.08192) 2 model  (0.02952) 9 set  (0.02952) 13 output  (0.02952) 5 data  (0.02952)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

520: Optimal Depth Neural Networks for Multiplication and Related Problems
    id = 580
    authors = Roychowdhury_V Siu_K 
    10 (0.46843): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.14099): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

521: Towards Faster Stochastic Gradient Search
    id = 552
    authors = Darken_C Moody_J 
    0 (0.47219): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.13346): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

522: Constant-Time Loading of Shallow 1-Dimensional Networks
    id = 534
    authors = Judd_S 
    2 (0.29154): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.13722): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.04690): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

523: Chaitin-Kolmogorov Complexity and Generalization in Neural Networks .
    id = 411
    authors = Pearlmutter_B Rosenfeld_R 
    6 (0.23884): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.15228): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.13722): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

524: Adjoint Operator Algorithms for Faster Learning in Dynamical Neural Networks
    id = 245
    authors = Barhen_J Gulati_S Toomarian_N 
    13 (0.17486): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.17486): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.12217): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

525: Acoustic-Imaging Computations by Echolocating Bats: Unification of Diversely-Represented Stimulus Features into Whole Images
    id = 185
    authors = Simmons_J 
    14 (0.44585): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    9 (0.16733): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.06948): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.05442): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

526: Fool's Gold: Extracting Finite State Machines from Recurrent Network Dynamics
    id = 763
    authors = Kolen_J 
    5 (0.19744): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

527: Learning Complex Boolean Functions: Algorithms and Applications
    id = 814
    authors = Oliveira_A Sangiovanni-Vincentelli_A 
    2 (0.30283): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.13346): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.09959): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

528: RECOGNIZING HANDWRITEN DIGITS USING MIXTURES OF LINEAR MODELS
    id = 969
    authors = Dayan_P Hinton_G Revow_M 
    9 (0.56629): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.10711): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

529: Bayesian Self-Organization
    id = 825
    authors = Smimakis_S Xu_L Yuille_A 
    11 (0.28025): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.23508): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.15228): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.10711): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

530: The Clusteron: Toward a Simple Abstraction for a Complex Neuron
    id = 433
    authors = Mel_B 
    1 (0.29906): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.13346): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.10335): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

531: Electronic Receptors for Tactile/Haptic Sensing
    id = 180
    authors = Andreou_A 
    1 (0.25766): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.08077): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.05819): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.03560): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.01302): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

532: Analogy--Watershed or Waterloo? Structural Alignment and the Development of Connectionist Models of Cognition
    id = 677
    authors = Gentner_D Markman_A 
    14 (0.44208): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.25766): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

533: Discontinuous Generalization in Large Committee Machines
    id = 750
    authors = Hertz_J Schwarze_H 
    1 (0.34799): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.20873): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.14852): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

534: Speech Recognition Experiments with Perceptrons
    id = 14
    authors = Burr_D 
    1 (0.31788): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.14852): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.12970): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    37 (0.04690): 4 input  (0.13303) 19 units  (0.13303) 8 time  (0.07631) 15 system  (0.04794) 13 output  (0.04794) 0 network  (0.04794) 9 set  (0.04794) 10 networks  (0.04794) 21 problem  (0.04794) 20 information  (0.04794)
    16 (0.01679): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

535: Feedback Synapse to Cone and Light Adaptation .
    id = 338
    authors = Skrzypek_J 
    8 (0.23884): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.13722): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.09582): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)

536: Network generalization for production: Learning and producing styled letterforms
    id = 566
    authors = Grebert_I Keesing_R Mims_S Stork_D 
    2 (0.37057): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.12970): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.09959): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

537: Learning on a General Network
    id = 2
    authors = Atiya_A 
    10 (0.32165): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.05066): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.03184): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.01679): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.01679): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)

538: Practical Characteristics of Neural Network and Conventional Pattern Classifiers on Artificial and Speech Problems
    id = 205
    authors = Lee_Y Lippmann_R 
    10 (0.23132): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.22755): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.14475): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.13722): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.03560): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

539: PCA-PYRAMIDS FOR IMAGE COMPRESSION
    id = 960
    authors = Bischof_H Hornik_K 
    0 (0.34423): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.19744): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    7 (0.08077): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

540: The Cascade-Correlation Learning Architecture
    id = 248
    authors = Fahlman_S Lebiere_C 
    4 (0.53618): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.09582): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

541: AN ANALOG NEURAL NETWORK INSPIRED BY FRACFAL BLOCK CODING
    id = 942
    authors = Andreou_A Pineda_F 
    0 (0.35928): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

542: Non-Boltzmann Dynamics in Networks of Spiking Neurons
    id = 198
    authors = Bialek_W Crair_M 
    0 (0.26895): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.23508): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.15981): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.06571): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

543: Competitive Anti-Hebbian Learning of Invariants
    id = 553
    authors = Schraudolph_N Sejnowski_T 
    16 (0.48725): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    9 (0.20497): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

544: Bounds on the Complexity of Recurrent Neural Network Implementations of Finite State Machines
    id = 745
    authors = Home_B Hush_D 
    0 (0.30283): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.15228): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.06571): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    3 (0.05066): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

545: Recognizing Hand-Printed Letters and Digits
    id = 234
    authors = Martin_G Pittman_J 
    1 (0.38187): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.27272): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

546: Feature Densities Are Required for Computing Feature Correspondences
    id = 820
    authors = Ahmad_S 
    2 (0.38563): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.20121): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.05442): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

547: Generalization Dynamics in LMS Trained Linear Networks .
    id = 406
    authors = Chauvin_Y 
    10 (0.60016): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.12593): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

548: Neuronal Maps for Sensory-Motor Control in the Barn Owl
    id = 132
    authors = Gelfand_J Pearson_J Peterson_R Spence_C Sullivan_W 
    12 (0.39692): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.18239): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

549: A CONNECIIONIST TECHNIQUE FOR ACCELERATED TEXTUAL INPUT: LETTING A NETWORK DO THE TYPING
    id = 972
    authors = Pomerleau_D 
    2 (0.26895): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.23132): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.07324): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.05819): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

550: NON-LINEAR PREDICTION OF ACOUSTIC VECTORS USING HIERARCHICAL MIXTURES OF EXPERTS
    id = 947
    authors = Robinson_A Waterhouse_S 
    10 (0.37057): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.22003): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.09959): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.05442): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

551: Modeling Applications with the Focused Gamma Net
    id = 446
    authors = Kuo_J Principe_J de-Oliveira_P de-Vries_B 
    9 (0.23508): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.12970): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.11464): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.11088): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.09582): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

552: A STUDY OF PARALLEL PERTURBATIVE GRADIENT DESCENT
    id = 943
    authors = Alspector_J Lippe_D 
    1 (0.29530): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.18239): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.17110): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.11464): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

553: Mechanisms for Neuromodulation of Biological Neural Networks
    id = 187
    authors = Harris-Warrick_R 
    5 (0.26895): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.26143): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.07324): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.07324): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

554: STOCHASTIC DYNAMICS OF THREE-STATE NEURAL NETWORKS
    id = 877
    authors = Cowan_J Ohira_T 
    12 (0.45714): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.12970): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

555: Improved Hidden Markov Model Speech Recognition Using Radial Basis Function Networks
    id = 448
    authors = Lippmann_R Singer_E 
    0 (0.25014): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.22379): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.03560): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

556: Analog Implementation of Shunting Neural Networks
    id = 170
    authors = Darling_R Nabet_B Pinter_R 
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.14852): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.05066): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

557: Integration of Visual and Somatosensory Information for Preshaping Hand in Grasping Movements
    id = 611
    authors = Fukumura_N Kawato_M Suzuki_R Uno_Y 
    6 (0.34799): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.15981): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.05819): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

558: An Analog VLSI Chip for Thin-Plate Surface Interpolation
    id = 169
    authors = Harris_J 
    8 (0.31036): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.13346): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.04690): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.04690): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

559: Burst Synchronization without Frequency Locking in a Completely Solvable Network Model
    id = 443
    authors = Koch_C Schuster_H 
    13 (0.40068): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.16357): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

560: LEARNING FROM QUERIES FOR MAXIMUM INFORMATION GAIN IN IMPERFECTLY LEARNABLE PROBLEMS
    id = 879
    authors = Saad_D Sollich_P 
    11 (0.28777): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.13346): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.11088): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.09206): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.03937): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

561: Self-Organizing Rules for Robust Principal Component Analysis
    id = 630
    authors = Xu_L Yuille_A 
    3 (0.30283): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.20873): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

562: Self Organizing Neural Networks for the Identification Problem
    id = 96
    authors = Lee_W Tenorio_M 
    10 (0.21250): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.15604): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.14852): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.10335): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.07701): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.06195): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

563: Discovering Structure from Motion in Monkey, Man and Machine
    id = 72
    authors = Siegel_R 
    14 (0.22003): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.14099): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.12593): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

564: Links Between Markov Models and Multilayer Percepttons
    id = 147
    authors = Bourlard_H Wellekens_C 
    6 (0.30283): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.15981): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.14099): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.09959): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.03937): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

565: Learning Trajectory and Force Control of an Artifidal Muscle Arm .
    id = 344
    authors = Katayama_M Kawato_M 
    2 (0.32541): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.31788): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.12593): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

566: A Theory for Neural Networks with Time Delays
    id = 307
    authors = Principe_J de-Vries_B 
    1 (0.44208): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.23884): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

567: LEARNING SACCADIC EYE MOVEMENTS USING MULTISCALE SPATIAL FILTERS
    id = 954
    authors = Ballard_D Rao_R 
    0 (0.30659): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.18615): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

568: Optimal Neural Spike Classification
    id = 9
    authors = Atiya_A Bower_J 
    2 (0.16357): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.13346): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.12593): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.11841): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.06948): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06195): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)

569: Performance Measures for Associative Memories that Learn and Forget
    id = 45
    authors = Kuh_A 
    7 (0.25390): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.22003): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.10711): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.07701): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.07324): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

570: Development and Spatial Structure of Cortical Feature Maps: A Model Study
    id = 287
    authors = Obermayer_K Ritter_H Schulten_K 
    0 (0.37810): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.20873): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

571: UNSUPERVISED CLASSIFICATION OF 3D OBJECFS FROM 2D VIEWS
    id = 961
    authors = Ando_H Suzuki_S 
    6 (0.32917): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.26519): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

572: Neural Implementation of Motivated Behavior: Feeding in an Artificial Insect
    id = 190
    authors = Beer_R Chiel_H 
    5 (0.15981): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.15228): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.11464): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.11088): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.03184): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

573: Cholinergic Modulation May Enhance Cortical Associative Memory Function . .
    id = 292
    authors = Anderson_B Bower_J Hasselmo_M 
    7 (0.20873): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.19744): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.12970): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.05442): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.03560): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

574: Generic Analog Neural Computation: The Epsilon Chip
    id = 667
    authors = Baxter_D Churcher_S Hamilton_A Murray_A Reekie_H 
    7 (0.40445): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.19368): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.14475): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

575: Lipreading by Neural Networks: Visual Preprocessing, Learning, and Sensory Integration
    id = 828
    authors = Hennecke_M Prasad_K Stork_D Wolff_G 
    1 (0.33670): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.19744): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.14852): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.04313): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    21 (0.02808): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    15 (0.01679): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

576: VISUAL SPEECH RECOGNITION WITH STOCHASTIC NETWORKS
    id = 949
    authors = Movellan_J 
    2 (0.27272): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.14099): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.13346): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.08077): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

577: Induction of Multiscale Temporal Structure
    id = 462
    authors = Mozer_M 
    6 (0.25766): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.12593): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.02808): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

578: A Model of Auditory Streaming
    id = 991
    authors = Denham_M McCabe_S 
    2 (0.35552): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.13722): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.08830): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.04313): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

579: Segmental Neural Net Optimization for Continuous Speech Recognition
    id = 832
    authors = Makhoul_J Schwartz_R Zavaliagkos_G Zhao_Y 
    14 (0.29530): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.23132): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.11841): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.10335): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

580: The Tempo 2 Algorithm: Adjusting Time-Delays By Supervised Learning .
    id = 306
    authors = Bodenhausen_U Waibel_A 
    7 (0.28401): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.17486): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.06571): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.04313): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

581: Performance of Synthetic Neural Network Classification of Noisy Radar Signals
    id = 122
    authors = Ahalt_S Garber_F Jouny_I Krishnamurthy_A 
    2 (0.39692): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.18992): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

582: Training a Limited-Interconnect, Synthetic Neural IC
    id = 179
    authors = Afghan_A Akers_L Haghighi_S Walker_M 
    6 (0.35928): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.17863): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.11088): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.06571): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    17 (0.03184): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

583: Oriented Non-Radial Basis Functions for Image Coding and Analysis .
    id = 384
    authors = Christian_J Saha_A Tang_D Wu_C 
    9 (0.44208): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.12217): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.10711): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.06195): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

584: Transforming Neural-Net Output Levels to Probability Distributions .
    id = 401
    authors = Denker_J LeCun_Y 
    1 (0.23132): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.21250): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.18239): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.09959): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.05442): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

585: DYNAMIC CELL STRUCTURES
    id = 905
    authors = Bmske_JO Sommer_G 
    3 (0.32917): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.22755): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.13346): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

586: Directional-Unit Boltzmann Machines
    id = 594
    authors = Mozer_M Williams_C Zemel_R 
    8 (0.21250): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.17110): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.13346): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.03184): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)

587: Comparison of Three Classification Techniques, CART, C4.5 and Multi-Layer Perceptrons ..
    id = 416
    authors = Pearson_R Tsoi_A 
    1 (0.23884): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.09582): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.08830): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.07701): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

588: MODEL OF BIOLOGICAL NEURON AS A TEMPORAL NEURAL NETWORK
    id = 854
    authors = Kairiss_E Murphy_S 
    6 (0.28025): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.13722): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

589: Automatic Local Annealing
    id = 159
    authors = Leinbach_J 
    1 (0.21626): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.17863): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.14099): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.12217): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.03937): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

590: GDS: Gradient Descent Generation of Symbolic Classification Rules
    id = 836
    authors = Blasig_R 
    6 (0.32917): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.15228): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

591: An Analog VLSI Model of Central Pattern Generation in the Leech
    id = 778
    authors = Siegel_M 
    8 (0.40068): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.25766): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    39 (0.03560): 9 set  (0.09521) 12 algorithm  (0.09521) 17 state  (0.05982) 11 training  (0.05982) 16 error  (0.05982) 6 function  (0.05982) 10 networks  (0.05982) 20 information  (0.05982) 2 model  (0.05982) 7 figure  (0.02443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

592: Efficient Parallel Learning Algorithms for Neural Networks
    id = 94
    authors = Kramer_A Sangiovanni-Vincentelli_A 
    0 (0.17110): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.13346): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.07701): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    28 (0.06195): 3 neural  (0.16986) 21 problem  (0.11898) 14 number  (0.10880) 9 set  (0.09862) 2 model  (0.08844) 20 information  (0.07827) 24 performance  (0.06809) 18 results  (0.03756) 8 time  (0.03756) 12 algorithm  (0.03756)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

593: Winner-Take-All Networks of O(N) Complexity
    id = 171
    authors = Lazzaro_J Mahowald_M Mead_C Ryckebusch_S 
    10 (0.15604): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    19 (0.15228): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    17 (0.14852): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    1 (0.12217): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.10335): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

594: A Model of Neural Oscillator for a Unified Submodule
    id = 154
    authors = Borisyuk_G Borisyuk_R Chulaevsky_V Kirillov_A Kovalenko_Y Kryukov_V Makarenko_V 
    1 (0.35928): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.17486): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.07701): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    13 (0.05442): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.04313): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    19 (0.03560): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

595: Summed Weight Neuron Perturbation: An O(N) Improvement Over Weight Perturbation
    id = 599
    authors = Flower_B Jabri_M 
    0 (0.15981): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.15604): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.10335): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.06195): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

596: Neural Network Routing for Random Multistage Interconnection Networks
    id = 517
    authors = Giles_C Goudreau_M 
    7 (0.38939): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.13346): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    19 (0.04313): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.03560): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

597: Optimal Signalling in Attractor Neural Networks
    id = 761
    authors = Meilijson_I Ruppin_E 
    11 (0.41574): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    18 (0.12217): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

598: HIGHER ORDER STATISTICAL DECORRELATION WITHOUT INFORMATION LOSS
    id = 874
    authors = Brauer_W Deco_G 
    12 (0.31412): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.29154): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

599: Efficient Design of Boltzmann Machines .
    id = 397
    authors = Gupta_A Maass_W 
    0 (0.31788): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.21626): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.14852): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.01302): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

600: Synchronization in Neural Nets
    id = 85
    authors = Haggerty_J Vidal_J 
    3 (0.19368): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.15981): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.14099): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.12970): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.12217): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.03937): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

601: Skeletonization: A Technique for Trimming the Fat from a Network via Relevance Assessment
    id = 102
    authors = Mozer_M Smolensky_P 
    14 (0.20497): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.15981): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.14475): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    19 (0.06571): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

602: Some Solutions to the Missing Feature Problem in Vision
    id = 621
    authors = Ahmad_S Tresp_V 
    10 (0.48725): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.07324): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.03184): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

603: Efficient Pattern Recognition Using a New Transformation Distance
    id = 579
    authors = Cun_Y Denker_J Simard_P 
    1 (0.31412): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.11464): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    7 (0.10335): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.09206): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.08830): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

604: A Neural Model of Descending Gain Control in the Electrosensory System
    id = 685
    authors = Nelson_M 
    8 (0.28025): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.22379): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.17110): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    39 (0.00926): 9 set  (0.09521) 12 algorithm  (0.09521) 17 state  (0.05982) 11 training  (0.05982) 16 error  (0.05982) 6 function  (0.05982) 10 networks  (0.05982) 20 information  (0.05982) 2 model  (0.05982) 7 figure  (0.02443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

605: Word Space
    id = 682
    authors = Schfitze_H 
    4 (0.31412): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.22003): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.12970): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.05442): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

606: A Computational Model for Cursive Handwriting Based on the Minimization Principle
    id = 791
    authors = Kawato_M Koike_Y Vatikiotis-Bateson_E Wada_Y 
    9 (0.32541): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.17110): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.10711): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    36 (0.00926): 8 time  (0.11651) 11 training  (0.09167) 5 data  (0.09167) 13 output  (0.06683) 18 results  (0.06683) 9 set  (0.06683) 10 networks  (0.06683) 23 hidden  (0.06683) 15 system  (0.04199) 7 figure  (0.04199)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

607: How to Choose an Activation Function
    id = 740
    authors = Mhaskar_H Micchelli_C 
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.19368): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.18615): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.04690): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.03937): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

608: Learning to See Rotation and Dilation with a Hebb Rule .
    id = 328
    authors = Sereno_M 
    4 (0.26895): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.19744): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.11088): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.02055): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    31 (0.01302): 17 state  (0.15178) 1 learning  (0.11685) 14 number  (0.09938) 6 function  (0.08192) 7 figure  (0.08192) 24 performance  (0.08192) 2 model  (0.02952) 9 set  (0.02952) 13 output  (0.02952) 5 data  (0.02952)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

609: Translating Locative Prepositions .
    id = 367
    authors = Munro_P Tabasko_M 
    11 (0.41574): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.21250): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

610: Cycles: A Simulation Tool for Studying Cyclic Neural Networks
    id = 30
    authors = Gately_M 
    1 (0.26895): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.18615): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.15604): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

611: The Computation of Stereo Disparity for Transparent and for Opaque Surfaces
    id = 620
    authors = Kersten_D Madarasmi_S Pong_T 
    2 (0.21250): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.18615): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.14475): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

612: Lg Depth Estimation and Ripple Fire Characterization ..
    id = 359
    authors = Baumgardt_D Perry_J 
    3 (0.28777): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.18615): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.13722): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    33 (0.08077): 23 hidden  (0.10685) 16 error  (0.10685) 4 input  (0.08807) 19 units  (0.08807) 9 set  (0.06929) 12 algorithm  (0.06929) 11 training  (0.05052) 5 data  (0.05052) 6 function  (0.03174) 2 model  (0.03174)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

613: Modeling Interactions of the Rat's Place and Head Direction Systems
    id = 992
    authors = Rexlish_A Touretzky_D 
    8 (0.27648): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.26519): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

614: TEMPORAL DYNAMICS OF GENERALIZATION IN NEURAL NETWORKS
    id = 876
    authors = Venkatesh_S Wang_C 
    0 (0.25014): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.16733): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.12217): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

615: Direction Selective Silicon Retina that uses Null Inhibition
    id = 521
    authors = Benson_R Delbruck_T 
    1 (0.25766): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.20497): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.17486): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.13346): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

616: Recognition of Manipulated Objects by Motor Learning
    id = 495
    authors = Gomi_H Kawato_M 
    0 (0.31788): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.26895): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

617: Learning to Segment Images Using Dynamic Feature Binding
    id = 482
    authors = Behrmann_M Mozer_M Zemel_R 
    4 (0.25766): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.21626): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.20497): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    30 (0.00926): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

618: Stimulus Encoding By Multidimensional Receptive Fields in Single Cells and Cell Populations in V1 of Awake Monkey
    id = 619
    authors = Aertsen_A Hochstein_S Stern_E Vaadia_E 
    8 (0.24261): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.22003): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

619: Evolution and Learning in Neural Networks ..
    id = 394
    authors = Keesing_R Stork_D 
    0 (0.42703): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.11464): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.08077): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.05819): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

620: Weight Space Probability Densities in Stochastic Learning: I. Dynamics and Equilibria
    id = 628
    authors = Leen_T Moody_J 
    4 (0.25014): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.13722): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.12970): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.07324): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.03184): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    23 (0.01679): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)

621: How the Catfish Tracks Its Prey: An Interactive 'Pipelined' Processing System May Direct Foraging via Reticulospinal Neurons
    id = 42
    authors = Kanwal_J 
    1 (0.26895): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.22755): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.13722): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    18 (0.09959): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    37 (0.02431): 4 input  (0.13303) 19 units  (0.13303) 8 time  (0.07631) 15 system  (0.04794) 13 output  (0.04794) 0 network  (0.04794) 9 set  (0.04794) 10 networks  (0.04794) 21 problem  (0.04794) 20 information  (0.04794)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

622: Perceiving Complex Visual Scenes: An Oscillator Neural Network Model that Integrates Selective Attention, Perceptual Organisation, and Invariant Recognition
    id = 683
    authors = Goebel_R 
    2 (0.27648): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.17486): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.15228): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.06195): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.04690): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.01302): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

623: Training Neural Networks with Deficient Data
    id = 716
    authors = Ahmad_S Neuneier_R Tresp_V 
    7 (0.26519): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.25766): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

624: A NEURAL MODEL OF DELUSIONS AND HALLUCINATIONS IN SCHIZOPHRENIA
    id = 862
    authors = Horn_D Reggia_J Ruppin_E 
    6 (0.27648): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.25766): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.15604): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.05819): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

625: Connectionist Approaches to the Use of Markov Models for Speech Recognition .
    id = 314
    authors = Bourlard_H Morgan_N Wooters_C 
    8 (0.23508): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.18992): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.07324): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    17 (0.03184): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

626: Statistical Prediction with Kanerva's Sparse Distributed Memory
    id = 157
    authors = Rogers_D 
    12 (0.22755): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.22003): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.12970): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

627: Correlation Functions in a Large Stochastic Neural Network
    id = 759
    authors = Ginzburg_I Sompolinski_H 
    0 (0.28777): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.25014): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.09959): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    18 (0.00926): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

628: Decoding Cursive Scripts
    id = 804
    authors = Singer_Y Tishby_N 
    4 (0.31788): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.22003): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.12970): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.10335): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

629: Inverse Dynamics of Speech Motor Control
    id = 830
    authors = Hirayama_M Kawato_M Vatikiotis-Bateson_E 
    3 (0.28401): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.25390): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.20121): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

630: Adaptive Stimulus Representations: A Computational Theory of Hippocampal-Region Function
    id = 687
    authors = Gluck_M Myers_C 
    9 (0.23132): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.18992): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

631: JPMAX: LEARNING TO RECOGNIZE MOVING OBJECTS AS A MODEL-FITTING PROBLEM
    id = 959
    authors = Becker_S 
    2 (0.21250): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.14099): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.12593): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.02431): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

632: A Mean Field Theory of Layer IV of Visual Cortex and Its Application to Artificial Neural Networks
    id = 70
    authors = Scofield_C 
    8 (0.35176): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.22003): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.18239): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

633: Can Simple Cells Learn Curves? A Hebbian Model in a Structured Environment
    id = 200
    authors = Kammen_D Softky_W 
    2 (0.65662): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.02808): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

634: Biologically Plausible Local Learning Rules for the Adaptation of the Vestibulo-Ocular Reflex
    id = 690
    authors = Coenen_O Lisberger_S Sejnowski_T 
    11 (0.35552): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.17110): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.14852): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.08830): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

635: Adaptive Soft Weight Tying using Gaussian Mixtures
    id = 550
    authors = Hinton_G Nowlan_S 
    4 (0.20121): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.17863): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.17110): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.08830): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

636: Human Reading and the Curse of Dimensionality
    id = 986
    authors = Martin_G 
    2 (0.34799): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.17110): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.02808): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

637: Reading a Neural Code
    id = 189
    authors = Bialek_W Rieke_F Warland_D de-Ruyter-van-Steveninck_R 
    4 (0.22003): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.12593): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.07701): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.07324): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.06195): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.04313): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

638: Bayesian Modeling and Classification of Neural Signals
    id = 774
    authors = Lewicki_M 
    5 (0.22755): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.10335): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

639: An Analog Self-Organizing Neural Network Chip
    id = 175
    authors = Gilbert_S Mann_J 
    1 (0.22003): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.20497): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.15604): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

640: A Simple Weight Decay Can Improve Generalization
    id = 545
    authors = Hertz_J Krogh_A 
    2 (0.32917): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.22379): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.11464): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.08077): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

641: Destabilization and Route to Chaos in Neural Networks with Random Connectivity
    id = 640
    authors = Cessac_B Doyon_B Quoy_M Samuelides_M 
    18 (0.20121): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    9 (0.18239): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.15604): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.11841): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.09206): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.02431): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

642: Learning by State Recurrence Detection
    id = 66
    authors = Goodwin_J Rosen_B Vidal_J 
    8 (0.26519): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.22379): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.22379): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

643: The Effect of Catecholamines on Performance: From Unit to System Behavior
    id = 197
    authors = Cohen_J Printz_H Servan-Schreiber_D 
    11 (0.23884): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.16357): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.13346): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

644: Learning Curves, Model Selection and Complexity of Neural Networks
    id = 647
    authors = Amari_S Murata_N Yoshizawa_S 
    11 (0.31788): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.22003): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.21250): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

645: Models of Ocular Dominance Column Formation: Analytical and Computational Results
    id = 133
    authors = Keller_J Miller_K Stryker_M 
    3 (0.22003): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.17486): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.16733): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.03560): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

646: Correlated Neuronal Response: Time Scales and Mechanisms
    id = 993
    authors = Bair_W Koch_C Zohary_E 
    10 (0.24637): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.14099): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.10335): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    23 (0.08453): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    8 (0.06571): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

647: Backpropagation without Multiplication
    id = 729
    authors = Graf_H Simard_P 
    3 (0.26519): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.10335): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    8 (0.08453): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

648: Harmony Networks Do Not Work
    id = 988
    authors = Gourley_R 
    4 (0.25766): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.14475): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.11088): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.05066): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    23 (0.01302): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

649: Signal Processing by Multiplexing and Demultiplexing in Neurons .
    id = 323
    authors = Tam_D 
    9 (0.21250): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.14475): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.10711): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.09206): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

650: Using Local Trajectory Optimizers to Speed Up Global Optimization in Dynamic Programming
    id = 783
    authors = Atkeson_C 
    6 (0.29154): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.19744): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.18992): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.09206): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

651: Nonlinear Pattern Separation in Single Hippocampal Neurons with Active Dendritic Membrane
    id = 435
    authors = Brown_T Claiborne_B Zador_A 
    11 (0.20497): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.12970): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.12593): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.06195): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

652: How Oscillatory Neuronal Responses Reflect Bistability and Switching of the Hidden Assembly Dynamics
    id = 692
    authors = Bauer_H Deppisch_J Geisel_T Pawelzik_K 
    0 (0.35176): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.16357): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.02808): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

653: Modeling Small Oscillating Biological Networks in Analog VLSI
    id = 134
    authors = Bower_J Mead_C Ryckebusch_S 
    9 (0.55876): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.18239): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

654: The 'Moving Targets' Training Algorithm
    id = 252
    authors = Rohwer_R 
    4 (0.25014): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.20873): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.17486): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

655: Extracting Tree-structured Representations of Trained Networks
    id = 987
    authors = Craven_M Shavlik_J 
    8 (0.15604): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.14475): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.14099): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.08077): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.03560): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

656: Temporal Difference Learning of Position Evaluation in the Game of Go
    id = 802
    authors = Dayan_P Schraudolph_N Sejnowski_T 
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.14475): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.14099): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.11464): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.06195): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.05442): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

657: Optimal Stochastic Search and Adaptive Momentum
    id = 760
    authors = Leen_T Orr_G 
    0 (0.28025): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.15981): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.06571): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.05819): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.05819): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

658: Analysis of Short Term Memories for Neural Networks
    id = 826
    authors = Hsu_H Kuo_J Principe_J 
    6 (0.50983): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.23508): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    35 (0.00926): 18 results  (0.19636) 8 time  (0.10598) 10 networks  (0.08338) 16 error  (0.06079) 5 data  (0.06079) 11 training  (0.03819) 12 algorithm  (0.03819) 0 network  (0.03819) 7 figure  (0.03819) 2 model  (0.03819)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

659: How Perception Guides Production in Birdsong Learning
    id = 999
    authors = Fry_C 
    3 (0.37810): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.11464): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.03937): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.03560): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

660: The Computation of Sound Source Elevation in the Barn Owl
    id = 186
    authors = Pearson_J Spence_C 
    0 (0.38187): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.14852): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.14475): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.08453): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

661: ACIIVE LEARNING FOR FUNCTION APPROXIMATION
    id = 917
    authors = Niyogi_P Sung_K 
    6 (0.17486): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.09959): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

662: A Massively Parallel Self-Tuning Context-Free Parser
    id = 151
    authors = Santos_E 
    14 (0.22755): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    10 (0.17863): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.17486): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.11841): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.07701): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

663: Associative Learning via Inhibitory Search
    id = 92
    authors = Ackley_D 
    5 (0.31788): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.31036): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.05442): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.01679): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

664: Handwritten Digit Recognition with a Back-Propagation Network
    id = 233
    authors = Boser_B Denker_J Henderson_D Howard_R Hubbard_W Jackel_L LeCun_Y 
    0 (0.32917): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

665: Human and Machine 'Quick Modeling' .
    id = 570
    authors = Bernasconi_J Gustarson_K 
    1 (0.16733): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.16357): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.15981): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.09206): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.06195): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.04313): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

666: Pattern Class Degeneracy in an Unrestricted Storage Density Memory
    id = 69
    authors = Cooper_L Elbaurn_C Reilly_D Scofield_C 
    6 (0.19368): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.18239): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.08830): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.06195): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.05819): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

667: The Power of Approximating: A Comparison of Activation Functions
    id = 648
    authors = DasGupta_B Schnitger_G 
    0 (0.20121): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.16357): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.15981): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

668: The Efficient Learning of Multiple Task Sequences
    id = 459
    authors = Singh_S 
    3 (0.28401): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.15604): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.07324): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

669: Using A Translation-Invariant Neural Network to Diagnose Heart Arrhythmia.
    id = 214
    authors = Lee_S 
    9 (0.36681): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.28025): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

670: RecNorm: Simultaneous Normalisation and Classification Applied to Speech Recognition .
    id = 317
    authors = Bridle_J Cox_S 
    7 (0.30283): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.17110): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    28 (0.12217): 3 neural  (0.16986) 21 problem  (0.11898) 14 number  (0.10880) 9 set  (0.09862) 2 model  (0.08844) 20 information  (0.07827) 24 performance  (0.06809) 18 results  (0.03756) 8 time  (0.03756) 12 algorithm  (0.03756)
    13 (0.11088): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

671: A REAL TIME CLUSTERING CMOS NEURAL ENGINE
    id = 937
    authors = Huertas_J Linares-Barranco_B Serrano-Gotarredona_T 
    2 (0.35552): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.15604): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.15228): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    21 (0.02431): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

672: Partitioning of Sensory Data by a Cortical Network
    id = 34
    authors = Ambros-Ingerson_J Granger_R Henry_H Lynch_G 
    2 (0.26143): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.23884): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.18239): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.06195): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

673: Threshold Network Learning in the Presence of Equivalences
    id = 536
    authors = Shawe-Taylor_J 
    2 (0.25766): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.18239): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.07324): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    38 (0.00926): 20 information  (0.10772) 6 function  (0.10772) 13 output  (0.10772) 3 neural  (0.07853) 10 networks  (0.04934) 1 learning  (0.04934) 7 figure  (0.04934) 24 performance  (0.04934) 21 problem  (0.04934) 23 hidden  (0.04934)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

674: Neural Network Analysis of Distributed Representations of Dynamical Sensory- Motor Transformations in the Leech
    id = 188
    authors = Fang_Y Lockery_S Sejnowski_T 
    10 (0.20873): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.20873): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.19368): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.08453): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.04690): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

675: Dimensionality Reduction and Prior Knowledge in E-Set Recognition
    id = 206
    authors = Hinton_G Lang_K 
    6 (0.31036): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.15981): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.07324): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.03937): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

676: Illumination and View Position in 3D Visual Recognition
    id = 478
    authors = Shashua_A 
    0 (0.61898): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

677: Hidden Markov Models for Human Genes
    id = 795
    authors = Baldi_P Brunak_S Chauvin_Y Englebrecht_J Krogh_A 
    1 (0.23884): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.15228): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.11464): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.08077): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

678: Improving Performance in Neural Networks Using a Boosting Algorithm
    id = 578
    authors = Drucker_H Schapire_R Simard_P 
    11 (0.21250): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.13722): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.12217): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.08077): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.06195): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.02808): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

679: ADVANTAGE UPDATING APPLIED TO A DIFFERENTIAL GAME
    id = 887
    authors = Baird_L Harmon_M Klopf_A 
    10 (0.49101): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.17110): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    32 (0.02808): 14 number  (0.22966) 4 input  (0.08488) 12 algorithm  (0.08488) 13 output  (0.04869) 16 error  (0.04869) 2 model  (0.04869) 5 data  (0.04869) 24 performance  (0.04869) 20 information  (0.04869) 3 neural  (0.03059)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

680: Real-Time Computer Vision and Robotics Using Analog VLSI Circuits
    id = 276
    authors = Bair_W Harris_J Horiuchi_T Hsu_A Koch_C Luo_J 
    5 (0.37434): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.29154): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

681: Surface Learning with Applications to Lipreading
    id = 705
    authors = Bregler_C Omohundro_S 
    2 (0.23508): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.17863): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.17486): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.05442): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.02431): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

682: Segmentation Circuits Using Constrained Optimization
    id = 526
    authors = Harris_J 
    0 (0.26895): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.22379): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.04690): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.03560): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

683: A Model of Feedback to the Lateral Geniculate Nucleus
    id = 623
    authors = Brody_C 
    1 (0.20121): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.14852): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.12593): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.03937): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

684: Introduction to a System for Implementing Neural Net Connections on SIMD Architectures
    id = 83
    authors = Tomboulian_S 
    7 (0.23132): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.20497): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.16733): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.05819): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.03937): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

685: Convergence and Pattern-Stabilization in the Boltzmann Machine
    id = 148
    authors = Cheng_R Karo_M 
    0 (0.32165): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.16357): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.14099): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.05442): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

686: Bayesian Backprop in Action: Pruning, Committees, Error Bars, and an Application to Spectroscopy
    id = 726
    authors = Thodberg_H 
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.19368): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.12217): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.06948): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.05442): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

687: Computing with Almost Optimal Size Neural Networks
    id = 575
    authors = Kailath_T Roychowdhury_V Siu_K 
    4 (0.37434): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.22755): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.05819): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

688: Self-Organization of Associative Database and Its Applications
    id = 79
    authors = Arimoto_S Suzuki_H 
    1 (0.40821): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.22379): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.03560): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

689: Analog LSI Implementation of an Auto-Adaptive Network for Real-Time Separation of Independent Signals
    id = 527
    authors = Andreou_A Cohen_M Pouliquen_P 
    4 (0.22379): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.18239): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.15228): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.09582): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.08830): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

690: Bumptrees for Efficient Function, Constraint, and Classification Learning .
    id = 379
    authors = Omohundro_S 
    6 (0.27648): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.22003): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.13722): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.07701): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

691: Statistical Mechanics of Temporal Association in Neural Networks
    id = 309
    authors = Herz_A Li_Z vanHemmen_J 
    10 (0.45714): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.08077): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.03937): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

692: DYNAMIC MODELLING OF CHAOTIC TIME SERIES W1TH NEURAL NETWORKS
    id = 882
    authors = Kuo_J Principe_J 
    3 (0.30659): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.27648): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.14475): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.03184): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

693: Using Local Models to Control Movement
    id = 223
    authors = Atkeson_C 
    1 (0.28025): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.15981): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    22 (0.12593): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)
    10 (0.04690): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

694: Self-organisation in real neurons: Anti-Hebb in 'Channel Space'?
    id = 436
    authors = Bell_A 
    4 (0.34423): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.29906): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.04313): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

695: Information Processing to Create Eye Movements
    id = 471
    authors = Robinson_D 
    1 (0.22755): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.14852): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.14099): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.10711): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    22 (0.03184): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

696: Time Dependent Adaptive Neural Networks
    id = 271
    authors = Pineda_F 
    12 (0.30659): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.15228): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.10711): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

697: Computational Elements of the Adaptive Controller of the Human Arm
    id = 834
    authors = Mussa-Ivaldi_F Shadmehr_R 
    1 (0.32541): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.28777): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.08830): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

698: REINFORCEMENT LEARNING METHODS FOR CONTINUOUS-TIME MARKOV DECISION PROBLEMS
    id = 892
    authors = Bradtke_S Duff_M 
    4 (0.22003): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

699: MULTIDIMENSIONAL SCALING AND DATA CLUSTERING
    id = 900
    authors = Buhmann_J Hofmann_T 
    0 (0.27648): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.24637): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.09206): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

700: Refining PID Controllers using Neural Networks
    id = 496
    authors = Ray_W Scott_G Shavlik_J 
    1 (0.33670): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.23508): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.16357): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.03560): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

701: Packet Routing in Dynamically Changing Networks: A Reinforcement Learning Approach
    id = 784
    authors = Boyan_J Littman_M 
    0 (0.23132): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.19744): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.12593): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.02431): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)

702: FACTORIAL LEARNING AND THE EM ALGORITHM
    id = 920
    authors = Ghahramani_Z 
    13 (0.24637): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.10711): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.06948): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

703: On the Non-Existence of a Universal Learning Algorithm for Recurrent Neural Networks
    id = 754
    authors = Wiklicky_H 
    6 (0.32541): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.26143): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.17486): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    18 (0.00926): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

704: INTERFERENCE IN LEARNING INTERNAL MODELS OF INVERSE DYNAMICS IN HUMANS
    id = 982
    authors = Brashers-Krug_T Mussa-lvaldi_F Shadmehr_R 
    8 (0.22755): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.20497): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    10 (0.17863): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.11841): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

705: Spatial Organization of Neural Networks: A Probabilistic Modeling Approach
    id = 76
    authors = Dikaiakos_M Kontoravdis_D Stafylopatis_A 
    5 (0.39692): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.14099): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.10711): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.04690): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.01679): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

706: SPATIAL REPRESENTATIONS IN THE PARIETAL CORTEX MAY USE BASIS FUNCTIONS
    id = 863
    authors = Pouget_A Sejnowski_T 
    2 (0.22755): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.22003): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.12970): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.03560): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

707: The Perceptron Algorithm Is Fast for Non-Malicious Distributions
    id = 267
    authors = Baum_E 
    5 (0.32165): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.12593): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.09959): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

708: 3D Object Recognition Using Unsupervised Feature Extraction
    id = 485
    authors = Bfilthoff_H Edelman_S Gold_J Intrator_N 
    5 (0.30659): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.22003): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.20497): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.01679): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

709: Algorithms for Better Representation and Faster Learning in Radial Basis Function Networks
    id = 243
    authors = Keeler_J Saha_A 
    10 (0.25390): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.21250): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.10335): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.09959): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.06571): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    8 (0.02431): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    21 (0.01302): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)

710: Complexity of Finite Precision Neural Network Classifier
    id = 266
    authors = Dembo_A Kailath_T Siu_K 
    15 (0.28025): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    0 (0.17110): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.15228): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    23 (0.08453): 4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275)
    4 (0.07701): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

711: Generalized Hopfield Networks and Nonlinear Optimization ........
    id = 228
    authors = Reklaitis_G Tenorio_M Tsirukis_A 
    8 (0.38187): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

712: Sigma-Pi Learning: On Radial Basis Functions and Cortical Associative Learning
    id = 242
    authors = Koch_C Mel_B 
    8 (0.30283): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.11464): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.09582): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.08453): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

713: Theory of Self-Organization of Cortical Maps
    id = 141
    authors = Tanaka_S 
    1 (0.25766): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.14475): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.10335): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.05442): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

714: Recurrent Eye Tracking Network Using a Distributed Representation of Image Motion
    id = 475
    authors = Lisberger_S Sejnowski_T Viola_P 
    4 (0.37057): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.24261): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.02431): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

715: An Optimality Principle for Unsupervised Learning
    id = 91
    authors = Sanger_T 
    10 (0.36305): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.15604): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.10711): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

716: Language Induction by Phase Transition in Dynamical Recognizers ..
    id = 370
    authors = Pollack_J 
    3 (0.20497): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.20497): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.16733): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.11841): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.03560): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.03184): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

717: Computer Modeling of Associative Learning
    id = 138
    authors = Alkon_D Quek_F Vogl_T 
    2 (0.30283): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.25766): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

718: The Connectivity Analysis of Simple Association
    id = 35
    authors = Hammerstrom_D 
    8 (0.22755): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.12593): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    1 (0.11464): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.07701): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    14 (0.05442): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.02055): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

719: A Parallel Gradient Descent Method for Learning in Analog VLSI Neural Networks
    id = 675
    authors = Alspector_J Jayakumar_A Lippe_D Meir_R Yuhas_B 
    1 (0.27648): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.24261): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.14099): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.06948): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

720: SARDNET: A SELF-ORGANIZING FEATURE MAP FOR SEQUENCES
    id = 915
    authors = James_D Miikkulainen_R 
    7 (0.49478): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.16357): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.09582): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

721: New Hardware for Massive Neural Networks
    id = 20
    authors = Coon_D Perera_A 
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.13722): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    24 (0.13346): 9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.07324): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

722: Harmonic Grammars for Formal Languages
    id = 676
    authors = Smolensky_P 
    13 (0.28777): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.24261): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.11464): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.09582): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.03560): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

723: LIMITS ON LEARNING MACHINE ACCURACY IMPOSED BY DATA QUAL1TY
    id = 873
    authors = Chiang_W Cortes_C Jackel_L 
    0 (0.23132): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.18239): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.08830): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.05442): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.03184): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

724: MORPHOGENESIS OF THE LATERAL GENICULATE NUCLEUS: HOW SINGULARITIES AFFECT GLOBAL STRUCTURE
    id = 860
    authors = Malpeli_J Schulten_K Tzonev_S 
    4 (0.21250): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.20121): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.17863): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.14475): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.03560): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

725: Efficient Computation of Complex Distance Metrics Using Hierarchical Filtering
    id = 721
    authors = Simard_P 
    3 (0.37434): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.15228): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    20 (0.10335): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.04313): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

726: A CONVOLUTIONAL NEURAL NETWORK HAND TRACKER
    id = 955
    authors = Nowlan_S Platt_J 
    7 (0.22755): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.18992): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.14852): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.05442): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.03184): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

727: Learning a Color Algorithm from Examples
    id = 64
    authors = Hurlbert_A Poggio_T 
    1 (0.24261): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.14475): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

728: Learning Theory and Experiments with Competitive Networks .
    id = 400
    authors = Bilbro_G VandenBout_D 
    0 (0.30659): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.20497): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.14852): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.08830): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

729: Analysis of Distributed Representation of Constituent Structure in Connectionist Systems
    id = 75
    authors = Smolensky_P 
    3 (0.42703): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.15228): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

730: What Size Net Gives Valid Generalization?
    id = 99
    authors = Baum_E Haussler_D 
    5 (0.34423): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.19368): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.12217): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.03937): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    2 (0.02431): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

731: Phase Transitions in Neural Networks
    id = 19
    authors = Chover_J 
    12 (0.27648): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.23132): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.05442): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.03184): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.02808): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

732: "Fast Learning in Multi-Resolution Hierarchies'
    id = 93
    authors = Moody_J 
    3 (0.29906): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.20497): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.08077): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

733: Proximity Effect Corrections in Electron Beam Lithography .
    id = 345
    authors = Cummings_K Frye_R Reitman_E 
    0 (0.22003): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.18239): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.14475): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.08077): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.04313): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.03184): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    31 (0.00926): 17 state  (0.15178) 1 learning  (0.11685) 14 number  (0.09938) 6 function  (0.08192) 7 figure  (0.08192) 24 performance  (0.08192) 2 model  (0.02952) 9 set  (0.02952) 13 output  (0.02952) 5 data  (0.02952)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)

734: CATASTROPHIC INTERFERENCE IN HUMAN MOTOR LEARNING
    id = 846
    authors = Brashers-Krug_T Shadmehr_R Todorov_E 
    4 (0.28025): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.21250): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    14 (0.16357): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.08830): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

735: HIERARCHICAL MIXTURES OF EXPERTS METHODOLOGY APPLIED TO CONTINUOUS SPEECH RECOGNITION
    id = 950
    authors = Makhoul_J Schwartz_R Sroka_J Zhao_Y 
    4 (0.21626): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.15981): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.11464): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.09959): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.04690): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

736: Programmable Synaptic Chip for Electronic Neural Networks
    id = 58
    authors = Khanna_S Langenbacher_H Moopenn_A Thakoor_A 
    13 (0.25390): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    0 (0.21626): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.18992): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.07324): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

737: INTERIOR POINT IMPLEMENTATIONS OF ALTERNATING MINIMIZATION TRAINING
    id = 914
    authors = Lemmon_M Szymanski_P 
    7 (0.23132): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.15981): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.15604): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.10711): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

738: Figure of Merit Training for Detection and Spotting
    id = 827
    authors = Chang_E Lippmann_R 
    10 (0.25014): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.19744): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.18239): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.13722): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

739: Supervised Learning from Incomplete Data via an EM Approach
    id = 715
    authors = Ghahramani_Z Jordan_M 
    6 (0.25390): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.24261): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.18615): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.06195): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

740: An Information-Theoretic Approach to Deciphering the Hippocampal Code
    id = 699
    authors = Gothard_K Markus_E McNaughton_B Skaggs_W 
    1 (0.20873): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.15228): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.12593): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.06571): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)

741: Lower Boundaries of Motoneuron Desynchronization via Renshaw Interneurons
    id = 767
    authors = Druzinsky_R Heckman_C Maltenfort_M Rymer_W 
    11 (0.34046): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.18239): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.12593): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.10335): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

742: Learning in Feedforward Networks with Nonsmooth Functions
    id = 558
    authors = Downs_T Redding_N 
    3 (0.34423): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.20873): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.12217): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

743: Heterogeneous Neural Networks for Adaptive Behavior in Dynamic Environments
    id = 156
    authors = Beer_R Chiel_H Sterling_L 
    1 (0.19368): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.17110): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    20 (0.13346): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

744: Computer Recognition of Wave Location in Graphical Data by a Neural Network
    id = 515
    authors = Freeman_D 
    4 (0.38187): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.03937): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.03560): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.01679): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

745: An Artificial Neural Network for Spatio-Temporal Bipolar Patterns: Application to Phoneme Classification
    id = 3
    authors = Atlas_L Homma_T Marks_R 
    10 (0.21250): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.17863): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.15228): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

746: Microelectronic Implementations of Connectionist Neural Networks
    id = 53
    authors = Denker_J Graf_H Mackie_S Schwartz_D 
    3 (0.25014): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.13722): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.10711): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.06195): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.04690): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    29 (0.00926): 15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

747: SEXNET: A Neural Network Identifies Sex From Human Faces .
    id = 363
    authors = Golomb_B Lawrence_D Sejnowski_T 
    13 (0.42327): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    7 (0.17486): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.11088): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.06195): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

748: Bayesian Learning via Stochastic Dynamics
    id = 631
    authors = Neal_R 
    6 (0.21626): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.13722): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.12593): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

749: Transition Point Dynamic Programming
    id = 780
    authors = Buckland_K Lawrence_P 
    2 (0.32165): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.07324): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.04313): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

750: Dual Mechanisms for Neural Binding and Segmentation
    id = 824
    authors = Finkel_L Sajda_P 
    4 (0.30659): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.22379): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.10711): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

751: FORWARD DYNAMIC MODELS IN HUMAN MOTOR CONTROL: PSYCHOPHYSICAL EVIDENCE
    id = 849
    authors = Ghahramani_Z Jordan_M Wolpert_D 
    11 (0.28401): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.17486): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.09582): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

752: GEMINI: Gradient Estimation Through Matrix Inversion After Noise Injection
    id = 106
    authors = Galland_C Hinton_G LeCun_Y 
    3 (0.25766): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.21626): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.19744): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.02055): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

753: A Trellis-Structured Neural Network
    id = 61
    authors = Dickinson_B Petsche_T 
    0 (0.34799): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.14475): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.04313): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.02808): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

754: Experimental Demonstrations of Optical Neural Computers
    id = 39
    authors = Brady_D Hsu_K Psaltis_D 
    10 (0.29154): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.19744): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.16357): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.07324): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.02055): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

755: Adjoint-Functions and Temporal Learning Algorithms in Neural Networks
    id = 301
    authors = Barhen_J Toomarian_N 
    3 (0.42703): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.26895): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.05819): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

756: A Neural Network to Detect Homologies in Proteins
    id = 236
    authors = Agin_P Bengio_S Bengio_Y Pouliot_Y 
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.16357): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.15981): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    18 (0.14099): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.04690): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

757: PULSESTREAM SYNAPSES WITH NON-VOLATILE ANALOGUE AMORPHOUS-SILICON MEMORIES
    id = 938
    authors = Churcher_S Hajto_J Holmes_A Murray_A Rose_M 
    0 (0.44208): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.16733): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.13346): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.02055): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

758: CLASSIFYING WITH GAUSSIAN MIXTURES AND CLUSTERS
    id = 928
    authors = Kambhatla_N Leen_T 
    4 (0.27648): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.18615): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.17110): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

759: Neural Architecture
    id = 181
    authors = Braitenberg_V 
    10 (0.26895): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.22755): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.18992): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.04313): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.02808): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

760: ICEG MORPHOLOGY CLASSIFICATION USING AN ANALOGUE VLSI NEURAL NETWORK
    id = 934
    authors = Flower_B Jabri_M Pickard_S 
    4 (0.22379): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.22379): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    27 (0.13346): 19 units  (0.11722) 22 models  (0.09875) 18 results  (0.09875) 21 problem  (0.08951) 16 error  (0.08027) 20 information  (0.08027) 17 state  (0.06180) 23 hidden  (0.06180) 14 number  (0.05256) 5 data  (0.04333)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.06195): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.01679): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

761: Spreading Activation over Distributed Microfeatures
    id = 153
    authors = Hendler_J 
    9 (0.30283): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.27648): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.08077): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.07701): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

762: Connectivity Versus Entropy
    id = 0
    authors = Abu-Mostafa_Y 
    5 (0.22755): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.18239): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    4 (0.17863): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.13722): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    29 (0.03937): 15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029)
    6 (0.01302): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

763: Learning in Higher-Order 'Artificial Dendritic Trees'
    id = 244
    authors = Bell_A 
    6 (0.29154): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.19368): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    14 (0.18992): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.07324): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

764: Non-Intrusive Gaze Tracking Using Artificial Neural Networks
    id = 794
    authors = Baluja_S Pomerleau_D 
    6 (0.35928): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.18239): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.10711): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    24 (0.02431): 9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

765: Associative Memory in a Network of 'Biological' Neurons .
    id = 297
    authors = Gerstner_W 
    10 (0.38939): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.14475): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.11088): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

766: Pulse-Firing Neural Chips for Hundreds of Neurons
    id = 280
    authors = Brownlow_M Hamilton_A Han_I Murray_A Reekie_H Tarassenko_L 
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.18992): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.13346): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.06571): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

767: Network activity determines spatio-temporal integration in single cells
    id = 434
    authors = Bernander_O Douglas_R Koch_C 
    6 (0.23132): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.20121): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.17486): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.07701): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.06195): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

768: A Neurocomputer Board Based on the ANNA Neural Network Chip
    id = 523
    authors = Boser_B Jackel_L Sackinger_E 
    2 (0.26895): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.18239): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    3 (0.14099): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.07324): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.01679): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

769: IMPLEMENTATION OF NEURAL HARDWARE WrFH THE NEURAL VLSI OF URAN IN APPLICATIONS WITH REDUCED REPRESENTATIONS
    id = 944
    authors = Han_I Kim_K Lee_H 
    3 (0.31788): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.13346): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.09206): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    18 (0.08453): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

770: DIRECTION SELECTIVITY IN PRIMARY VISUAL CORTEX USING MASSIVE INTRACORTICAL CONNECTIONS
    id = 844
    authors = Douglas_R Koch_C Suarez_H 
    6 (0.36305): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.19744): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.10711): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    11 (0.06195): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.04313): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

771: The Sigmoid Nonlinearity in Prepyriform Cortex
    id = 25
    authors = Eeckman_F 
    1 (0.33294): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.14475): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.14099): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.11088): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

772: Estimating Analogical Similarity by Dot-Products of Holographic Reduced Representations
    id = 838
    authors = Plate_T 
    2 (0.38939): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.13346): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.12970): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.06948): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

773: PATTERNS OF DAMAGE IN NEURAL NETWORKS: THE EFFECTS OF LESION AREA, SHAPE AND NUMBER
    id = 848
    authors = Reggia_J Ruppin_E 
    7 (0.22755): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.22755): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.20497): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.08077): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    35 (0.00926): 18 results  (0.19636) 8 time  (0.10598) 10 networks  (0.08338) 16 error  (0.06079) 5 data  (0.06079) 11 training  (0.03819) 12 algorithm  (0.03819) 0 network  (0.03819) 7 figure  (0.03819) 2 model  (0.03819)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

774: Kohonen Feature Maps and Growing Cell Structures--a Performance Comparison
    id = 588
    authors = Fritzke_B 
    12 (0.22755): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.17486): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.13722): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

775: A Back-Propagation Algorithm with Optimal Use of Hidden Units
    id = 149
    authors = Chauvin_Y 
    3 (0.28401): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.23132): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.11464): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.04690): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.03184): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

776: Hidden Markov Models in Molecular Biology: New Algorithms and Applications
    id = 664
    authors = Baldi_P Chauvin_Y Hunkapiller_T McClure_M 
    3 (0.22755): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.21626): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.19744): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.09959): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    41 (0.00926): 2 model  (0.12656) 9 set  (0.07952) 24 performance  (0.07952) 6 function  (0.03247) 7 figure  (0.03247) 5 data  (0.03247) 22 models  (0.03247) 8 time  (0.03247) 10 networks  (0.03247) 0 network  (0.03247)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

777: Dopaminergic Neuromodulation Brings a Dynamical Plasticity to the Retina
    id = 770
    authors = Boussard_E Vibert_J 
    5 (0.49101): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.22755): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    12 (0.05066): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.00549): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

778: Neural Control for Rolling Mills: Incorporating Domain Theories to Overcome Data Deficiency
    id = 509
    authors = Holmann_R Roscheisen_M Tresp_V 
    9 (0.27648): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.19368): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.14475): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.07324): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

779: Simulation of the Neocognitron on a CCD Parallel Processing Architecture . . .
    id = 427
    authors = Chiang_A Chuang_M 
    6 (0.26895): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.23132): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.11841): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

780: When Is an Integrate-and-fire Neuron like a Poisson Neuron?
    id = 998
    authors = Stevens_C Zador_A 
    6 (0.20873): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.17110): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.10711): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    11 (0.09959): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.02808): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.01679): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

781: INFERRING GROUND TRUTH FROM SUBJECTIVE LABELLING OF VENUS IMAGES
    id = 978
    authors = Baldi_P Burl_M Fayyad_U Perona_P Smyth_P 
    7 (0.36305): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    13 (0.26143): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.10711): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

782: Unsupervised Learning of Mixtures of Multiple Causes in Binary Data
    id = 703
    authors = Saund_E 
    1 (0.29906): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.20873): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.05819): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.04313): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.03937): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

783: Time-Warping Network: A Hybrid Framework for Speech Recognition
    id = 447
    authors = Bocchieri_E Levin_E Pieraccini_R 
    11 (0.30659): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.21250): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    22 (0.17486): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)
    9 (0.05442): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

784: Analog Neural Networks of Limited Precision I: Computing with Multilinear Threshold Functions
    id = 270
    authors = Obradovic_Z Parberry_I 
    10 (0.20873): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.13346): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.11464): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.06948): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.06571): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

785: Lance M. Optican, and 3oels Kjter Learning How to Teach or Selecting Minimal Surface Data
    id = 473
    authors = Geiger_D Pereira_R 
    9 (0.25014): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.24261): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.06948): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.02431): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

786: Basins of Attraction for Electronic Neural Networks
    id = 54
    authors = Marcus_C Westervelt_R 
    3 (0.66414): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

787: Stability Results for Neural Networks
    id = 57
    authors = Farrell_J Michel_A Porod_W 
    6 (0.32917): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.25766): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.03560): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

788: Cricket Wind Detection
    id = 184
    authors = Miller_J 
    0 (0.32917): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.26895): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    18 (0.04313): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

789: JANUS: Speech-to-Speech Translation Using Connectionist and Non-Connectionist Techniques
    id = 451
    authors = Jain_A McNair_A Osterholtz_L Saito_H Schmidbauer_O Sloboda_T Tebelskis_J Waibel_A Woszczyna_M 
    2 (0.22755): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.18615): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.14475): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.10335): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    3 (0.05442): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.04313): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.02431): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

790: Induction of Finite-State Automata Using Second-Order Recurrent Networks
    id = 466
    authors = Kuhn_G Watrous_R 
    5 (0.18615): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.18239): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.17863): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.17486): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.02808): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

791: Unsupervised Learning in Neurodynamics Using the Phase Velocity Field Approach
    id = 255
    authors = Toomarian_N Zak_M 
    10 (0.18615): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.17486): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.14099): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.08453): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.07701): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.02431): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

792: Comparing the Performance of Connectionist and Statistical Classifiers on an Image Segmentation Problem
    id = 259
    authors = Blanz_W Gish_S 
    5 (0.29530): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.11841): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    35 (0.09959): 18 results  (0.19636) 8 time  (0.10598) 10 networks  (0.08338) 16 error  (0.06079) 5 data  (0.06079) 11 training  (0.03819) 12 algorithm  (0.03819) 0 network  (0.03819) 7 figure  (0.03819) 2 model  (0.03819)
    6 (0.08830): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    7 (0.02808): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

793: Foraging in an Uncertain Environment Using Predictive Hebbian Learning
    id = 775
    authors = Dayan_P Montague_P Sejnowski_T 
    1 (0.29906): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.22755): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.13722): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.11088): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

794: A Method for Learning from Hints
    id = 582
    authors = Abu-Mostafa_Y 
    8 (0.20121): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.19744): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.16733): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.13346): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

795: Transient Signal Detection with Neural Networks: The Search for the Desired Signal
    id = 657
    authors = Principe_J Zahalka_A 
    2 (0.25766): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.18615): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.12217): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    30 (0.07701): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    7 (0.03560): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

796: Agnostic PAC-Leaming of Functions on Analog Neural Nets
    id = 739
    authors = Maass_W 
    1 (0.24261): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.15981): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.14475): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.08077): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    30 (0.05442): 5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000)
    4 (0.05066): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.01302): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

797: Unsupervised Classifiers, Mutual Information and 'Phantom Targets' .
    id = 563
    authors = Bridle_J Heading_A MacKay_D 
    13 (0.38563): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    11 (0.17863): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.09959): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.08453): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

798: Flight Control in the Dragonfly: A Neurobiological Simulation .
    id = 355
    authors = Faller_W Luttges_M 
    4 (0.44585): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.06571): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

799: Constraints on Adaptive Networks for Modeling Human Generalization
    id = 90
    authors = Gluck_M Henkle_V Pavel_M 
    11 (0.49854): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.20497): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

800: Learning in Networks of Nondeterministic Adaptive Logic Elements
    id = 87
    authors = Windecker_R 
    3 (0.24261): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.11841): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.04690): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

801: Don Montgomery, and Mark Saffman Principles of Risk Minimization for Learning Theory
    id = 530
    authors = Vapnik_V 
    3 (0.23884): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.21250): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.15604): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.12593): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

802: COMPARING THE PREDICTION ACCURACY OF ARTIFICIAL NEURAL NETWORKS AND OTHER STATISTICAL MODELS FOR BREAST CANCER SURVIVAL
    id = 975
    authors = Burke_H Goodman_P Rosen_D 
    5 (0.27272): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.11841): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.09206): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.08453): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.06571): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.01679): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

803: REINFORCEMENT LEARNING W1TH SOFT STATE AGGREGATION
    id = 888
    authors = Jaakkola_T Jordan_M Singh_S 
    1 (0.18239): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.17863): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.17486): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.15228): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.04690): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.01302): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

804: Discovering High Order Features with Mean Field Modules
    id = 246
    authors = Galland_C Hinton_G 
    2 (0.18615): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.17110): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.14852): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    25 (0.10711): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    3 (0.07701): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.06948): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

805: Adaptive Neural Networks Using MOS Charge Storage
    id = 177
    authors = Howard_R Hubbard_W Schwartz_D 
    9 (0.25766): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.23132): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.11088): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

806: Optimization with Artificial Neural Network Systems: A Mapping Principle and a Comparison to Gradient Based Methods
    id = 49
    authors = Leong_H 
    2 (0.29906): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.09582): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.08830): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.08077): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.06195): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.05442): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

807: Optimal Stopping and Effective Machine Complexity in Learning
    id = 738
    authors = Judd_J Venkatesh_S Wang_C 
    8 (0.37057): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.19744): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.10335): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.09959): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

808: Song Learning in Birds
    id = 182
    authors = Konishi_M 
    10 (0.18239): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.17110): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    22 (0.08453): 20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.03937): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

809: Neuromorphic Networks Based on Sparse Optical Orthogonal Codes
    id = 84
    authors = Salehi_J Vecchi_M 
    6 (0.31788): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.18615): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.14099): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

810: Practical Characteristics of Neural Network and Conventional Pattern Classifiers.
    id = 417
    authors = Lippmann_R Ng_K 
    3 (0.32541): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.30659): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.12217): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

811: TRAFFIC: Recognizing Objects Using Hierarchical Reference Frame Transformations
    id = 217
    authors = Hinton_G Mozer_M Zemel_R 
    18 (0.37810): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    4 (0.20121): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.09206): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.05819): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

812: A GROWING NEURAL GAS NETWORK LEARNS TOPOLOGIES
    id = 921
    authors = Fritzke_B 
    10 (0.30283): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.14475): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.08077): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    20 (0.07701): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.05066): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

813: Integrated Modeling and Control Based on Reinforcement Learning .
    id = 349
    authors = Sutton_R 
    4 (0.22755): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.21626): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.15228): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.09206): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.06948): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    21 (0.01302): 23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

814: A Computational Mechanism to Account for Averaged Modified Hand Trajectories
    id = 504
    authors = Flash_T Henis_E 
    3 (0.27272): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.16357): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.12217): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.11464): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.08830): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

815: LEARNING TO PLAY THE GAME OF CHESS
    id = 976
    authors = Thmn_S 
    1 (0.23884): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.18239): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.14852): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.05442): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.05066): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

816: Statistical Modeling of Cell-Assemblies Activities in Associative Cortex of Behaving Monkeys
    id = 688
    authors = Gat_I Tishby_N 
    6 (0.34046): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.14099): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.12217): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.09582): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    11 (0.06571): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.02055): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

817: A Reconfigurable Analog VLSI Neural Network Chip
    id = 277
    authors = Graf_H Satyanarayana_S Tsividis_Y 
    7 (0.20873): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    9 (0.14852): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.12593): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.10335): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.09582): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.05442): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

818: Visual Motion Computation in Analog VLSI using Pulses
    id = 668
    authors = Bair_W Koch_C Sarpeshkar_R 
    8 (0.29154): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.17486): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.12593): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.11088): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.06571): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

819: ASYMPTOTICS OF GRADIENT-BASED NEURAL NETWORK TRAINING ALGORITHMS
    id = 885
    authors = Fine_T Mukherjee_S 
    9 (0.44585): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.25766): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.05066): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

820: Structural Risk Minimization for Character Recognition
    id = 486
    authors = Boser_B Bottou_L Guyon_I Solla_S Vapnik_V 
    9 (0.27648): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.19368): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.12217): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.05066): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.03937): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

821: COMBINING ESTIMATORS USING NON-CONSTANT WEIGHTING FUNCTIONS
    id = 895
    authors = Taniguchi_M Tresp_V 
    10 (0.27648): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.14852): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.12217): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.08830): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

822: Perturbing Hebbian Rules
    id = 431
    authors = Dayan_P Goodhill_G 
    3 (0.27648): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.20497): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.09206): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.02808): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

823: EFFECTS OF NOISE ON CONVERGENCE AND GENERALIZATION IN RECURRENT NETWORKS
    id = 924
    authors = Giles_C Horne_B Jim_K 
    5 (0.23508): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.17863): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.11088): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    7 (0.06195): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.02431): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

824: Visual Grammars and their Neural Nets
    id = 481
    authors = Mjolsness_E 
    0 (0.46090): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.16733): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.06948): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.05442): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.01679): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

825: Repeat Until Bored: A Pattern Selection Strategy
    id = 551
    authors = Munro_P 
    12 (0.24261): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.17863): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.17486): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.16733): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

826: Backpropagation Convergence via Deterministic Nonmonotone Perturbed Minimization
    id = 748
    authors = Mangasarian_O Solodov_M 
    2 (0.32541): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.18239): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.05066): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

827: Natural Dolphin Echo Recognition Using an Integrator Gateway Network.
    id = 322
    authors = Moore_P Nachtigall_P Penner_R Roitblat_H 
    1 (0.29906): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.17486): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.12217): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.10711): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.07701): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

828: Static and Dynamic Error Propagation Networks with Application to Speech Coding
    id = 65
    authors = Fallside_F Robinson_A 
    1 (0.40068): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.16357): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.12593): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.03560): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.03184): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.02808): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

829: A Delay-Line Based Motion Detection Chip .
    id = 340
    authors = Horiuchi_T Koch_C Lazzaro_J Moore_A 
    0 (0.16357): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.15228): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.08077): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.07701): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.07324): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.06195): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.05066): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.04313): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)

830: Generalization by Weight-Elimination with Application to Forecasting .
    id = 404
    authors = Huberman_B Rumelhart_D Weigend_A 
    2 (0.28401): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.17110): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.10711): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.09959): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    34 (0.06195): 5 data  (0.15117) 12 algorithm  (0.12857) 17 state  (0.10598) 18 results  (0.08338) 8 time  (0.06079) 1 learning  (0.06079) 19 units  (0.06079) 14 number  (0.03819) 2 model  (0.03819) 3 neural  (0.03819)
    0 (0.03937): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

831: From Speech Recognition to Spoken Language Understanding .
    id = 320
    authors = Glass_J Goodine_D Hirschman_L Leung_H Phillips_M Polifroni_J Seneft_S Zue_V 
    13 (0.34799): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    3 (0.15604): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.15228): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

832: Compact EEPROM-based Weight Functions ..
    id = 421
    authors = Chu_R Ko_P Kramer_A Sin_C 
    2 (0.43456): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    1 (0.12970): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.10335): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.08077): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

833: Exploiting Syllable Structure in a Connectionist Phonology Model ..
    id = 369
    authors = Touretzky_D Wheeler_D 
    3 (0.27648): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.21250): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.12217): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.08453): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.08453): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

834: The Hopfield Model with Multi-Level Neurons
    id = 29
    authors = Fleisher_M 
    2 (0.50983): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.23132): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00926): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    11 (0.00549): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

835: SINGLE TRANSISTOR LEARNING SYNAPSES
    id = 945
    authors = Hasler_P 
    0 (0.35928): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.28777): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.09582): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    4 (0.02808): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

836: Oscillatory Neural Fields for Globally Optimal Path Planning
    id = 494
    authors = Lemmon_M 
    9 (0.26895): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.18992): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.09206): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.07701): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.06195): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    10 (0.06195): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    6 (0.02808): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

837: Meiosis Networks
    id = 249
    authors = Hanson_S 
    4 (0.26895): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.26519): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.15981): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.05819): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.02808): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

838: Computing Motion Using Resistive Networks
    id = 44
    authors = Hutchinson_J Koch_C Luo_J Mead_C 
    1 (0.39692): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    0 (0.19368): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.11464): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.00926): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

839: Phonetic Classification and Recognition Using the Multi-Layer Perceptton .
    id = 319
    authors = Glass_J Leung_H Phillips_M Zue_V 
    10 (0.35176): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.24261): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.15604): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.01679): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

840: Stochastic Learning Networks and their Electronic Implementation
    id = 1
    authors = Allen_R Alspector_J Hu_V Satyanarayana_S 
    5 (0.16357): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    4 (0.16357): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.16357): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.09959): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.07701): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.07324): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.03560): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)

841: Exploratory Feature Extraction in Speech Signals .
    id = 318
    authors = Intrator_N 
    3 (0.32541): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.17486): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    6 (0.11464): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    14 (0.08077): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.04313): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.03184): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    25 (0.00926): 17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

842: Obstacle Avoidance through Reinforcement Learning
    id = 492
    authors = Mayhew_J Prescott_T 
    2 (0.31036): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    12 (0.20873): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.14852): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    3 (0.05819): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.02808): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

843: Neural Net and Traditional Classifiers
    id = 40
    authors = Huang_W Lippmann_R 
    12 (0.27272): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    11 (0.22003): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.16357): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.10711): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    17 (0.01679): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

844: GROUPING COMPONENTS OF THREE-DIMENSIONAL MOVING OBJECTS IN AREA MST OF VISUAL CORTEX
    id = 864
    authors = Sejnowski_T Zemel_R 
    5 (0.26519): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.20497): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    19 (0.17863): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    2 (0.11088): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

845: A Neural Network for Motion Detection of Drift-Balanced Stimuli
    id = 516
    authors = Tunley_H 
    5 (0.20873): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.17486): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    3 (0.08830): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.08830): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    4 (0.07701): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.07324): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.03937): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.01679): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)

846: Some Approximation Properties of Projection Pursuit Learning Networks
    id = 543
    authors = Atkeson_C Zhao_Y 
    7 (0.37810): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.09582): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.06571): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

847: Adaptive Knot Placement for Nonparametric Regression
    id = 731
    authors = Cherkassky_V Najafi_H 
    3 (0.55876): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.11464): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    7 (0.05819): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.02431): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

848: Metamorphosis Networks: An Alternative to Constructive Models
    id = 589
    authors = Bonnlander_B Mozer_M 
    5 (0.28777): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.24637): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.15604): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.06948): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

849: BIAS, VARIANCE AND THE COMBINATION OF LEAST SQUARES ESTIMATORS
    id = 880
    authors = Meir_R 
    7 (0.34046): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.18239): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.10335): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.05066): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    11 (0.04690): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.04313): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

850: FINDING STRUCTURE IN REINFORCEMENT LEARN1NG
    id = 891
    authors = Schwartz_A Thrun_S 
    1 (0.40068): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    4 (0.19744): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.07324): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.06195): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.02808): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

851: Stochastic Neurodynamics .
    id = 294
    authors = Cowen_J 
    2 (0.35552): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.12217): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.11464): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.06948): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    13 (0.03184): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

852: Generalization Properties of Radial Basis Functions .
    id = 381
    authors = Atkeson_C Botros_S 
    2 (0.21250): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.20121): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    8 (0.15981): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.14475): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.02431): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    0 (0.02431): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

853: Unsmearing Visual Motion: Development of Long-Range Horizontal Intrinsic Connections
    id = 624
    authors = Marshall_J Martin_K 
    11 (0.28777): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.24637): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.08830): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.06571): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

854: Reinforcement Learning Applied to Linear Quadratic Regulation
    id = 609
    authors = Bradtke_S 
    0 (0.28025): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    7 (0.18992): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.12970): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    10 (0.08077): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    5 (0.07324): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.02808): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    14 (0.00926): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

855: A Low-Power CMOS Circuit Which Emulates Temporal Electrical Properties of Neurons
    id = 168
    authors = Cole_C Meador_J 
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.17110): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.08077): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.01679): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

856: Adaptive Spline Networks .
    id = 377
    authors = Freidman_J 
    0 (0.22003): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.22003): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.13346): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.10335): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    8 (0.05819): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

857: A RAPID GRAPH-BASED METHOD FOR ARBITRARY TRANSFORMATION-INVARIANT PATFERN CLASSIFICATION
    id = 926
    authors = Sperduti_A Stork_D 
    1 (0.27648): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.13346): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.12970): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    12 (0.08830): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.05819): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.01302): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

858: Spiral Waves in Integrate-and-Fire Neural Networks
    id = 695
    authors = Chu_P Cowan_J Milton_J 
    0 (0.32165): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.17486): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.17486): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.02431): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.01679): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    3 (0.00926): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

859: Discriminability-Based Transfer between Neural Networks
    id = 598
    authors = Pratt_L 
    7 (0.32917): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.17863): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.10711): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    1 (0.02808): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

860: Encoding Labeled Graphs by Labeling RAAM
    id = 840
    authors = Sperduti_A 
    3 (0.20873): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.20121): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    5 (0.17486): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    24 (0.04690): 9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.02055): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

861: On the Use of Projection Pursuit Constraints for Training Neural Networks
    id = 573
    authors = Intrator_N 
    1 (0.39316): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.13722): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.11088): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    32 (0.07324): 14 number  (0.22966) 4 input  (0.08488) 12 algorithm  (0.08488) 13 output  (0.04869) 16 error  (0.04869) 2 model  (0.04869) 5 data  (0.04869) 24 performance  (0.04869) 20 information  (0.04869) 3 neural  (0.03059)
    0 (0.05066): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.02055): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

862: Design and Implementation of a High Speed CMAC Neural Network .
    id = 424
    authors = Box_B Glynn_J Miller_W Whitney_E 
    1 (0.18239): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.14099): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.12593): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.11088): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.09582): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.05819): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    13 (0.04690): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.02055): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)

863: Gradient Descent: Second Order Momentum and Saturating Error
    id = 537
    authors = Pearlmutter_B 
    6 (0.36305): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    3 (0.20497): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    5 (0.16733): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.03184): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

864: Speech Recognition using Connectionist Approaches .
    id = 321
    authors = Choukri_K 
    3 (0.44585): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    9 (0.20873): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    7 (0.09959): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    10 (0.01302): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

865: On the Use of Evidence in Neural Networks
    id = 639
    authors = Wolpert_D 
    8 (0.38563): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.15604): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    13 (0.15604): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    10 (0.06195): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    0 (0.02055): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

866: Dataflow Architectures: Flexible Platforms for Neural Network Simulation
    id = 284
    authors = Smotroff_I 
    10 (0.25014): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.16733): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.15604): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    11 (0.12593): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.04313): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.02431): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

867: Grammatical Inference by Attentional Control of Synchronization in an Oscillating Elman Network
    id = 708
    authors = Baird_B Eeckman_F Troyer_T 
    11 (0.33670): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.21626): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.09959): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.09206): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.02055): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.00926): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    13 (0.00926): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

868: Programmable Analog Pulse-Firing Neural Networks
    id = 167
    authors = Hamilton_A Murray_A Tarassenko_L 
    0 (0.22755): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    14 (0.17863): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    5 (0.15981): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.06948): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.06195): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    13 (0.01302): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

869: Learning the Solution to the Aperture Problem for Pattern Motion with a Hebb Rule
    id = 143
    authors = Sereno_M 
    0 (0.21626): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.17863): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.12970): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.09959): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    3 (0.06948): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    2 (0.05442): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

870: The Boltzmann Perceptron Network: A Multi-Layered Feed-Forward Network Equivalent to the Boltzmann Machine
    id = 103
    authors = Gersho_A Yair_E 
    0 (0.36305): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    9 (0.36305): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    8 (0.01679): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

871: Classification of Multi-Spectral Pixels by the Binary Diamond Neural Network
    id = 842
    authors = Salu_Y 
    4 (0.52112): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.10335): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.09959): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    6 (0.04313): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.00926): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

872: Rapid Quality Estimation of Neural Network Input Representations
    id = 990
    authors = Cherkauer_K Shavlik_J 
    11 (0.50230): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.10335): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.05819): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    8 (0.04690): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.03937): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.02055): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

873: Multi-Layer Perceptrons with B-Spline Receptive Field Functions .
    id = 378
    authors = Flax_M Gelfand_J Handelman_D Lane_S 
    4 (0.22003): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    1 (0.20497): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    5 (0.18239): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.15981): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    8 (0.00926): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.00926): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

874: Learning Temporal Dependencies in Connectionist Speech Recognition
    id = 831
    authors = Hochberg_M Renals_S Robinson_T 
    9 (0.23884): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.16357): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    26 (0.12593): 3 neural  (0.21238) 8 time  (0.12636) 6 function  (0.08335) 12 algorithm  (0.04895) 4 input  (0.04895) 22 models  (0.04895) 14 number  (0.04034) 23 hidden  (0.04034) 17 state  (0.04034) 7 figure  (0.03174)
    5 (0.09959): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.06571): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    12 (0.06195): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

875: Analog Circuits for Conslxained Optimization
    id = 279
    authors = Platt_J 
    3 (0.29530): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    1 (0.17486): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    17 (0.15228): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    10 (0.07324): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.03937): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    18 (0.02808): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.01302): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

876: Speaker Independent Speech Recognition with Neural Networks and Speech Knowledge
    id = 211
    authors = Bengio_Y Cardin_R De-Mori_R 
    2 (0.48349): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.20497): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.03560): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    9 (0.03560): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    12 (0.02055): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

877: Designing Linear Threshold Based Neural Network Pattern Classifiers .
    id = 395
    authors = Fine_T 
    5 (0.17486): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.13346): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    10 (0.12217): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.09959): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.08453): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.06948): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.03184): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    41 (0.00926): 2 model  (0.12656) 9 set  (0.07952) 24 performance  (0.07952) 6 function  (0.03247) 7 figure  (0.03247) 5 data  (0.03247) 22 models  (0.03247) 8 time  (0.03247) 10 networks  (0.03247) 0 network  (0.03247)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

878: A Lagrangian Approach to Fixed Points .
    id = 296
    authors = Miranker_W Mjolsness_E 
    6 (0.18615): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.18615): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.17486): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    9 (0.12593): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.07701): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    11 (0.02808): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    0 (0.01302): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

879: A Computer Simulation of Olfactory Cortex with Functional Implications for Storage and Retrieval of Olfactory Information
    id = 11
    authors = Bower_J Wilson_M 
    0 (0.23508): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.22379): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    7 (0.18239): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    10 (0.13346): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

880: Towards an Organizing Principle for a Layered Perceptual Network
    id = 50
    authors = Linsker_R 
    11 (0.31788): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    9 (0.20121): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.12970): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.08077): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    3 (0.02055): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.01679): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

881: Mapping Classifier Systems Into Neural Networks
    id = 95
    authors = Davis_L 
    8 (0.25766): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.25014): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.10711): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    10 (0.03937): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

882: Unsupervised Discrimination of Clustered Data via Optimization of Binary Information Gain
    id = 634
    authors = Schraudolph_N Sejnowski_T 
    1 (0.37434): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    6 (0.28777): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    2 (0.08077): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    11 (0.02055): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.00926): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

883: Discovering Discrete Distributed Representations .
    id = 371
    authors = Mozer_M 
    4 (0.26519): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.23884): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    5 (0.13346): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    2 (0.06948): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    0 (0.05442): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    1 (0.01302): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    16 (0.00926): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)

884: The CHIR Algorithm for Feed Forward Networks with Binary Weights
    id = 247
    authors = Grossman_T 
    5 (0.25014): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    12 (0.18239): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    6 (0.11841): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.09206): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    9 (0.05066): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

885: Learning to See Where and What: Training a Net to Make Saccades and Recognize Handwritten Characters
    id = 627
    authors = Chapman_D Martin_G Pittman_J Rashid_M 
    12 (0.43832): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    0 (0.22379): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    8 (0.05066): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    6 (0.04313): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    7 (0.02055): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

886: A MODEL FOR CHEMOSENSORY RECEPTION
    id = 851
    authors = Hammer_M Malaka_R Ragg_T 
    11 (0.30283): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    1 (0.22003): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.15981): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    5 (0.03184): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)

887: Model Based Image Compression and Adaptive Data Representation by Interacting Filter Banks
    id = 221
    authors = Inui_T Kawato_M Miyake_S Okamoto_T 
    10 (0.28401): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.24637): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.23884): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    12 (0.00549): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

888: Generalization and Parameter Estimation in Feedforward Nets: Some Experiments
    id = 261
    authors = Bourlard_H Morgan_N 
    12 (0.53618): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    7 (0.12970): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.06571): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    11 (0.00926): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    20 (0.00549): 23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)

889: A Connectionist Expert System that Actually Works
    id = 118
    authors = Bradshaw_G Ceci_L Fozzard_R 
    8 (0.37810): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    15 (0.21626): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    6 (0.13722): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    12 (0.02431): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    2 (0.01302): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    1 (0.00926): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

890: On the Power of Neural Networks for Solving Hard Problems
    id = 13
    authors = Bruck_J Goodman_J 
    0 (0.36305): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    11 (0.19744): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    6 (0.12217): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    9 (0.04690): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    4 (0.03937): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)

891: HYPERPARAMETERS, EVIDENCE AND GENERALISATION FOR AN UNREALISABLE RULE
    id = 875
    authors = Marion_G Saad_D 
    11 (0.29530): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    2 (0.12970): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    9 (0.12217): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    5 (0.11841): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    10 (0.05442): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    1 (0.03937): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.02808): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

892: Back Propagation is Sensitive to Initial Conditions .
    id = 402
    authors = Kolen_J Pollack_J 
    2 (0.22379): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    3 (0.11464): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    19 (0.11464): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    10 (0.09582): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    4 (0.09206): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    7 (0.07701): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    6 (0.03937): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    0 (0.03184): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    5 (0.01302): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

893: LEARNING PROTOTYPE MODELS FOR TANGENT DISTANCE
    id = 967
    authors = Hastie_T Sackinger_E Simard_P 
    2 (0.31412): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    8 (0.17110): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    4 (0.09959): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    5 (0.09582): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    3 (0.05442): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    10 (0.03560): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    9 (0.02055): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)

894: Networks for the Separation of Sources that are Superimposed and Delayed . .
    id = 518
    authors = Faggin_F Platt_J 
    12 (0.25014): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    5 (0.17110): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    0 (0.15228): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    4 (0.10711): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    11 (0.09959): 5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698)
    14 (0.00549): 24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    13 (0.00549): 23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424)
    19 (0.00549): 0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010)
    18 (0.00549): 9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088)

895: Probabilistic Anomaly Detection in Dynamic Systems
    id = 803
    authors = Smyth_P 
    1 (0.30659): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    10 (0.19368): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    3 (0.14852): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.11088): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    4 (0.01302): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.00926): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

896: Use of Bad Training Data for Better Predictions
    id = 743
    authors = Grossman_T Lapedes_A 
    4 (0.20873): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.19744): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    12 (0.17486): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    8 (0.11841): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    1 (0.05066): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    3 (0.02431): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    7 (0.00926): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    2 (0.00926): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    6 (0.00926): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

897: Cross-Validation Estimates IMSE
    id = 749
    authors = Plutowski_M Sakata_S White_H 
    2 (0.39316): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    4 (0.12970): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    15 (0.10335): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    1 (0.07701): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    7 (0.04690): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.01679): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    8 (0.01302): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    17 (0.00926): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

898: Learning in the Vestibular System: Simulations of Vestibular Compensation Using Recurrent Back-Propagation
    id = 502
    authors = Anastasio_T 
    1 (0.36681): 7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829)
    9 (0.18615): 21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667)
    10 (0.13346): 16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696)
    8 (0.05442): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    2 (0.01679): 7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531)
    7 (0.01302): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    3 (0.01302): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    12 (0.01302): 14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275)
    15 (0.00549): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    16 (0.00549): 3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203)

899: GRAMMAR LEARNING BY A SELF-ORGANIZING NETWORK
    id = 847
    authors = Negishi_M 
    7 (0.32917): 10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328)
    15 (0.20497): 11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494)
    4 (0.08453): 17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443)
    0 (0.05819): 1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841)
    3 (0.03937): 4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922)
    6 (0.03560): 18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326)
    8 (0.02055): 12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426)
    5 (0.01679): 23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914)
    41 (0.01302): 2 model  (0.12656) 9 set  (0.07952) 24 performance  (0.07952) 6 function  (0.03247) 7 figure  (0.03247) 5 data  (0.03247) 22 models  (0.03247) 8 time  (0.03247) 10 networks  (0.03247) 0 network  (0.03247)
    17 (0.00549): 19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661)

0 (4.89488 / 45):  1 learning  (0.15795) 0 network  (0.15307) 4 input  (0.14676) 3 neural  (0.14406) 2 model  (0.13809) 20 information  (0.02742) 13 output  (0.02231) 10 networks  (0.02059) 6 function  (0.01858) 5 data  (0.01841) 21 problem  (0.01778) 11 training  (0.01755) 16 error  (0.01450) 8 time  (0.01428) 23 hidden  (0.01410) 15 system  (0.01376) 14 number  (0.01370) 18 results  (0.00848) 17 state  (0.00842) 7 figure  (0.00681)
1 (4.71150 / 45):  7 figure  (0.15825) 22 models  (0.15586) 2 model  (0.15228) 12 algorithm  (0.14990) 17 state  (0.14984) 21 problem  (0.02133) 14 number  (0.02032) 24 performance  (0.02032) 9 set  (0.01948) 1 learning  (0.01829) 16 error  (0.01775) 6 function  (0.01632) 11 training  (0.01507) 19 units  (0.01423) 8 time  (0.01310) 4 input  (0.01203) 10 networks  (0.00922) 5 data  (0.00738) 20 information  (0.00666) 23 hidden  (0.00559)
2 (4.67522 / 45):  7 figure  (0.16038) 9 set  (0.15226) 6 function  (0.15076) 8 time  (0.14613) 5 data  (0.14373) 12 algorithm  (0.01933) 13 output  (0.01789) 1 learning  (0.01765) 22 models  (0.01735) 3 neural  (0.01531) 2 model  (0.01495) 21 problem  (0.01464) 10 networks  (0.01290) 19 units  (0.01218) 24 performance  (0.01194) 4 input  (0.01170) 20 information  (0.01164) 11 training  (0.01134) 0 network  (0.01032) 17 state  (0.00996)
3 (4.46738 / 45):  4 input  (0.14846) 9 set  (0.14494) 24 performance  (0.14054) 19 units  (0.13764) 14 number  (0.13142) 0 network  (0.03495) 15 system  (0.02080) 5 data  (0.02017) 2 model  (0.01985) 22 models  (0.01922) 20 information  (0.01891) 16 error  (0.01841) 6 function  (0.01809) 10 networks  (0.01797) 1 learning  (0.01463) 21 problem  (0.01394) 18 results  (0.01287) 3 neural  (0.01256) 7 figure  (0.01187) 12 algorithm  (0.01099)
4 (4.04241 / 45):  17 state  (0.16363) 15 system  (0.15807) 18 results  (0.15724) 19 units  (0.15529) 16 error  (0.14980) 12 algorithm  (0.01846) 23 hidden  (0.01798) 10 networks  (0.01784) 3 neural  (0.01589) 8 time  (0.01443) 21 problem  (0.01395) 11 training  (0.01318) 22 models  (0.01270) 24 performance  (0.01138) 1 learning  (0.01124) 0 network  (0.00992) 14 number  (0.00873) 5 data  (0.00755) 13 output  (0.00728) 7 figure  (0.00728)
5 (3.85622 / 45):  23 hidden  (0.16504) 22 models  (0.15972) 24 performance  (0.14748) 21 problem  (0.14304) 20 information  (0.14173) 7 figure  (0.03691) 2 model  (0.02846) 6 function  (0.02088) 12 algorithm  (0.02045) 8 time  (0.01914) 9 set  (0.01746) 17 state  (0.01746) 3 neural  (0.01309) 5 data  (0.01265) 4 input  (0.01120) 14 number  (0.01098) 16 error  (0.00916) 11 training  (0.00755) 10 networks  (0.00697) 1 learning  (0.00406)
6 (3.71363 / 45):  18 results  (0.13635) 13 output  (0.12160) 3 neural  (0.12069) 8 time  (0.10322) 23 hidden  (0.09853) 17 state  (0.05073) 19 units  (0.04415) 15 system  (0.03893) 16 error  (0.03568) 14 number  (0.03326) 4 input  (0.02879) 12 algorithm  (0.02766) 11 training  (0.01987) 7 figure  (0.01972) 2 model  (0.01904) 10 networks  (0.01768) 0 network  (0.01768) 1 learning  (0.01631) 20 information  (0.01578) 6 function  (0.00951)
7 (3.50353 / 45):  10 networks  (0.17169) 20 information  (0.17097) 15 system  (0.16512) 5 data  (0.16223) 0 network  (0.15982) 14 number  (0.01801) 16 error  (0.01609) 11 training  (0.01609) 13 output  (0.01328) 21 problem  (0.01328) 12 algorithm  (0.01240) 1 learning  (0.01088) 18 results  (0.01032) 4 input  (0.00951) 2 model  (0.00791) 19 units  (0.00791) 6 function  (0.00735) 3 neural  (0.00703) 17 state  (0.00599) 8 time  (0.00334)
8 (3.26363 / 45):  12 algorithm  (0.16648) 14 number  (0.16252) 13 output  (0.16140) 10 networks  (0.16028) 11 training  (0.15951) 22 models  (0.02441) 7 figure  (0.02080) 15 system  (0.01985) 5 data  (0.01512) 0 network  (0.01426) 17 state  (0.01236) 1 learning  (0.01219) 2 model  (0.01202) 24 performance  (0.01047) 8 time  (0.01021) 23 hidden  (0.00909) 18 results  (0.00746) 20 information  (0.00660) 16 error  (0.00522) 6 function  (0.00247)
9 (2.94272 / 45):  21 problem  (0.18661) 11 training  (0.15245) 1 learning  (0.14939) 16 error  (0.14834) 6 function  (0.14634) 22 models  (0.02821) 20 information  (0.02487) 24 performance  (0.02449) 23 hidden  (0.02373) 12 algorithm  (0.01667) 5 data  (0.01342) 0 network  (0.01190) 13 output  (0.01056) 3 neural  (0.00980) 14 number  (0.00942) 2 model  (0.00923) 15 system  (0.00875) 9 set  (0.00808) 10 networks  (0.00732) 19 units  (0.00302)
10 (2.82994 / 45):  16 error  (0.16546) 1 learning  (0.14145) 11 training  (0.13192) 6 function  (0.11992) 21 problem  (0.09730) 17 state  (0.05325) 19 units  (0.05186) 18 results  (0.04620) 15 system  (0.03618) 2 model  (0.02696) 4 input  (0.02517) 0 network  (0.02477) 24 performance  (0.01803) 9 set  (0.01356) 12 algorithm  (0.01108) 3 neural  (0.00949) 5 data  (0.00801) 7 figure  (0.00582) 10 networks  (0.00533) 14 number  (0.00304)
11 (2.62434 / 45):  5 data  (0.11004) 0 network  (0.09014) 15 system  (0.09014) 3 neural  (0.08576) 20 information  (0.08405) 8 time  (0.08191) 18 results  (0.08030) 10 networks  (0.07784) 23 hidden  (0.06736) 13 output  (0.05698) 9 set  (0.03923) 7 figure  (0.01837) 2 model  (0.01815) 4 input  (0.01730) 24 performance  (0.01698) 1 learning  (0.01312) 6 function  (0.01280) 22 models  (0.01098) 17 state  (0.00842) 21 problem  (0.00820)
12 (2.02613 / 45):  14 number  (0.15478) 24 performance  (0.10839) 13 output  (0.08997) 19 units  (0.08955) 4 input  (0.08568) 9 set  (0.07446) 11 training  (0.07418) 12 algorithm  (0.06421) 10 networks  (0.05715) 23 hidden  (0.04275) 8 time  (0.03333) 21 problem  (0.03125) 3 neural  (0.02655) 18 results  (0.02253) 22 models  (0.01644) 6 function  (0.00896) 7 figure  (0.00702) 17 state  (0.00383) 1 learning  (0.00356) 0 network  (0.00300)
13 (1.11459 / 45):  23 hidden  (0.19137) 3 neural  (0.16901) 18 results  (0.16423) 8 time  (0.14439) 13 output  (0.14087) 22 models  (0.03384) 20 information  (0.02153) 1 learning  (0.01826) 21 problem  (0.01475) 5 data  (0.01424) 11 training  (0.01098) 7 figure  (0.01022) 6 function  (0.00997) 16 error  (0.00922) 2 model  (0.00846) 4 input  (0.00746) 0 network  (0.00620) 9 set  (0.00570) 14 number  (0.00545) 24 performance  (0.00344)
14 (0.59822 / 45):  24 performance  (0.14536) 21 problem  (0.14023) 20 information  (0.10012) 23 hidden  (0.09733) 22 models  (0.07028) 9 set  (0.05535) 4 input  (0.05209) 14 number  (0.04416) 19 units  (0.04183) 10 networks  (0.03716) 6 function  (0.03530) 11 training  (0.03297) 13 output  (0.03297) 16 error  (0.02970) 15 system  (0.02038) 7 figure  (0.01851) 5 data  (0.01804) 3 neural  (0.00918) 8 time  (0.00638) 1 learning  (0.00312)
15 (0.24216 / 45):  11 training  (0.11806) 6 function  (0.10782) 13 output  (0.10326) 12 algorithm  (0.08618) 9 set  (0.08504) 7 figure  (0.08163) 1 learning  (0.07252) 19 units  (0.04633) 14 number  (0.03608) 10 networks  (0.03494) 21 problem  (0.03381) 16 error  (0.03267) 24 performance  (0.03039) 4 input  (0.02470) 8 time  (0.02128) 5 data  (0.01445) 17 state  (0.01331) 22 models  (0.01103) 2 model  (0.00989) 18 results  (0.00989)
16 (0.20053 / 45):  3 neural  (0.11460) 24 performance  (0.08996) 13 output  (0.07352) 1 learning  (0.06941) 17 state  (0.06804) 23 hidden  (0.06120) 18 results  (0.05161) 0 network  (0.04887) 22 models  (0.04613) 10 networks  (0.04203) 7 figure  (0.03792) 8 time  (0.03655) 21 problem  (0.03518) 14 number  (0.03244) 6 function  (0.02696) 12 algorithm  (0.02696) 2 model  (0.02286) 19 units  (0.02286) 20 information  (0.01875) 9 set  (0.01875)
17 (0.13809 / 45):  19 units  (0.11547) 8 time  (0.10760) 12 algorithm  (0.09383) 9 set  (0.07809) 3 neural  (0.07809) 11 training  (0.07612) 15 system  (0.07219) 10 networks  (0.06235) 5 data  (0.05251) 6 function  (0.04661) 16 error  (0.03874) 4 input  (0.03677) 17 state  (0.03087) 21 problem  (0.02103) 14 number  (0.02103) 24 performance  (0.01120) 22 models  (0.01120) 13 output  (0.01120) 1 learning  (0.00726) 7 figure  (0.00726)
18 (0.10997 / 45):  9 set  (0.17315) 20 information  (0.11926) 6 function  (0.09722) 5 data  (0.07028) 19 units  (0.05803) 17 state  (0.05558) 24 performance  (0.05313) 16 error  (0.04578) 8 time  (0.04333) 12 algorithm  (0.04088) 13 output  (0.03598) 15 system  (0.03108) 10 networks  (0.02863) 14 number  (0.02863) 7 figure  (0.02619) 0 network  (0.01884) 11 training  (0.01639) 21 problem  (0.01639) 1 learning  (0.01149) 22 models  (0.00904)
19 (0.10519 / 45):  0 network  (0.15256) 20 information  (0.11678) 13 output  (0.10144) 23 hidden  (0.08866) 1 learning  (0.07077) 3 neural  (0.06566) 14 number  (0.05799) 16 error  (0.05033) 17 state  (0.05033) 18 results  (0.04010) 11 training  (0.03755) 24 performance  (0.03755) 22 models  (0.02221) 19 units  (0.01966) 7 figure  (0.01966) 15 system  (0.01966) 8 time  (0.01199) 2 model  (0.00943) 4 input  (0.00688) 10 networks  (0.00688)
20 (0.09759 / 45):  23 hidden  (0.16387) 6 function  (0.08700) 9 set  (0.07602) 1 learning  (0.07327) 20 information  (0.06778) 3 neural  (0.06504) 7 figure  (0.05955) 8 time  (0.05680) 21 problem  (0.05406) 17 state  (0.04307) 24 performance  (0.03758) 19 units  (0.03758) 18 results  (0.03209) 22 models  (0.03209) 16 error  (0.02386) 12 algorithm  (0.02111) 5 data  (0.01837) 10 networks  (0.01288) 4 input  (0.01013) 14 number  (0.00739)
21 (0.07903 / 45):  23 hidden  (0.12637) 24 performance  (0.10625) 8 time  (0.09619) 13 output  (0.09619) 3 neural  (0.09619) 22 models  (0.06267) 21 problem  (0.05261) 6 function  (0.05261) 4 input  (0.04590) 5 data  (0.03920) 9 set  (0.03920) 11 training  (0.02578) 20 information  (0.02578) 7 figure  (0.01908) 0 network  (0.01573) 2 model  (0.01573) 18 results  (0.01573) 12 algorithm  (0.01573) 14 number  (0.01573) 17 state  (0.01237)
22 (0.05569 / 45):  20 information  (0.15651) 4 input  (0.07754) 2 model  (0.06825) 19 units  (0.06360) 22 models  (0.06360) 21 problem  (0.05431) 23 hidden  (0.05431) 1 learning  (0.05431) 6 function  (0.04502) 12 algorithm  (0.04502) 24 performance  (0.04502) 7 figure  (0.04037) 15 system  (0.04037) 11 training  (0.03108) 17 state  (0.02643) 8 time  (0.02179) 10 networks  (0.02179) 5 data  (0.01714) 16 error  (0.01714) 14 number  (0.01714)
23 (0.05259 / 45):  4 input  (0.17963) 2 model  (0.10619) 18 results  (0.08171) 24 performance  (0.08171) 15 system  (0.06702) 14 number  (0.05723) 19 units  (0.05723) 22 models  (0.04255) 17 state  (0.03765) 13 output  (0.03275) 3 neural  (0.03275) 0 network  (0.03275) 6 function  (0.02296) 7 figure  (0.02296) 21 problem  (0.02296) 1 learning  (0.01807) 5 data  (0.01807) 20 information  (0.01807) 12 algorithm  (0.01807) 10 networks  (0.01807)
24 (0.05231 / 45):  9 set  (0.14607) 7 figure  (0.13623) 11 training  (0.12147) 12 algorithm  (0.09195) 22 models  (0.07719) 14 number  (0.05751) 19 units  (0.04768) 10 networks  (0.04276) 24 performance  (0.04276) 4 input  (0.03784) 8 time  (0.03292) 21 problem  (0.03292) 5 data  (0.03292) 6 function  (0.02800) 16 error  (0.01816) 1 learning  (0.01324) 0 network  (0.00832) 20 information  (0.00832) 2 model  (0.00340) 3 neural  (0.00340)
25 (0.04584 / 45):  17 state  (0.21464) 22 models  (0.08150) 2 model  (0.07040) 11 training  (0.07040) 0 network  (0.06485) 13 output  (0.05376) 24 performance  (0.05376) 18 results  (0.04821) 5 data  (0.04266) 12 algorithm  (0.04266) 21 problem  (0.04266) 14 number  (0.03712) 10 networks  (0.03712) 20 information  (0.03157) 15 system  (0.02047) 6 function  (0.02047) 4 input  (0.01492) 3 neural  (0.00938) 19 units  (0.00938) 1 learning  (0.00938)
26 (0.02784 / 45):  3 neural  (0.21238) 8 time  (0.12636) 6 function  (0.08335) 12 algorithm  (0.04895) 4 input  (0.04895) 22 models  (0.04895) 14 number  (0.04034) 23 hidden  (0.04034) 17 state  (0.04034) 7 figure  (0.03174) 19 units  (0.03174) 1 learning  (0.03174) 0 network  (0.03174) 10 networks  (0.02314) 16 error  (0.02314) 2 model  (0.02314) 11 training  (0.02314) 24 performance  (0.01454) 18 results  (0.01454) 15 system  (0.01454)
27 (0.02559 / 45):  19 units  (0.11722) 22 models  (0.09875) 18 results  (0.09875) 21 problem  (0.08951) 16 error  (0.08027) 20 information  (0.08027) 17 state  (0.06180) 23 hidden  (0.06180) 14 number  (0.05256) 5 data  (0.04333) 12 algorithm  (0.03409) 8 time  (0.03409) 6 function  (0.02485) 1 learning  (0.02485) 9 set  (0.01561) 24 performance  (0.01561) 11 training  (0.01561) 15 system  (0.00638) 2 model  (0.00638) 3 neural  (0.00638)
28 (0.02278 / 45):  3 neural  (0.16986) 21 problem  (0.11898) 14 number  (0.10880) 9 set  (0.09862) 2 model  (0.08844) 20 information  (0.07827) 24 performance  (0.06809) 18 results  (0.03756) 8 time  (0.03756) 12 algorithm  (0.03756) 0 network  (0.02738) 4 input  (0.01720) 19 units  (0.01720) 6 function  (0.01720) 5 data  (0.00703) 1 learning  (0.00703) 22 models  (0.00703) 23 hidden  (0.00703) 17 state  (0.00703) 15 system  (0.00703)
29 (0.02138 / 45):  15 system  (0.14680) 8 time  (0.09319) 7 figure  (0.09319) 16 error  (0.07174) 3 neural  (0.06102) 13 output  (0.06102) 21 problem  (0.06102) 20 information  (0.06102) 1 learning  (0.06102) 5 data  (0.05029) 2 model  (0.05029) 23 hidden  (0.02885) 9 set  (0.01812) 6 function  (0.01812) 14 number  (0.01812) 12 algorithm  (0.01812) 11 training  (0.01812) 4 input  (0.01812) 0 network  (0.00740) 24 performance  (0.00740)
30 (0.01406 / 45):  5 data  (0.15895) 14 number  (0.09947) 3 neural  (0.06974) 4 input  (0.05487) 18 results  (0.05487) 11 training  (0.05487) 15 system  (0.05487) 2 model  (0.05487) 12 algorithm  (0.04000) 0 network  (0.04000) 1 learning  (0.04000) 24 performance  (0.04000) 13 output  (0.04000) 6 function  (0.02513) 8 time  (0.02513) 20 information  (0.02513) 16 error  (0.02513) 10 networks  (0.02513) 21 problem  (0.01026) 23 hidden  (0.01026)
31 (0.01125 / 45):  17 state  (0.15178) 1 learning  (0.11685) 14 number  (0.09938) 6 function  (0.08192) 7 figure  (0.08192) 24 performance  (0.08192) 2 model  (0.02952) 9 set  (0.02952) 13 output  (0.02952) 5 data  (0.02952) 22 models  (0.02952) 19 units  (0.02952) 0 network  (0.02952) 20 information  (0.02952) 23 hidden  (0.02952) 4 input  (0.01206) 3 neural  (0.01206) 18 results  (0.01206) 15 system  (0.01206) 12 algorithm  (0.01206)
32 (0.01069 / 45):  14 number  (0.22966) 4 input  (0.08488) 12 algorithm  (0.08488) 13 output  (0.04869) 16 error  (0.04869) 2 model  (0.04869) 5 data  (0.04869) 24 performance  (0.04869) 20 information  (0.04869) 3 neural  (0.03059) 8 time  (0.03059) 22 models  (0.03059) 6 function  (0.03059) 1 learning  (0.03059) 18 results  (0.03059) 21 problem  (0.01249) 23 hidden  (0.01249) 0 network  (0.01249) 17 state  (0.01249) 19 units  (0.01249)
33 (0.01013 / 45):  23 hidden  (0.10685) 16 error  (0.10685) 4 input  (0.08807) 19 units  (0.08807) 9 set  (0.06929) 12 algorithm  (0.06929) 11 training  (0.05052) 5 data  (0.05052) 6 function  (0.03174) 2 model  (0.03174) 1 learning  (0.03174) 24 performance  (0.03174) 20 information  (0.03174) 21 problem  (0.03174) 17 state  (0.03174) 18 results  (0.03174) 0 network  (0.01296) 3 neural  (0.01296) 22 models  (0.01296) 13 output  (0.01296)
34 (0.00759 / 45):  18 results  (0.19636) 8 time  (0.10598) 10 networks  (0.08338) 16 error  (0.06079) 5 data  (0.06079) 11 training  (0.03819) 12 algorithm  (0.03819) 0 network  (0.03819) 7 figure  (0.03819) 2 model  (0.03819) 24 performance  (0.03819) 17 state  (0.03819) 20 information  (0.03819) 3 neural  (0.01560) 4 input  (0.01560) 21 problem  (0.01560) 23 hidden  (0.01560) 22 models  (0.01560) 1 learning  (0.01560) 13 output  (0.01560)
35 (0.00759 / 45):  5 data  (0.15117) 12 algorithm  (0.12857) 17 state  (0.10598) 18 results  (0.08338) 8 time  (0.06079) 1 learning  (0.06079) 19 units  (0.06079) 14 number  (0.03819) 2 model  (0.03819) 3 neural  (0.03819) 7 figure  (0.01560) 9 set  (0.01560) 0 network  (0.01560) 6 function  (0.01560) 4 input  (0.01560) 24 performance  (0.01560) 21 problem  (0.01560) 22 models  (0.01560) 20 information  (0.01560) 23 hidden  (0.01560)
36 (0.00647 / 45):  8 time  (0.11651) 11 training  (0.09167) 5 data  (0.09167) 13 output  (0.06683) 18 results  (0.06683) 9 set  (0.06683) 10 networks  (0.06683) 23 hidden  (0.06683) 15 system  (0.04199) 7 figure  (0.04199) 21 problem  (0.04199) 1 learning  (0.01715) 0 network  (0.01715) 4 input  (0.01715) 3 neural  (0.01715) 2 model  (0.01715) 6 function  (0.01715) 24 performance  (0.01715) 20 information  (0.01715) 19 units  (0.01715)
37 (0.00506 / 45):  4 input  (0.13303) 19 units  (0.13303) 8 time  (0.07631) 15 system  (0.04794) 13 output  (0.04794) 0 network  (0.04794) 9 set  (0.04794) 10 networks  (0.04794) 21 problem  (0.04794) 20 information  (0.04794) 3 neural  (0.04794) 5 data  (0.01958) 1 learning  (0.01958) 2 model  (0.01958) 6 function  (0.01958) 7 figure  (0.01958) 24 performance  (0.01958) 18 results  (0.01958) 22 models  (0.01958) 17 state  (0.01958)
38 (0.00478 / 45):  20 information  (0.10772) 6 function  (0.10772) 13 output  (0.10772) 3 neural  (0.07853) 10 networks  (0.04934) 1 learning  (0.04934) 7 figure  (0.04934) 24 performance  (0.04934) 21 problem  (0.04934) 23 hidden  (0.04934) 5 data  (0.02015) 4 input  (0.02015) 19 units  (0.02015) 0 network  (0.02015) 22 models  (0.02015) 2 model  (0.02015) 16 error  (0.02015) 17 state  (0.02015) 14 number  (0.02015) 12 algorithm  (0.02015)
39 (0.00309 / 45):  9 set  (0.09521) 12 algorithm  (0.09521) 17 state  (0.05982) 11 training  (0.05982) 16 error  (0.05982) 6 function  (0.05982) 10 networks  (0.05982) 20 information  (0.05982) 2 model  (0.05982) 7 figure  (0.02443) 8 time  (0.02443) 0 network  (0.02443) 1 learning  (0.02443) 5 data  (0.02443) 4 input  (0.02443) 3 neural  (0.02443) 24 performance  (0.02443) 21 problem  (0.02443) 22 models  (0.02443) 19 units  (0.02443)
40 (0.00141 / 45):  20 information  (0.07594) 13 output  (0.07594) 17 state  (0.07594) 5 data  (0.07594) 12 algorithm  (0.07594) 8 time  (0.03101) 7 figure  (0.03101) 6 function  (0.03101) 9 set  (0.03101) 0 network  (0.03101) 1 learning  (0.03101) 4 input  (0.03101) 3 neural  (0.03101) 2 model  (0.03101) 24 performance  (0.03101) 19 units  (0.03101) 21 problem  (0.03101) 18 results  (0.03101) 23 hidden  (0.03101) 22 models  (0.03101)
41 (0.00113 / 45):  2 model  (0.12656) 9 set  (0.07952) 24 performance  (0.07952) 6 function  (0.03247) 7 figure  (0.03247) 5 data  (0.03247) 22 models  (0.03247) 8 time  (0.03247) 10 networks  (0.03247) 0 network  (0.03247) 1 learning  (0.03247) 4 input  (0.03247) 3 neural  (0.03247) 23 hidden  (0.03247) 21 problem  (0.03247) 17 state  (0.03247) 18 results  (0.03247) 16 error  (0.03247) 20 information  (0.03247) 19 units  (0.03247)
42 (0.00028 / 45):  14 number  (0.09258) 8 time  (0.03781) 7 figure  (0.03781) 6 function  (0.03781) 10 networks  (0.03781) 9 set  (0.03781) 11 training  (0.03781) 1 learning  (0.03781) 2 model  (0.03781) 0 network  (0.03781) 5 data  (0.03781) 4 input  (0.03781) 3 neural  (0.03781) 24 performance  (0.03781) 20 information  (0.03781) 21 problem  (0.03781) 19 units  (0.03781) 23 hidden  (0.03781) 22 models  (0.03781) 12 algorithm  (0.03781)
43 (0.00028 / 45):  11 training  (0.09258) 7 figure  (0.03781) 8 time  (0.03781) 6 function  (0.03781) 10 networks  (0.03781) 9 set  (0.03781) 0 network  (0.03781) 1 learning  (0.03781) 2 model  (0.03781) 5 data  (0.03781) 4 input  (0.03781) 3 neural  (0.03781) 24 performance  (0.03781) 20 information  (0.03781) 21 problem  (0.03781) 19 units  (0.03781) 18 results  (0.03781) 23 hidden  (0.03781) 22 models  (0.03781) 12 algorithm  (0.03781)
44 (0.00028 / 45):  22 models  (0.09258) 7 figure  (0.03781) 8 time  (0.03781) 6 function  (0.03781) 5 data  (0.03781) 10 networks  (0.03781) 9 set  (0.03781) 11 training  (0.03781) 0 network  (0.03781) 1 learning  (0.03781) 4 input  (0.03781) 3 neural  (0.03781) 2 model  (0.03781) 24 performance  (0.03781) 19 units  (0.03781) 20 information  (0.03781) 18 results  (0.03781) 23 hidden  (0.03781) 21 problem  (0.03781) 12 algorithm  (0.03781)
