import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.io.OutputStream;
import java.io.PrintWriter;
import java.io.Writer;
import java.util.List;
import java.util.Properties;

import edu.stanford.nlp.ling.CoreAnnotations.LemmaAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TextAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.util.CoreMap;

/**
 * An object of BaseFormConverter convert English texts to texts in words' base form by using
 * <a href="http://nlp.stanford.edu/software/corenlp.shtml">Standford Core NLP Tools</a>.
 * <p>
 * The input can be a single file or a directory. When the input is a single file, the converting
 * results will be written to the specified output file. Note the specified output file must not be 
 * an existing directory; otherwise, an error will occur making the processing fail.<br>
 * If the input is an existing directory, the files in the directory will be processed individually
 * with the words in the base form written to a file with the same file name in the specified output
 * directory. It will also cause a processing failure if the specified output is an existing file
 * rather than a directory regardless its existence.
 * <p>
 * 
 * @author Youwei Lu
 */
public class BaseFormConverter {
	String inputf;
	String outputf;
	String errorlogfile;
	boolean isdir;
	
	// a StanfordCoreNLP object, with POS tagging, lemmatization, NER, parsing, and coreference resolution 
	StanfordCoreNLP pipeline;
	
	public BaseFormConverter(String inputf, String outputf, String errorlogfile) {
		this.inputf = inputf;
		this.outputf = outputf;
		this.errorlogfile = errorlogfile;
		File output = new File(outputf);
		if(new File(inputf).isDirectory()){
			this.isdir = true;
			if(output.exists() && output.isFile()) {
				throw new RuntimeException("The output directory cannot be created");
			}
			else if(!output.exists()) {
				output.mkdir();
			}
		}
		else {
			if(output.exists() && output.isDirectory()) {
				throw new RuntimeException("Directory "+outputf+" is already used.");
			}
			this.isdir = false;
		}
		Properties props = new Properties();
		props.setProperty("annotators", "tokenize, ssplit, pos, lemma, ner, parse, dcoref");
		pipeline = new StanfordCoreNLP(props);
	}
	
	public BaseFormConverter(String inputf, String outputf) {
		this(inputf, outputf, "error.log");
	}
	
	public void doconvert() {
		PrintWriter err;
		try {
			err = new PrintWriter(this.errorlogfile);
		} catch (FileNotFoundException e1) {
			throw new RuntimeException("Cannot create log file.");
		}
		if(isdir) {
			File inputdir = new File(this.inputf);
			File[] directoryListing = inputdir.listFiles();
			File outputfile = null;
			BufferedWriter writer = null;
			BufferedReader reader = null;
			String line = null;
			for (File child : directoryListing) {
				try {
					outputfile = new File(outputf, child.getName());
					writer = new BufferedWriter(new FileWriter(outputfile));
					reader = new BufferedReader(new FileReader(child));
					List<CoreMap> sentences;
					while((line=reader.readLine()) != null) {
						sentences = convertStringToSentences(line);
						outputSentencesInBasicForm(sentences, writer);
						writer.newLine();
					}
					writer.close();
					reader.close();
				} catch (IOException e) {
					e.printStackTrace(err);
				}
			}
		}
		else {
			
		}
	}
	
	static void outputSentencesInBasicForm(List<CoreMap> sentences, BufferedWriter out) throws IOException {
		String word, pos;
		for(CoreMap sentence: sentences) {
			for (CoreLabel token: sentence.get(TokensAnnotation.class)) {
		        // this is the text of the token
		        word = token.get(TextAnnotation.class);
		        // this is the lemma of the token
		        pos = token.get(LemmaAnnotation.class);
		        out.write(pos+" ");
		    }
		}
		out.flush();
	}
	
	public List<CoreMap> convertStringToSentences(String text) {
	    // create an empty Annotation just with the given text
	    Annotation document = new Annotation(text);
	    
	    // run all Annotators on this text
	    pipeline.annotate(document);
	    
	    // these are all the sentences in this document
	    // a CoreMap is essentially a Map that uses class objects as keys and has values with custom types
	    List<CoreMap> sentences = document.get(SentencesAnnotation.class);
	    
	    return sentences;
	}

	public static void main(String[] args) {
		// TODO Auto-generated method stub
		File f = new File();
	}

}
