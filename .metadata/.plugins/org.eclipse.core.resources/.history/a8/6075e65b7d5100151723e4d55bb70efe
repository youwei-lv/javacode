import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.io.OutputStream;
import java.io.PrintWriter;
import java.io.Writer;
import java.util.List;
import java.util.Properties;

import edu.stanford.nlp.ling.CoreAnnotations.LemmaAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.SentencesAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TextAnnotation;
import edu.stanford.nlp.ling.CoreAnnotations.TokensAnnotation;
import edu.stanford.nlp.ling.CoreLabel;
import edu.stanford.nlp.pipeline.Annotation;
import edu.stanford.nlp.pipeline.StanfordCoreNLP;
import edu.stanford.nlp.util.CoreMap;

public class BaseFormConverter {
	String inputf;
	String outputf;
	String errorlogfile="error.log";
	boolean isdir;
	
	// creates a StanfordCoreNLP object, with POS tagging, lemmatization, NER, parsing, and coreference resolution 
	static StanfordCoreNLP pipeline;
	static {
		Properties props = new Properties();
		props.setProperty("annotators", "tokenize, ssplit, pos, lemma, ner, parse, dcoref");
		pipeline = new StanfordCoreNLP(props);
	}
	
	public BaseFormConverter(String inputf, String outputf) {
		this.inputf = inputf;
		this.outputf = outputf;
		if(new File(inputf).isDirectory()){
			this.isdir = true;
			File outputdir = new File(outputf);
			if(outputdir.exists() && outputdir.isFile()) {
				throw new RuntimeException("The output directory cannot be created");
			}
			else if(!outputdir.exists()) {
				outputdir.mkdir();
			}
		}
		else {
			this.isdir = false;
		}
	}
	
	public void baseFormConverting() {
		PrintWriter err;
		try {
			err = new PrintWriter(this.errorlogfile);
		} catch (FileNotFoundException e1) {
			throw new RuntimeException("Cannot create log file.");
		}
		if(isdir) {
			File dir = new File(this.inputf);
			File[] directoryListing = dir.listFiles();
			BufferedReader reader = null;
			String line = null;
			for (File child : directoryListing) {
				try {
					reader = new BufferedReader(new FileReader(child));
					List<CoreMap> sentences;
					while((line=reader.readLine()) != null) {
						sentences = convertStringToSentences(line);
						for(CoreMap sentence: sentences) {
						      // traversing the words in the current sentence
						      // a CoreLabel is a CoreMap with additional token-specific methods
						      
						}
					}
				} catch (IOException e) {
					e.printStackTrace(err);
				}
			}
		}
		else {
			
		}
	}
	
	static void outputSentenceInBasicForm(CoreMap sentence, BufferedWriter out) throws IOException {
		String word, pos;
		
		for (CoreLabel token: sentence.get(TokensAnnotation.class)) {
	        // this is the text of the token
	        word = token.get(TextAnnotation.class);
	        // this is the lemma of the token
	        pos = token.get(LemmaAnnotation.class);
	        out.write(pos+" ");
	    }
		out.flush();
	}
	
	static public List<CoreMap> convertStringToSentences(String text) {
	    // create an empty Annotation just with the given text
	    Annotation document = new Annotation(text);
	    
	    // run all Annotators on this text
	    pipeline.annotate(document);
	    
	    // these are all the sentences in this document
	    // a CoreMap is essentially a Map that uses class objects as keys and has values with custom types
	    List<CoreMap> sentences = document.get(SentencesAnnotation.class);
	    
	    return sentences;
	}

	public static void main(String[] args) {
		// TODO Auto-generated method stub
		File f = new File();
	}

}
